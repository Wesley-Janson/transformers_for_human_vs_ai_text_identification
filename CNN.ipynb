{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wesley-Janson/transformers_for_human_vs_ai_text_identification/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sVt0Q2rzlJJs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/mlclass/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "/opt/anaconda3/envs/mlclass/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Import relevant packages and data_loader.py\n",
        "#import data_loader\n",
        "\n",
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for reading and displaying images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for creating validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, Conv2d, MaxPool1d, MaxPool2d, Module, Softmax, BatchNorm1d, BatchNorm2d, Dropout, Embedding\n",
        "from torch.optim import Adam, SGD\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k8CDKMYwpjwm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aRaZIij8puzX"
      },
      "outputs": [],
      "source": [
        "def load_data(csv):\n",
        "  # Reads the raw csv file and split into\n",
        "  # sentences (x) and target (y)\n",
        "  df = pd.read_csv(csv)  \n",
        "  text = df['intro'].values\n",
        "  labels = df['type'].values\n",
        "  return labels,text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oIY1CJJ5p0zA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This function processes training data, establishing number IDs for each vocabulary word,\n",
        "# converting word sequence into ID sequence (input_as_ids), and providing dict\n",
        "# to map from word to its ID (word2id), and list to map from ID back to word (id2word)\n",
        "def process_training_data(corpus_text):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        # Create the model's vocabulary and map to unique indices\n",
        "        word2id = {}\n",
        "        id2word = []\n",
        "        indexes_dropped = []\n",
        "        list_of_inputs = []\n",
        "        for j, entry in enumerate(corpus_text):\n",
        "            for i,word in enumerate(entry):\n",
        "                if 7<i<=30:\n",
        "                    if word not in word2id:\n",
        "                        id2word.append(word)\n",
        "                        word2id[word] = len(id2word) - 1\n",
        "\n",
        "            # Convert string of text into string of IDs in a tensor for input to model\n",
        "            input_as_ids = []\n",
        "            for i,word in enumerate(entry):\n",
        "                if 7<i<=30:\n",
        "                    input_as_ids.append(word2id[word])\n",
        "            if len(input_as_ids) == 23:\n",
        "              list_of_inputs.append(input_as_ids)\n",
        "            else:\n",
        "              indexes_dropped.append(j)\n",
        "            # final_ids = torch.LongTensor(input_as_ids)\n",
        "        list_of_inputs = torch.Tensor(list_of_inputs)\n",
        "\n",
        "        return list_of_inputs,word2id,id2word, indexes_dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T4irZ27ls7Z",
        "outputId": "c7e3d556-3533-4122-f0a9-2f817c8d304c"
      },
      "outputs": [],
      "source": [
        "# Run data loader\n",
        "labels, text = load_data('data/data.csv')\n",
        "train_x, val_x, train_y, val_y = train_test_split(text, labels, test_size = 0.2)\n",
        "val_x, test_x, val_y, test_y = train_test_split(val_x, val_y, test_size = 0.5)\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "list_of_tokens_train = [tokenizer(x) for x in train_x]\n",
        "list_of_tokens_val = [tokenizer(x) for x in val_x]\n",
        "list_of_tokens_test = [tokenizer(x) for x in test_x]\n",
        "\n",
        "train_x,word2id_train,id2word_train, indexes_dropped_train = process_training_data(list_of_tokens_train)\n",
        "\n",
        "val_x,word2id_val,id2word_val, indexes_dropped_val = process_training_data(list_of_tokens_val)\n",
        "\n",
        "test_x,word2id_test,id2word_test, indexes_dropped_test = process_training_data(list_of_tokens_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEao8vNKIceW",
        "outputId": "79e73750-7a42-4dd5-c535-740bb1bbd698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([238912, 23])\n",
            "torch.Size([238912, 1])\n",
            "torch.Size([29871, 23])\n",
            "torch.Size([29871, 1])\n",
            "torch.Size([29862, 23])\n",
            "torch.Size([29862, 1])\n",
            "(238912, 24)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "new_train = [x for x in indexes_dropped_train]\n",
        "new_val = [x for x in indexes_dropped_val]\n",
        "new_test = [x for x in indexes_dropped_test]\n",
        "\n",
        "train_y = list(train_y)\n",
        "for index, element in enumerate(new_train):\n",
        "    del train_y[element - index]  # Remove element from train_y\n",
        "    for i in range(len(indexes_dropped_train)):\n",
        "        if indexes_dropped_train[i] > element:\n",
        "            indexes_dropped_train[i] -= 1  # Decrement indexes after removal\n",
        "\n",
        "val_y = list(val_y)\n",
        "for index, element in enumerate(new_val):\n",
        "    del val_y[element - index]  # Remove element from val_y\n",
        "    for i in range(len(indexes_dropped_val)):\n",
        "        if indexes_dropped_val[i] > element:\n",
        "            indexes_dropped_val[i] -= 1  # Decrement indexes after removal\n",
        "\n",
        "test_y = list(test_y)\n",
        "for index, element in enumerate(new_test):\n",
        "    del test_y[element - index]  # Remove element from test_y\n",
        "    for i in range(len(indexes_dropped_test)):\n",
        "        if indexes_dropped_test[i] > element:\n",
        "            indexes_dropped_test[i] -= 1  # Decrement indexes after removal\n",
        "\n",
        "train_y = np.asarray(train_y)\n",
        "val_y = np.asarray(val_y)\n",
        "train_y = torch.Tensor(train_y.reshape((len(train_y), 1)))\n",
        "val_y = torch.Tensor(val_y.reshape((len(val_y), 1)))\n",
        "test_y = np.asarray(test_y)\n",
        "test_y = torch.Tensor(test_y.reshape((len(test_y), 1)))\n",
        "\n",
        "# Check the shapes of the arrays after the modifications\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(val_x.shape)\n",
        "print(val_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)\n",
        "\n",
        "text_pipeline = lambda x: x\n",
        "label_pipeline = lambda x: int(x)\n",
        "train_both = np.concatenate([train_x, train_y], axis=1)\n",
        "val_both = np.concatenate([val_x, val_y], axis=1)\n",
        "test_both = np.concatenate([test_x, test_y], axis=1)\n",
        "print(train_both.shape)\n",
        "print(type(train_both))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zQmxBERv2lg",
        "outputId": "9adc0bb9-af59-4606-f41e-b7a57d360ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23891 (tensor([0, 1]), tensor([    12,     32,      7,    940,     28,     30,   2181,  14617,  49437,\n",
            "          2307,    219, 182976,      0,     14,     30,   2998,     32,    675,\n",
            "            71,    131,   1558,      3, 182977,  10254,   2789,    242,     28,\n",
            "          7970,  28386,     14,     22,      6,      2,    153,     77,   6466,\n",
            "        104026,   7839,      1,  49890, 182978,  23697,      1,     12,  37614,\n",
            "          3058]), tensor([ 0, 23]))\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for entry in batch:\n",
        "         _label = entry[-1] \n",
        "         _text = entry[:len(entry)-1] \n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "batch_size_var = 10\n",
        "train_loader = DataLoader(train_both, batch_size=batch_size_var, shuffle=False, collate_fn=collate_batch)\n",
        "val_loader = DataLoader(train_both, batch_size=batch_size_var, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_both, batch_size=batch_size_var, shuffle=False, collate_fn=collate_batch)\n",
        "trainSteps = len(train_loader.dataset) // batch_size_var\n",
        "valSteps = len(val_loader.dataset) // batch_size_var\n",
        "testSteps = len(test_loader.dataset) // batch_size_var\n",
        "for i, batch in enumerate(train_loader):\n",
        "  a,b,c = batch\n",
        "  if len(a) != 10:\n",
        "      print(i, batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CavGDuyJxt5l",
        "outputId": "c270404b-ba35-44ff-b9d1-c6088a4bcf22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "next_, labels_, _offset = next(iter(train_loader))\n",
        "print(next_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        # Max pooling layer\n",
        "        self.max_pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(128, 1)  # Assuming the output size is 2\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "        x = self.conv1(embedded)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (embedding): Embedding(182979, 23)\n",
            "  (conv1): Conv1d(23, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (conv2): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (conv3): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# defining the model\n",
        "vocab_size = len(word2id_train)\n",
        "embedding_dim = 23\n",
        "\n",
        "model = CNN(vocab_size, embedding_dim)\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "# defining the loss function\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)\n",
        "\n",
        "def compute_metrics(predictions, targets):\n",
        "    # Round predictions to get binary values\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "\n",
        "    # Calculate true positives, false positives, and false negatives\n",
        "    true_positives = torch.logical_and(rounded_preds == 1, targets == 1).sum().item()\n",
        "    false_positives = torch.logical_and(rounded_preds == 1, targets == 0).sum().item()\n",
        "    false_negatives = torch.logical_and(rounded_preds == 0, targets == 1).sum().item()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = torch.eq(rounded_preds, targets).sum().item() / targets.size(0)\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    if true_positives + false_positives > 0:\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "    else:\n",
        "        precision = 0.0\n",
        "\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "    return accuracy, precision, recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7lv7xQRCx1ln"
      },
      "outputs": [],
      "source": [
        "#logistic regression bag of words, can get fwearture importance\n",
        "\n",
        "#how get feature importance in CNN's\n",
        "\n",
        "#how get tokesn out of featurs\n",
        "\n",
        "#run examples we know, print which filter getting trigegred, associate words or grams with filteere\n",
        "\n",
        "#tsney (visualize nerual net)\n",
        "\n",
        "#take examples human got wrong, see what we get right, find k-grams that ar enon-triavail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_accuracies = []\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "val_accuracies = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "test_accuracies = []\n",
        "test_precisions = []\n",
        "test_recalls = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(epoch):\n",
        "    running_loss = 0.0\n",
        "    total_predictions = []\n",
        "    total_labels = []\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        labels, inputs, offset = data\n",
        "        if len(labels) == 10:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs = inputs.reshape([10, 23]).to(device=device, dtype=torch.long)\n",
        "            labels = labels.float().to(device=device)  # Convert labels to float\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels.unsqueeze(1))\n",
        "\n",
        "            # Calculate metrics\n",
        "            rounded_preds = torch.round(torch.sigmoid(outputs))\n",
        "            total_predictions.extend(rounded_preds.tolist())\n",
        "            total_labels.extend(labels.tolist())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:  # Print average loss every 10 batches\n",
        "                average_loss = running_loss / 10\n",
        "                accuracy, precision, recall = compute_metrics(torch.tensor(total_predictions), torch.tensor(total_labels))\n",
        "                print(f\"Epoch: {epoch}, Batch: {i+1}, Loss: {average_loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "                # Reset lists for next batch\n",
        "                total_predictions = []\n",
        "                total_labels = []\n",
        "\n",
        "    return running_loss\n",
        "def train_epoch(epoch):\n",
        "    running_loss = 0.0\n",
        "    total_predictions = []\n",
        "    total_labels = []\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        labels, inputs, offset = data\n",
        "        if len(labels) == 10:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs = inputs.reshape([10, 23]).to(device=device, dtype=torch.long)\n",
        "            labels = labels.float().to(device=device)  # Convert labels to float\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels.unsqueeze(1))\n",
        "\n",
        "            # Calculate metrics\n",
        "            rounded_preds = torch.round(torch.sigmoid(outputs))\n",
        "            total_predictions.extend(rounded_preds.tolist())\n",
        "            total_labels.extend(labels.tolist())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:  # Print average loss every 10 batches\n",
        "                average_loss = running_loss / 10\n",
        "                accuracy, precision, recall = compute_metrics(torch.tensor(total_predictions), torch.tensor(total_labels))\n",
        "                print(f\"Epoch: {epoch}, Batch: {i+1}, Loss: {average_loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "                # Reset lists for next batch\n",
        "                total_predictions = []\n",
        "                total_labels = []\n",
        "\n",
        "    return average_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWUhv7b-WJMk",
        "outputId": "bd044904-19f2-4022-b23f-4974982c3188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1:\n",
            "Epoch: 0, Batch: 10, Loss: 0.7020741879940033, Accuracy: 51.84, Precision: 0.54, Recall: 0.73\n",
            "Epoch: 0, Batch: 20, Loss: 0.6998058736324311, Accuracy: 49.58, Precision: 0.43, Recall: 0.53\n",
            "Epoch: 0, Batch: 30, Loss: 0.70354323387146, Accuracy: 52.0, Precision: 0.0, Recall: 0.0\n",
            "Epoch: 0, Batch: 40, Loss: 0.6966799974441529, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 50, Loss: 0.6953270077705384, Accuracy: 48.8, Precision: 0.48, Recall: 0.8\n",
            "Epoch: 0, Batch: 60, Loss: 0.6933410465717316, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 70, Loss: 0.6931746304035187, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 80, Loss: 0.693159306049347, Accuracy: 49.04, Precision: 0.52, Recall: 0.26\n",
            "Epoch: 0, Batch: 90, Loss: 0.6965607166290283, Accuracy: 56.72, Precision: 0.42, Recall: 0.08\n",
            "Epoch: 0, Batch: 100, Loss: 0.6914930880069733, Accuracy: 52.0, Precision: 0.0, Recall: 0.0\n",
            "Epoch: 0, Batch: 110, Loss: 0.6969154179096222, Accuracy: 46.08, Precision: 0.54, Recall: 0.01\n",
            "Epoch: 0, Batch: 120, Loss: 0.6915716469287873, Accuracy: 50.92, Precision: 0.49, Recall: 0.04\n",
            "Epoch: 0, Batch: 130, Loss: 0.6919218480587006, Accuracy: 50.18, Precision: 0.49, Recall: 0.41\n",
            "Epoch: 0, Batch: 140, Loss: 0.6903610229492188, Accuracy: 53.0, Precision: 0.6, Recall: 0.65\n",
            "Epoch: 0, Batch: 150, Loss: 0.6942828834056854, Accuracy: 51.0, Precision: 0.51, Recall: 1.0\n",
            "Epoch: 0, Batch: 160, Loss: 0.6945626080036164, Accuracy: 53.92, Precision: 0.54, Recall: 0.99\n",
            "Epoch: 0, Batch: 170, Loss: 0.6923183500766754, Accuracy: 51.84, Precision: 0.52, Recall: 0.96\n",
            "Epoch: 0, Batch: 180, Loss: 0.6959821045398712, Accuracy: 51.08, Precision: 0.53, Recall: 0.68\n",
            "Epoch: 0, Batch: 190, Loss: 0.6942486107349396, Accuracy: 48.96, Precision: 0.48, Recall: 0.76\n",
            "Epoch: 0, Batch: 200, Loss: 0.6863811671733856, Accuracy: 51.56, Precision: 0.56, Recall: 0.63\n",
            "Epoch: 0, Batch: 210, Loss: 0.6869642198085785, Accuracy: 54.7, Precision: 0.55, Recall: 0.97\n",
            "Epoch: 0, Batch: 220, Loss: 0.6917484343051911, Accuracy: 51.0, Precision: 0.51, Recall: 1.0\n",
            "Epoch: 0, Batch: 230, Loss: 0.6843543827533722, Accuracy: 52.8, Precision: 0.54, Recall: 0.85\n",
            "Epoch: 0, Batch: 240, Loss: 0.691570496559143, Accuracy: 50.0, Precision: 0.5, Recall: 0.9\n",
            "Epoch: 0, Batch: 250, Loss: 0.6919062435626984, Accuracy: 50.0, Precision: 0.5, Recall: 0.77\n",
            "Epoch: 0, Batch: 260, Loss: 0.6896624267101288, Accuracy: 49.44, Precision: 0.49, Recall: 0.78\n",
            "Epoch: 0, Batch: 270, Loss: 0.6911536872386932, Accuracy: 50.98, Precision: 0.43, Recall: 0.43\n",
            "Epoch: 0, Batch: 280, Loss: 0.693055534362793, Accuracy: 51.88, Precision: 0.48, Recall: 0.03\n",
            "Epoch: 0, Batch: 290, Loss: 0.6924242198467254, Accuracy: 48.56, Precision: 0.53, Recall: 0.26\n",
            "Epoch: 0, Batch: 300, Loss: 0.6843474686145783, Accuracy: 54.0, Precision: 0.55, Recall: 0.9\n",
            "Epoch: 0, Batch: 310, Loss: 0.7089516818523407, Accuracy: 44.72, Precision: 0.39, Recall: 0.74\n",
            "Epoch: 0, Batch: 320, Loss: 0.6956824421882629, Accuracy: 48.6, Precision: 0.52, Recall: 0.15\n",
            "Epoch: 0, Batch: 330, Loss: 0.6923149764537812, Accuracy: 48.2, Precision: 0.53, Recall: 0.2\n",
            "Epoch: 0, Batch: 340, Loss: 0.6915371239185333, Accuracy: 50.24, Precision: 0.51, Recall: 0.62\n",
            "Epoch: 0, Batch: 350, Loss: 0.6847660839557648, Accuracy: 51.74, Precision: 0.53, Recall: 0.79\n",
            "Epoch: 0, Batch: 360, Loss: 0.6735930025577546, Accuracy: 54.0, Precision: 0.54, Recall: 1.0\n",
            "Epoch: 0, Batch: 370, Loss: 0.6762492597103119, Accuracy: 50.0, Precision: 0.5, Recall: 0.63\n",
            "Epoch: 0, Batch: 380, Loss: 0.6530925273895264, Accuracy: 58.84, Precision: 0.33, Recall: 0.24\n",
            "Epoch: 0, Batch: 390, Loss: 0.6696048378944397, Accuracy: 52.24, Precision: 0.46, Recall: 0.22\n",
            "Epoch: 0, Batch: 400, Loss: 0.6738529324531555, Accuracy: 51.8, Precision: 0.55, Recall: 0.68\n",
            "Epoch: 0, Batch: 410, Loss: 0.6204438209533691, Accuracy: 51.68, Precision: 0.56, Recall: 0.64\n",
            "Epoch: 0, Batch: 420, Loss: 0.6779098868370056, Accuracy: 52.8, Precision: 0.4, Recall: 0.36\n",
            "Epoch: 0, Batch: 430, Loss: 0.6554236233234405, Accuracy: 56.56, Precision: 0.42, Recall: 0.09\n",
            "Epoch: 0, Batch: 440, Loss: 0.666333693265915, Accuracy: 50.0, Precision: 0.5, Recall: 0.56\n",
            "Epoch: 0, Batch: 450, Loss: 0.644238555431366, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 460, Loss: 0.6122480422258377, Accuracy: 59.24, Precision: 0.64, Recall: 0.83\n",
            "Epoch: 0, Batch: 470, Loss: 0.6793928742408752, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 480, Loss: 0.6697191894054413, Accuracy: 49.28, Precision: 0.53, Recall: 0.38\n",
            "Epoch: 0, Batch: 490, Loss: 0.6343241989612579, Accuracy: 51.38, Precision: 0.53, Recall: 0.73\n",
            "Epoch: 0, Batch: 500, Loss: 0.7231992244720459, Accuracy: 49.92, Precision: 0.49, Recall: 0.54\n",
            "Epoch: 0, Batch: 510, Loss: 0.659042376279831, Accuracy: 49.82, Precision: 0.51, Recall: 0.41\n",
            "Epoch: 0, Batch: 520, Loss: 0.6370021164417267, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 530, Loss: 0.6867631852626801, Accuracy: 47.24, Precision: 0.44, Recall: 0.73\n",
            "Epoch: 0, Batch: 540, Loss: 0.6661100447177887, Accuracy: 50.72, Precision: 0.48, Recall: 0.32\n",
            "Epoch: 0, Batch: 550, Loss: 0.6501022040843963, Accuracy: 49.44, Precision: 0.51, Recall: 0.22\n",
            "Epoch: 0, Batch: 560, Loss: 0.6707343459129333, Accuracy: 49.6, Precision: 0.4, Recall: 0.52\n",
            "Epoch: 0, Batch: 570, Loss: 0.6579852998256683, Accuracy: 50.38, Precision: 0.49, Recall: 0.31\n",
            "Epoch: 0, Batch: 580, Loss: 0.6160143375396728, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 590, Loss: 0.6365357756614685, Accuracy: 52.56, Precision: 0.58, Recall: 0.66\n",
            "Epoch: 0, Batch: 600, Loss: 0.6611931443214416, Accuracy: 50.34, Precision: 0.51, Recall: 0.67\n",
            "Epoch: 0, Batch: 610, Loss: 0.6298340439796448, Accuracy: 51.08, Precision: 0.47, Recall: 0.32\n",
            "Epoch: 0, Batch: 620, Loss: 0.7031151473522186, Accuracy: 49.28, Precision: 0.54, Recall: 0.41\n",
            "Epoch: 0, Batch: 630, Loss: 0.6491305232048035, Accuracy: 51.12, Precision: 0.52, Recall: 0.78\n",
            "Epoch: 0, Batch: 640, Loss: 0.6125928103923798, Accuracy: 49.52, Precision: 0.48, Recall: 0.62\n",
            "Epoch: 0, Batch: 650, Loss: 0.6213252186775208, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 660, Loss: 0.5990419089794159, Accuracy: 49.56, Precision: 0.52, Recall: 0.39\n",
            "Epoch: 0, Batch: 670, Loss: 0.6206109911203385, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 680, Loss: 0.6260620057582855, Accuracy: 53.12, Precision: 0.44, Recall: 0.24\n",
            "Epoch: 0, Batch: 690, Loss: 0.6106151729822159, Accuracy: 50.4, Precision: 0.52, Recall: 0.6\n",
            "Epoch: 0, Batch: 700, Loss: 0.6471804976463318, Accuracy: 51.02, Precision: 0.47, Recall: 0.33\n",
            "Epoch: 0, Batch: 710, Loss: 0.6677995145320892, Accuracy: 51.32, Precision: 0.48, Recall: 0.17\n",
            "Epoch: 0, Batch: 720, Loss: 0.6656539678573609, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 730, Loss: 0.6219702184200286, Accuracy: 49.64, Precision: 0.53, Recall: 0.44\n",
            "Epoch: 0, Batch: 740, Loss: 0.6376672148704529, Accuracy: 49.22, Precision: 0.53, Recall: 0.37\n",
            "Epoch: 0, Batch: 750, Loss: 0.6127892911434174, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 760, Loss: 0.6497042596340179, Accuracy: 51.6, Precision: 0.45, Recall: 0.34\n",
            "Epoch: 0, Batch: 770, Loss: 0.6434692442417145, Accuracy: 51.86, Precision: 0.47, Recall: 0.19\n",
            "Epoch: 0, Batch: 780, Loss: 0.6705909371376038, Accuracy: 51.3, Precision: 0.55, Recall: 0.63\n",
            "Epoch: 0, Batch: 790, Loss: 0.6750655770301819, Accuracy: 50.2, Precision: 0.55, Recall: 0.52\n",
            "Epoch: 0, Batch: 800, Loss: 0.6307483971118927, Accuracy: 51.44, Precision: 0.46, Recall: 0.32\n",
            "Epoch: 0, Batch: 810, Loss: 0.6431510597467422, Accuracy: 50.3, Precision: 0.49, Recall: 0.35\n",
            "Epoch: 0, Batch: 820, Loss: 0.6018870830535888, Accuracy: 50.84, Precision: 0.48, Recall: 0.29\n",
            "Epoch: 0, Batch: 830, Loss: 0.5653733313083649, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 840, Loss: 0.6766268253326416, Accuracy: 49.84, Precision: 0.48, Recall: 0.54\n",
            "Epoch: 0, Batch: 850, Loss: 0.6183002471923829, Accuracy: 53.48, Precision: 0.44, Recall: 0.21\n",
            "Epoch: 0, Batch: 860, Loss: 0.6723816871643067, Accuracy: 50.5, Precision: 0.49, Recall: 0.25\n",
            "Epoch: 0, Batch: 870, Loss: 0.652094841003418, Accuracy: 50.0, Precision: 0.5, Recall: 0.59\n",
            "Epoch: 0, Batch: 880, Loss: 0.6153343677520752, Accuracy: 51.36, Precision: 0.46, Recall: 0.33\n",
            "Epoch: 0, Batch: 890, Loss: 0.6064557939767837, Accuracy: 50.0, Precision: 0.58, Recall: 0.5\n",
            "Epoch: 0, Batch: 900, Loss: 0.6573814630508423, Accuracy: 51.0, Precision: 0.55, Recall: 0.6\n",
            "Epoch: 0, Batch: 910, Loss: 0.5669815450906753, Accuracy: 49.58, Precision: 0.53, Recall: 0.43\n",
            "Epoch: 0, Batch: 920, Loss: 0.6295044213533402, Accuracy: 52.24, Precision: 0.42, Recall: 0.36\n",
            "Epoch: 0, Batch: 930, Loss: 0.6379627317190171, Accuracy: 50.0, Precision: 0.5, Recall: 0.31\n",
            "Epoch: 0, Batch: 940, Loss: 0.5870597660541534, Accuracy: 50.7, Precision: 0.55, Recall: 0.57\n",
            "Epoch: 0, Batch: 950, Loss: 0.5842019021511078, Accuracy: 49.88, Precision: 0.48, Recall: 0.53\n",
            "Epoch: 0, Batch: 960, Loss: 0.6614009290933609, Accuracy: 50.32, Precision: 0.49, Recall: 0.34\n",
            "Epoch: 0, Batch: 970, Loss: 0.6251686215400696, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 980, Loss: 0.653652822971344, Accuracy: 50.16, Precision: 0.42, Recall: 0.49\n",
            "Epoch: 0, Batch: 990, Loss: 0.6157500147819519, Accuracy: 53.4, Precision: 0.45, Recall: 0.16\n",
            "Epoch: 0, Batch: 1000, Loss: 0.5825298607349396, Accuracy: 50.2, Precision: 0.6, Recall: 0.51\n",
            "Epoch: 0, Batch: 1010, Loss: 0.7150124728679657, Accuracy: 51.84, Precision: 0.54, Recall: 0.73\n",
            "Epoch: 0, Batch: 1020, Loss: 0.5963820964097977, Accuracy: 50.28, Precision: 0.43, Recall: 0.48\n",
            "Epoch: 0, Batch: 1030, Loss: 0.6402061700820922, Accuracy: 49.36, Precision: 0.54, Recall: 0.42\n",
            "Epoch: 0, Batch: 1040, Loss: 0.5876780241727829, Accuracy: 50.96, Precision: 0.44, Recall: 0.42\n",
            "Epoch: 0, Batch: 1050, Loss: 0.6299093455076218, Accuracy: 50.0, Precision: 0.5, Recall: 0.41\n",
            "Epoch: 0, Batch: 1060, Loss: 0.5985236525535583, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 1070, Loss: 0.611289981007576, Accuracy: 53.36, Precision: 0.42, Recall: 0.29\n",
            "Epoch: 0, Batch: 1080, Loss: 0.6122800290584565, Accuracy: 49.56, Precision: 0.52, Recall: 0.39\n",
            "Epoch: 0, Batch: 1090, Loss: 0.6549349665641785, Accuracy: 49.64, Precision: 0.44, Recall: 0.53\n",
            "Epoch: 0, Batch: 1100, Loss: 0.6279990375041962, Accuracy: 51.7, Precision: 0.45, Recall: 0.33\n",
            "Epoch: 0, Batch: 1110, Loss: 0.5815880566835403, Accuracy: 50.24, Precision: 0.49, Recall: 0.38\n",
            "Epoch: 0, Batch: 1120, Loss: 0.6267470091581344, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 1130, Loss: 0.6168828278779983, Accuracy: 51.6, Precision: 0.4, Recall: 0.42\n",
            "Epoch: 0, Batch: 1140, Loss: 0.6031547367572785, Accuracy: 49.1, Precision: 0.55, Recall: 0.41\n",
            "Epoch: 0, Batch: 1150, Loss: 0.7197373420000076, Accuracy: 50.12, Precision: 0.51, Recall: 0.56\n",
            "Epoch: 0, Batch: 1160, Loss: 0.5893236815929412, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 1170, Loss: 0.6341364622116089, Accuracy: 50.64, Precision: 0.46, Recall: 0.42\n",
            "Epoch: 0, Batch: 1180, Loss: 0.578765144944191, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 1190, Loss: 0.6650451600551606, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 1200, Loss: 0.6004523903131485, Accuracy: 52.64, Precision: 0.39, Recall: 0.38\n",
            "Epoch: 0, Batch: 1210, Loss: 0.5959017902612687, Accuracy: 50.0, Precision: 0.5, Recall: 0.32\n",
            "Epoch: 0, Batch: 1220, Loss: 0.6097481459379196, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 1230, Loss: 0.6229568809270859, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 1240, Loss: 0.5700879245996475, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 1250, Loss: 0.5802424430847168, Accuracy: 50.84, Precision: 0.47, Recall: 0.36\n",
            "Epoch: 0, Batch: 1260, Loss: 0.5517285287380218, Accuracy: 50.5, Precision: 0.55, Recall: 0.55\n",
            "Epoch: 0, Batch: 1270, Loss: 0.6268911242485047, Accuracy: 49.64, Precision: 0.48, Recall: 0.59\n",
            "Epoch: 0, Batch: 1280, Loss: 0.6329769343137741, Accuracy: 50.42, Precision: 0.49, Recall: 0.29\n",
            "Epoch: 0, Batch: 1290, Loss: 0.626999917626381, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 1300, Loss: 0.6580977767705918, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 1310, Loss: 0.5853640854358673, Accuracy: 49.28, Precision: 0.56, Recall: 0.44\n",
            "Epoch: 0, Batch: 1320, Loss: 0.6481115520000458, Accuracy: 50.78, Precision: 0.53, Recall: 0.63\n",
            "Epoch: 0, Batch: 1330, Loss: 0.5509303867816925, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 1340, Loss: 0.5849961668252945, Accuracy: 49.92, Precision: 0.46, Recall: 0.51\n",
            "Epoch: 0, Batch: 1350, Loss: 0.621814900636673, Accuracy: 50.16, Precision: 0.49, Recall: 0.42\n",
            "Epoch: 0, Batch: 1360, Loss: 0.5716056555509568, Accuracy: 50.0, Precision: 0.5, Recall: 0.42\n",
            "Epoch: 0, Batch: 1370, Loss: 0.6060872733592987, Accuracy: 50.12, Precision: 0.49, Recall: 0.44\n",
            "Epoch: 0, Batch: 1380, Loss: 0.6171036243438721, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 1390, Loss: 0.61211456656456, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 1400, Loss: 0.6557743221521377, Accuracy: 50.0, Precision: 0.5, Recall: 0.38\n",
            "Epoch: 0, Batch: 1410, Loss: 0.5795044243335724, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 1420, Loss: 0.6043730020523072, Accuracy: 49.6, Precision: 0.46, Recall: 0.55\n",
            "Epoch: 0, Batch: 1430, Loss: 0.6137946128845215, Accuracy: 50.2, Precision: 0.49, Recall: 0.4\n",
            "Epoch: 0, Batch: 1440, Loss: 0.575811293721199, Accuracy: 49.58, Precision: 0.53, Recall: 0.43\n",
            "Epoch: 0, Batch: 1450, Loss: 0.5941393196582794, Accuracy: 49.64, Precision: 0.44, Recall: 0.53\n",
            "Epoch: 0, Batch: 1460, Loss: 0.5741213738918305, Accuracy: 49.68, Precision: 0.52, Recall: 0.42\n",
            "Epoch: 0, Batch: 1470, Loss: 0.5450667709112167, Accuracy: 50.28, Precision: 0.57, Recall: 0.52\n",
            "Epoch: 0, Batch: 1480, Loss: 0.622374826669693, Accuracy: 49.52, Precision: 0.48, Recall: 0.62\n",
            "Epoch: 0, Batch: 1490, Loss: 0.6130160748958587, Accuracy: 49.46, Precision: 0.53, Recall: 0.41\n",
            "Epoch: 0, Batch: 1500, Loss: 0.5613382816314697, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 1510, Loss: 0.5938510507345199, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 1520, Loss: 0.5936102449893952, Accuracy: 51.44, Precision: 0.42, Recall: 0.41\n",
            "Epoch: 0, Batch: 1530, Loss: 0.5463647961616516, Accuracy: 50.92, Precision: 0.48, Recall: 0.27\n",
            "Epoch: 0, Batch: 1540, Loss: 0.6712945371866226, Accuracy: 48.72, Precision: 0.46, Recall: 0.66\n",
            "Epoch: 0, Batch: 1550, Loss: 0.5421578109264373, Accuracy: 50.0, Precision: 0.5, Recall: 0.36\n",
            "Epoch: 0, Batch: 1560, Loss: 0.5702613145112991, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 1570, Loss: 0.506029212474823, Accuracy: 50.4, Precision: 0.52, Recall: 0.6\n",
            "Epoch: 0, Batch: 1580, Loss: 0.5663165271282196, Accuracy: 51.32, Precision: 0.44, Recall: 0.39\n",
            "Epoch: 0, Batch: 1590, Loss: 0.5151415050029755, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 1600, Loss: 0.6362356275320054, Accuracy: 49.78, Precision: 0.51, Recall: 0.39\n",
            "Epoch: 0, Batch: 1610, Loss: 0.6311804324388504, Accuracy: 50.22, Precision: 0.51, Recall: 0.61\n",
            "Epoch: 0, Batch: 1620, Loss: 0.578399658203125, Accuracy: 51.02, Precision: 0.47, Recall: 0.33\n",
            "Epoch: 0, Batch: 1630, Loss: 0.5349593818187713, Accuracy: 49.7, Precision: 0.53, Recall: 0.45\n",
            "Epoch: 0, Batch: 1640, Loss: 0.7767381489276886, Accuracy: 49.36, Precision: 0.48, Recall: 0.66\n",
            "Epoch: 0, Batch: 1650, Loss: 0.5980170965194702, Accuracy: 50.9, Precision: 0.47, Recall: 0.35\n",
            "Epoch: 0, Batch: 1660, Loss: 0.5949662148952484, Accuracy: 52.94, Precision: 0.43, Recall: 0.29\n",
            "Epoch: 0, Batch: 1670, Loss: 0.5594506591558457, Accuracy: 50.88, Precision: 0.46, Recall: 0.39\n",
            "Epoch: 0, Batch: 1680, Loss: 0.6366548657417297, Accuracy: 51.6, Precision: 0.58, Recall: 0.6\n",
            "Epoch: 0, Batch: 1690, Loss: 0.5652190327644349, Accuracy: 50.24, Precision: 0.46, Recall: 0.47\n",
            "Epoch: 0, Batch: 1700, Loss: 0.5910500377416611, Accuracy: 52.4, Precision: 0.45, Recall: 0.26\n",
            "Epoch: 0, Batch: 1710, Loss: 0.5477235287427902, Accuracy: 50.48, Precision: 0.48, Recall: 0.38\n",
            "Epoch: 0, Batch: 1720, Loss: 0.6313701748847962, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 1730, Loss: 0.5685928732156753, Accuracy: 51.68, Precision: 0.56, Recall: 0.64\n",
            "Epoch: 0, Batch: 1740, Loss: 0.561193260550499, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 1750, Loss: 0.7097097277641297, Accuracy: 49.56, Precision: 0.51, Recall: 0.28\n",
            "Epoch: 0, Batch: 1760, Loss: 0.6070776760578156, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 1770, Loss: 0.5453171521425247, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 1780, Loss: 0.6088070273399353, Accuracy: 49.76, Precision: 0.49, Recall: 0.62\n",
            "Epoch: 0, Batch: 1790, Loss: 0.6291312009096146, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 1800, Loss: 0.5773008376359939, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 1810, Loss: 0.6290554612874985, Accuracy: 50.56, Precision: 0.43, Recall: 0.46\n",
            "Epoch: 0, Batch: 1820, Loss: 0.5545758724212646, Accuracy: 53.42, Precision: 0.41, Recall: 0.31\n",
            "Epoch: 0, Batch: 1830, Loss: 0.6447688907384872, Accuracy: 51.7, Precision: 0.45, Recall: 0.33\n",
            "Epoch: 0, Batch: 1840, Loss: 0.5431463956832886, Accuracy: 51.12, Precision: 0.46, Recall: 0.36\n",
            "Epoch: 0, Batch: 1850, Loss: 0.5782934844493866, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 1860, Loss: 0.6258912712335587, Accuracy: 50.08, Precision: 0.46, Recall: 0.49\n",
            "Epoch: 0, Batch: 1870, Loss: 0.5722823292016983, Accuracy: 50.4, Precision: 0.48, Recall: 0.4\n",
            "Epoch: 0, Batch: 1880, Loss: 0.5396036118268966, Accuracy: 50.6, Precision: 0.48, Recall: 0.35\n",
            "Epoch: 0, Batch: 1890, Loss: 0.6210374623537064, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 1900, Loss: 0.6316388040781021, Accuracy: 50.22, Precision: 0.49, Recall: 0.39\n",
            "Epoch: 0, Batch: 1910, Loss: 0.6357801377773284, Accuracy: 50.56, Precision: 0.48, Recall: 0.36\n",
            "Epoch: 0, Batch: 1920, Loss: 0.6314828038215637, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 1930, Loss: 0.5397207170724869, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 1940, Loss: 0.605765038728714, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 1950, Loss: 0.5899111032485962, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 1960, Loss: 0.6320167273283005, Accuracy: 49.72, Precision: 0.48, Recall: 0.57\n",
            "Epoch: 0, Batch: 1970, Loss: 0.5272779345512391, Accuracy: 51.2, Precision: 0.46, Recall: 0.35\n",
            "Epoch: 0, Batch: 1980, Loss: 0.5919874668121338, Accuracy: 50.0, Precision: 0.55, Recall: 0.5\n",
            "Epoch: 0, Batch: 1990, Loss: 0.5912538051605225, Accuracy: 50.8, Precision: 0.54, Recall: 0.6\n",
            "Epoch: 0, Batch: 2000, Loss: 0.636773806810379, Accuracy: 49.96, Precision: 0.51, Recall: 0.48\n",
            "Epoch: 0, Batch: 2010, Loss: 0.5595978736877442, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 2020, Loss: 0.5437806934118271, Accuracy: 50.14, Precision: 0.43, Recall: 0.49\n",
            "Epoch: 0, Batch: 2030, Loss: 0.5961437165737152, Accuracy: 51.28, Precision: 0.58, Recall: 0.58\n",
            "Epoch: 0, Batch: 2040, Loss: 0.5926461488008499, Accuracy: 49.6, Precision: 0.48, Recall: 0.6\n",
            "Epoch: 0, Batch: 2050, Loss: 0.5316157460212707, Accuracy: 49.8, Precision: 0.6, Recall: 0.49\n",
            "Epoch: 0, Batch: 2060, Loss: 0.628018257021904, Accuracy: 48.56, Precision: 0.41, Recall: 0.58\n",
            "Epoch: 0, Batch: 2070, Loss: 0.6140491485595703, Accuracy: 49.56, Precision: 0.52, Recall: 0.39\n",
            "Epoch: 0, Batch: 2080, Loss: 0.5553565949201584, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 2090, Loss: 0.5309246838092804, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 2100, Loss: 0.6077976852655411, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 2110, Loss: 0.6269043385982513, Accuracy: 49.28, Precision: 0.44, Recall: 0.56\n",
            "Epoch: 0, Batch: 2120, Loss: 0.6544649451971054, Accuracy: 48.92, Precision: 0.53, Recall: 0.32\n",
            "Epoch: 0, Batch: 2130, Loss: 0.5446774899959564, Accuracy: 50.2, Precision: 0.45, Recall: 0.48\n",
            "Epoch: 0, Batch: 2140, Loss: 0.6053823828697205, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 2150, Loss: 0.61995709836483, Accuracy: 52.72, Precision: 0.42, Recall: 0.33\n",
            "Epoch: 0, Batch: 2160, Loss: 0.589380931854248, Accuracy: 49.44, Precision: 0.52, Recall: 0.36\n",
            "Epoch: 0, Batch: 2170, Loss: 0.6063277840614318, Accuracy: 50.42, Precision: 0.57, Recall: 0.53\n",
            "Epoch: 0, Batch: 2180, Loss: 0.5347591429948807, Accuracy: 50.72, Precision: 0.54, Recall: 0.59\n",
            "Epoch: 0, Batch: 2190, Loss: 0.6140495896339416, Accuracy: 52.34, Precision: 0.41, Recall: 0.37\n",
            "Epoch: 0, Batch: 2200, Loss: 0.6336836576461792, Accuracy: 50.0, Precision: 0.5, Recall: 0.29\n",
            "Epoch: 0, Batch: 2210, Loss: 0.5833898901939392, Accuracy: 50.64, Precision: 0.58, Recall: 0.54\n",
            "Epoch: 0, Batch: 2220, Loss: 0.5922827005386353, Accuracy: 52.24, Precision: 0.57, Recall: 0.66\n",
            "Epoch: 0, Batch: 2230, Loss: 0.5974955946207047, Accuracy: 50.42, Precision: 0.57, Recall: 0.53\n",
            "Epoch: 0, Batch: 2240, Loss: 0.541422215104103, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 2250, Loss: 0.5876572459936142, Accuracy: 49.82, Precision: 0.51, Recall: 0.41\n",
            "Epoch: 0, Batch: 2260, Loss: 0.5537789732217788, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 2270, Loss: 0.7023093581199646, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 2280, Loss: 0.649335703253746, Accuracy: 47.58, Precision: 0.61, Recall: 0.39\n",
            "Epoch: 0, Batch: 2290, Loss: 0.6059215098619462, Accuracy: 50.22, Precision: 0.51, Recall: 0.61\n",
            "Epoch: 0, Batch: 2300, Loss: 0.6084337294101715, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 2310, Loss: 0.6210117280483246, Accuracy: 51.52, Precision: 0.46, Recall: 0.31\n",
            "Epoch: 0, Batch: 2320, Loss: 0.5695236146450042, Accuracy: 56.72, Precision: 0.36, Recall: 0.26\n",
            "Epoch: 0, Batch: 2330, Loss: 0.5980806618928909, Accuracy: 48.8, Precision: 0.53, Recall: 0.3\n",
            "Epoch: 0, Batch: 2340, Loss: 0.611797446012497, Accuracy: 50.26, Precision: 0.51, Recall: 0.63\n",
            "Epoch: 0, Batch: 2350, Loss: 0.5621124297380448, Accuracy: 50.28, Precision: 0.49, Recall: 0.36\n",
            "Epoch: 0, Batch: 2360, Loss: 0.5821957737207413, Accuracy: 50.42, Precision: 0.57, Recall: 0.53\n",
            "Epoch: 0, Batch: 2370, Loss: 0.5280679166316986, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 2380, Loss: 0.6039650529623032, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 2390, Loss: 0.623212319612503, Accuracy: 49.4, Precision: 0.55, Recall: 0.44\n",
            "Epoch: 0, Batch: 2400, Loss: 0.6145153522491456, Accuracy: 50.24, Precision: 0.52, Recall: 0.56\n",
            "Epoch: 0, Batch: 2410, Loss: 0.5760619282722473, Accuracy: 50.3, Precision: 0.53, Recall: 0.55\n",
            "Epoch: 0, Batch: 2420, Loss: 0.6320670485496521, Accuracy: 49.44, Precision: 0.52, Recall: 0.36\n",
            "Epoch: 0, Batch: 2430, Loss: 0.582456985116005, Accuracy: 53.04, Precision: 0.42, Recall: 0.31\n",
            "Epoch: 0, Batch: 2440, Loss: 0.5484313130378723, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 2450, Loss: 0.5538840621709824, Accuracy: 50.36, Precision: 0.49, Recall: 0.32\n",
            "Epoch: 0, Batch: 2460, Loss: 0.5449026674032211, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 2470, Loss: 0.4883023023605347, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 2480, Loss: 0.5216010481119155, Accuracy: 51.76, Precision: 0.61, Recall: 0.58\n",
            "Epoch: 0, Batch: 2490, Loss: 0.7540435791015625, Accuracy: 50.2, Precision: 0.4, Recall: 0.49\n",
            "Epoch: 0, Batch: 2500, Loss: 0.6190321564674377, Accuracy: 48.56, Precision: 0.59, Recall: 0.42\n",
            "Epoch: 0, Batch: 2510, Loss: 0.6476894736289978, Accuracy: 49.76, Precision: 0.49, Recall: 0.62\n",
            "Epoch: 0, Batch: 2520, Loss: 0.5893163651227951, Accuracy: 50.88, Precision: 0.46, Recall: 0.39\n",
            "Epoch: 0, Batch: 2530, Loss: 0.5834315896034241, Accuracy: 50.78, Precision: 0.47, Recall: 0.37\n",
            "Epoch: 0, Batch: 2540, Loss: 0.5530583202838898, Accuracy: 50.24, Precision: 0.49, Recall: 0.38\n",
            "Epoch: 0, Batch: 2550, Loss: 0.5379533559083939, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 2560, Loss: 0.5977189391851425, Accuracy: 49.64, Precision: 0.53, Recall: 0.44\n",
            "Epoch: 0, Batch: 2570, Loss: 0.5912516981363296, Accuracy: 49.86, Precision: 0.43, Recall: 0.51\n",
            "Epoch: 0, Batch: 2580, Loss: 0.6176448464393616, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 2590, Loss: 0.5382349967956543, Accuracy: 50.36, Precision: 0.59, Recall: 0.52\n",
            "Epoch: 0, Batch: 2600, Loss: 0.6233788698911666, Accuracy: 51.2, Precision: 0.56, Recall: 0.6\n",
            "Epoch: 0, Batch: 2610, Loss: 0.5860155105590821, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 2620, Loss: 0.5482860714197159, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 2630, Loss: 0.5686898618936539, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 2640, Loss: 0.5527939587831497, Accuracy: 50.7, Precision: 0.57, Recall: 0.55\n",
            "Epoch: 0, Batch: 2650, Loss: 0.5711887508630753, Accuracy: 49.7, Precision: 0.45, Recall: 0.53\n",
            "Epoch: 0, Batch: 2660, Loss: 0.5800738990306854, Accuracy: 49.3, Precision: 0.57, Recall: 0.45\n",
            "Epoch: 0, Batch: 2670, Loss: 0.5202756315469742, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 2680, Loss: 0.6781575322151184, Accuracy: 50.96, Precision: 0.44, Recall: 0.42\n",
            "Epoch: 0, Batch: 2690, Loss: 0.5295010209083557, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 2700, Loss: 0.6160844534635543, Accuracy: 51.5, Precision: 0.45, Recall: 0.35\n",
            "Epoch: 0, Batch: 2710, Loss: 0.6035485357046128, Accuracy: 50.0, Precision: 0.59, Recall: 0.5\n",
            "Epoch: 0, Batch: 2720, Loss: 0.5467359244823455, Accuracy: 51.4, Precision: 0.43, Recall: 0.4\n",
            "Epoch: 0, Batch: 2730, Loss: 0.5889094442129135, Accuracy: 51.2, Precision: 0.44, Recall: 0.4\n",
            "Epoch: 0, Batch: 2740, Loss: 0.5750892519950866, Accuracy: 51.2, Precision: 0.47, Recall: 0.3\n",
            "Epoch: 0, Batch: 2750, Loss: 0.48364914357662203, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 2760, Loss: 0.6146572291851043, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 2770, Loss: 0.5504280656576157, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 2780, Loss: 0.5570470780134201, Accuracy: 50.12, Precision: 0.56, Recall: 0.51\n",
            "Epoch: 0, Batch: 2790, Loss: 0.6139497935771943, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 2800, Loss: 0.5155507951974869, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 2810, Loss: 0.5342657476663589, Accuracy: 50.0, Precision: 0.5, Recall: 0.39\n",
            "Epoch: 0, Batch: 2820, Loss: 0.5499536037445069, Accuracy: 51.2, Precision: 0.56, Recall: 0.6\n",
            "Epoch: 0, Batch: 2830, Loss: 0.6275585025548935, Accuracy: 49.52, Precision: 0.48, Recall: 0.62\n",
            "Epoch: 0, Batch: 2840, Loss: 0.613105058670044, Accuracy: 47.9, Precision: 0.55, Recall: 0.29\n",
            "Epoch: 0, Batch: 2850, Loss: 0.5053783744573593, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 2860, Loss: 0.561467757821083, Accuracy: 50.64, Precision: 0.46, Recall: 0.42\n",
            "Epoch: 0, Batch: 2870, Loss: 0.6496080458164215, Accuracy: 50.4, Precision: 0.49, Recall: 0.3\n",
            "Epoch: 0, Batch: 2880, Loss: 0.7163003981113434, Accuracy: 50.0, Precision: 0.55, Recall: 0.5\n",
            "Epoch: 0, Batch: 2890, Loss: 0.5200160712003707, Accuracy: 50.4, Precision: 0.52, Recall: 0.6\n",
            "Epoch: 0, Batch: 2900, Loss: 0.5506417006254196, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 2910, Loss: 0.6179536312818528, Accuracy: 50.0, Precision: 0.56, Recall: 0.5\n",
            "Epoch: 0, Batch: 2920, Loss: 0.5633765935897828, Accuracy: 49.3, Precision: 0.45, Recall: 0.57\n",
            "Epoch: 0, Batch: 2930, Loss: 0.5238021314144135, Accuracy: 50.0, Precision: 0.56, Recall: 0.5\n",
            "Epoch: 0, Batch: 2940, Loss: 0.5731442749500275, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 2950, Loss: 0.5141425937414169, Accuracy: 50.64, Precision: 0.58, Recall: 0.54\n",
            "Epoch: 0, Batch: 2960, Loss: 0.5834845632314682, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 2970, Loss: 0.5684795647859573, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 2980, Loss: 0.5423060923814773, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 2990, Loss: 0.5375021725893021, Accuracy: 50.8, Precision: 0.55, Recall: 0.58\n",
            "Epoch: 0, Batch: 3000, Loss: 0.5835905849933625, Accuracy: 50.8, Precision: 0.4, Recall: 0.46\n",
            "Epoch: 0, Batch: 3010, Loss: 0.6375717252492905, Accuracy: 49.52, Precision: 0.53, Recall: 0.42\n",
            "Epoch: 0, Batch: 3020, Loss: 0.5430888921022415, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 3030, Loss: 0.5787083476781845, Accuracy: 50.18, Precision: 0.49, Recall: 0.41\n",
            "Epoch: 0, Batch: 3040, Loss: 0.5695124864578247, Accuracy: 50.84, Precision: 0.47, Recall: 0.36\n",
            "Epoch: 0, Batch: 3050, Loss: 0.5504191547632218, Accuracy: 50.12, Precision: 0.51, Recall: 0.56\n",
            "Epoch: 0, Batch: 3060, Loss: 0.5546735972166061, Accuracy: 51.7, Precision: 0.45, Recall: 0.33\n",
            "Epoch: 0, Batch: 3070, Loss: 0.5528852939605713, Accuracy: 51.1, Precision: 0.45, Recall: 0.39\n",
            "Epoch: 0, Batch: 3080, Loss: 0.5568874090909958, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 3090, Loss: 0.4660510867834091, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 3100, Loss: 0.5634153962135315, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 3110, Loss: 0.521166005730629, Accuracy: 49.6, Precision: 0.54, Recall: 0.45\n",
            "Epoch: 0, Batch: 3120, Loss: 0.5267362028360367, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 3130, Loss: 0.6289493560791015, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 3140, Loss: 0.5838490933179855, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 3150, Loss: 0.5364085108041763, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 3160, Loss: 0.5732077628374099, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 3170, Loss: 0.5676789730787277, Accuracy: 49.88, Precision: 0.52, Recall: 0.47\n",
            "Epoch: 0, Batch: 3180, Loss: 0.5559382826089859, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 3190, Loss: 0.6003918141126633, Accuracy: 52.38, Precision: 0.43, Recall: 0.33\n",
            "Epoch: 0, Batch: 3200, Loss: 0.5994214296340943, Accuracy: 50.72, Precision: 0.47, Recall: 0.38\n",
            "Epoch: 0, Batch: 3210, Loss: 0.5619522482156754, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "Epoch: 0, Batch: 3220, Loss: 0.5445009410381317, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 3230, Loss: 0.5483513653278351, Accuracy: 52.0, Precision: 0.6, Recall: 0.6\n",
            "Epoch: 0, Batch: 3240, Loss: 0.5833607465028763, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 3250, Loss: 0.5257540345191956, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 3260, Loss: 0.5439447492361069, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 3270, Loss: 0.6106808245182037, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 3280, Loss: 0.5150181412696838, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 3290, Loss: 0.5522137671709061, Accuracy: 50.52, Precision: 0.48, Recall: 0.37\n",
            "Epoch: 0, Batch: 3300, Loss: 0.5785079538822174, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 3310, Loss: 0.48421789705753326, Accuracy: 50.7, Precision: 0.55, Recall: 0.57\n",
            "Epoch: 0, Batch: 3320, Loss: 0.5547295212745667, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 3330, Loss: 0.4735481649637222, Accuracy: 50.36, Precision: 0.44, Recall: 0.47\n",
            "Epoch: 0, Batch: 3340, Loss: 0.5604265913367271, Accuracy: 51.7, Precision: 0.45, Recall: 0.33\n",
            "Epoch: 0, Batch: 3350, Loss: 0.5017997771501541, Accuracy: 52.24, Precision: 0.43, Recall: 0.34\n",
            "Epoch: 0, Batch: 3360, Loss: 0.49588417410850527, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 3370, Loss: 0.6233328849077224, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 3380, Loss: 0.5491178631782532, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 3390, Loss: 0.5338541209697724, Accuracy: 49.58, Precision: 0.57, Recall: 0.47\n",
            "Epoch: 0, Batch: 3400, Loss: 0.5783480882644654, Accuracy: 50.2, Precision: 0.51, Recall: 0.6\n",
            "Epoch: 0, Batch: 3410, Loss: 0.5207806050777435, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 3420, Loss: 0.5684368729591369, Accuracy: 50.1, Precision: 0.49, Recall: 0.45\n",
            "Epoch: 0, Batch: 3430, Loss: 0.5004184514284133, Accuracy: 51.32, Precision: 0.39, Recall: 0.44\n",
            "Epoch: 0, Batch: 3440, Loss: 0.5833477556705475, Accuracy: 50.0, Precision: 0.5, Recall: 0.39\n",
            "Epoch: 0, Batch: 3450, Loss: 0.5307770580053329, Accuracy: 50.44, Precision: 0.48, Recall: 0.39\n",
            "Epoch: 0, Batch: 3460, Loss: 0.6435184240341186, Accuracy: 50.28, Precision: 0.57, Recall: 0.52\n",
            "Epoch: 0, Batch: 3470, Loss: 0.5359960287809372, Accuracy: 50.14, Precision: 0.51, Recall: 0.57\n",
            "Epoch: 0, Batch: 3480, Loss: 0.6003848046064377, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 3490, Loss: 0.6092427611351013, Accuracy: 49.56, Precision: 0.52, Recall: 0.39\n",
            "Epoch: 0, Batch: 3500, Loss: 0.5418202012777329, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 3510, Loss: 0.5080386877059937, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 3520, Loss: 0.5324398547410965, Accuracy: 50.98, Precision: 0.57, Recall: 0.57\n",
            "Epoch: 0, Batch: 3530, Loss: 0.4928410202264786, Accuracy: 50.56, Precision: 0.43, Recall: 0.46\n",
            "Epoch: 0, Batch: 3540, Loss: 0.6233767092227935, Accuracy: 49.4, Precision: 0.55, Recall: 0.44\n",
            "Epoch: 0, Batch: 3550, Loss: 0.54071604013443, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 3560, Loss: 0.49959867298603056, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 3570, Loss: 0.5769028723239898, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 3580, Loss: 0.5533186107873916, Accuracy: 50.4, Precision: 0.55, Recall: 0.54\n",
            "Epoch: 0, Batch: 3590, Loss: 0.588958153128624, Accuracy: 50.56, Precision: 0.57, Recall: 0.54\n",
            "Epoch: 0, Batch: 3600, Loss: 0.5256238430738449, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 3610, Loss: 0.5059201866388321, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 3620, Loss: 0.5874485284090042, Accuracy: 50.48, Precision: 0.62, Recall: 0.52\n",
            "Epoch: 0, Batch: 3630, Loss: 0.6119560360908508, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 3640, Loss: 0.5948007106781006, Accuracy: 51.2, Precision: 0.55, Recall: 0.62\n",
            "Epoch: 0, Batch: 3650, Loss: 0.5687652319669724, Accuracy: 50.96, Precision: 0.46, Recall: 0.38\n",
            "Epoch: 0, Batch: 3660, Loss: 0.6262675315141678, Accuracy: 50.12, Precision: 0.49, Recall: 0.44\n",
            "Epoch: 0, Batch: 3670, Loss: 0.5781353205442429, Accuracy: 51.2, Precision: 0.45, Recall: 0.38\n",
            "Epoch: 0, Batch: 3680, Loss: 0.5451985239982605, Accuracy: 51.6, Precision: 0.6, Recall: 0.58\n",
            "Epoch: 0, Batch: 3690, Loss: 0.4944033414125443, Accuracy: 53.2, Precision: 0.6, Recall: 0.66\n",
            "Epoch: 0, Batch: 3700, Loss: 0.5539284855127334, Accuracy: 52.0, Precision: 0.55, Recall: 0.7\n",
            "Epoch: 0, Batch: 3710, Loss: 0.6078485667705535, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 3720, Loss: 0.5290087163448334, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 3730, Loss: 0.5466701179742813, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 3740, Loss: 0.5509549885988235, Accuracy: 50.24, Precision: 0.44, Recall: 0.48\n",
            "Epoch: 0, Batch: 3750, Loss: 0.5275842100381851, Accuracy: 49.28, Precision: 0.56, Recall: 0.44\n",
            "Epoch: 0, Batch: 3760, Loss: 0.6451196938753128, Accuracy: 51.6, Precision: 0.54, Recall: 0.7\n",
            "Epoch: 0, Batch: 3770, Loss: 0.6245390802621842, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 3780, Loss: 0.5448245048522949, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 3790, Loss: 0.569047600030899, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 3800, Loss: 0.5932274401187897, Accuracy: 51.3, Precision: 0.45, Recall: 0.37\n",
            "Epoch: 0, Batch: 3810, Loss: 0.522003248333931, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 3820, Loss: 0.557843342423439, Accuracy: 50.08, Precision: 0.46, Recall: 0.49\n",
            "Epoch: 0, Batch: 3830, Loss: 0.6298249900341034, Accuracy: 51.02, Precision: 0.47, Recall: 0.33\n",
            "Epoch: 0, Batch: 3840, Loss: 0.5072757780551911, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 3850, Loss: 0.5517538249492645, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 3860, Loss: 0.5871346056461334, Accuracy: 49.9, Precision: 0.55, Recall: 0.49\n",
            "Epoch: 0, Batch: 3870, Loss: 0.6144275605678559, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 3880, Loss: 0.5010770589113236, Accuracy: 49.86, Precision: 0.49, Recall: 0.57\n",
            "Epoch: 0, Batch: 3890, Loss: 0.525249844789505, Accuracy: 50.7, Precision: 0.57, Recall: 0.55\n",
            "Epoch: 0, Batch: 3900, Loss: 0.5083170682191849, Accuracy: 50.64, Precision: 0.54, Recall: 0.58\n",
            "Epoch: 0, Batch: 3910, Loss: 0.5543734550476074, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 3920, Loss: 0.5441858619451523, Accuracy: 49.96, Precision: 0.51, Recall: 0.48\n",
            "Epoch: 0, Batch: 3930, Loss: 0.5431293547153473, Accuracy: 51.44, Precision: 0.42, Recall: 0.41\n",
            "Epoch: 0, Batch: 3940, Loss: 0.5532012045383453, Accuracy: 49.82, Precision: 0.59, Recall: 0.49\n",
            "Epoch: 0, Batch: 3950, Loss: 0.5925388514995575, Accuracy: 50.28, Precision: 0.51, Recall: 0.64\n",
            "Epoch: 0, Batch: 3960, Loss: 0.5179074466228485, Accuracy: 49.9, Precision: 0.55, Recall: 0.49\n",
            "Epoch: 0, Batch: 3970, Loss: 0.48827494978904723, Accuracy: 50.06, Precision: 0.53, Recall: 0.51\n",
            "Epoch: 0, Batch: 3980, Loss: 0.5489812135696411, Accuracy: 50.42, Precision: 0.57, Recall: 0.53\n",
            "Epoch: 0, Batch: 3990, Loss: 0.5262753516435623, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 4000, Loss: 0.4713531076908112, Accuracy: 51.32, Precision: 0.56, Recall: 0.61\n",
            "Epoch: 0, Batch: 4010, Loss: 0.4946806952357292, Accuracy: 49.8, Precision: 0.48, Recall: 0.55\n",
            "Epoch: 0, Batch: 4020, Loss: 0.5294982522726059, Accuracy: 50.84, Precision: 0.47, Recall: 0.36\n",
            "Epoch: 0, Batch: 4030, Loss: 0.4863847464323044, Accuracy: 51.76, Precision: 0.39, Recall: 0.42\n",
            "Epoch: 0, Batch: 4040, Loss: 0.5227420777082443, Accuracy: 48.88, Precision: 0.54, Recall: 0.36\n",
            "Epoch: 0, Batch: 4050, Loss: 0.6373823314905167, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 4060, Loss: 0.4680445969104767, Accuracy: 49.88, Precision: 0.49, Recall: 0.56\n",
            "Epoch: 0, Batch: 4070, Loss: 0.5635375767946244, Accuracy: 49.7, Precision: 0.55, Recall: 0.47\n",
            "Epoch: 0, Batch: 4080, Loss: 0.5547309547662735, Accuracy: 49.84, Precision: 0.46, Recall: 0.52\n",
            "Epoch: 0, Batch: 4090, Loss: 0.5796186536550522, Accuracy: 50.0, Precision: 0.5, Recall: 0.4\n",
            "Epoch: 0, Batch: 4100, Loss: 0.4936768114566803, Accuracy: 50.5, Precision: 0.55, Recall: 0.55\n",
            "Epoch: 0, Batch: 4110, Loss: 0.6295800626277923, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 4120, Loss: 0.5590404003858567, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 4130, Loss: 0.5457119524478913, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 4140, Loss: 0.6125311195850373, Accuracy: 50.0, Precision: 0.5, Recall: 0.36\n",
            "Epoch: 0, Batch: 4150, Loss: 0.589607959985733, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 4160, Loss: 0.6132096707820892, Accuracy: 51.1, Precision: 0.45, Recall: 0.39\n",
            "Epoch: 0, Batch: 4170, Loss: 0.6189389199018478, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 4180, Loss: 0.5006656885147095, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 4190, Loss: 0.6048050850629807, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 4200, Loss: 0.5147717744112015, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 4210, Loss: 0.4488112092018127, Accuracy: 50.1, Precision: 0.51, Recall: 0.55\n",
            "Epoch: 0, Batch: 4220, Loss: 0.5023495942354202, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 4230, Loss: 0.5965752184391022, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 4240, Loss: 0.6200673192739486, Accuracy: 50.48, Precision: 0.54, Recall: 0.56\n",
            "Epoch: 0, Batch: 4250, Loss: 0.610704192519188, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 4260, Loss: 0.5800102919340133, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 4270, Loss: 0.5741417080163955, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 4280, Loss: 0.5661189615726471, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 4290, Loss: 0.6423688888549804, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 4300, Loss: 0.558741208910942, Accuracy: 50.48, Precision: 0.48, Recall: 0.38\n",
            "Epoch: 0, Batch: 4310, Loss: 0.5911999374628067, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 4320, Loss: 0.535463759303093, Accuracy: 50.56, Precision: 0.52, Recall: 0.64\n",
            "Epoch: 0, Batch: 4330, Loss: 0.5515908181667328, Accuracy: 51.62, Precision: 0.59, Recall: 0.59\n",
            "Epoch: 0, Batch: 4340, Loss: 0.5817571699619293, Accuracy: 50.0, Precision: 0.5, Recall: 0.61\n",
            "Epoch: 0, Batch: 4350, Loss: 0.5466876775026321, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 4360, Loss: 0.5839670836925507, Accuracy: 52.72, Precision: 0.42, Recall: 0.33\n",
            "Epoch: 0, Batch: 4370, Loss: 0.4632876068353653, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 4380, Loss: 0.4958865523338318, Accuracy: 53.0, Precision: 0.4, Recall: 0.35\n",
            "Epoch: 0, Batch: 4390, Loss: 0.5514141678810119, Accuracy: 51.12, Precision: 0.43, Recall: 0.42\n",
            "Epoch: 0, Batch: 4400, Loss: 0.5364357829093933, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 4410, Loss: 0.5879139542579651, Accuracy: 49.92, Precision: 0.51, Recall: 0.46\n",
            "Epoch: 0, Batch: 4420, Loss: 0.5887359619140625, Accuracy: 50.96, Precision: 0.54, Recall: 0.62\n",
            "Epoch: 0, Batch: 4430, Loss: 0.5295990854501724, Accuracy: 51.12, Precision: 0.43, Recall: 0.42\n",
            "Epoch: 0, Batch: 4440, Loss: 0.5298431634902954, Accuracy: 50.64, Precision: 0.48, Recall: 0.34\n",
            "Epoch: 0, Batch: 4450, Loss: 0.4389766439795494, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 4460, Loss: 0.6557430803775788, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 4470, Loss: 0.5548428744077682, Accuracy: 50.36, Precision: 0.49, Recall: 0.32\n",
            "Epoch: 0, Batch: 4480, Loss: 0.5658911943435669, Accuracy: 51.54, Precision: 0.57, Recall: 0.61\n",
            "Epoch: 0, Batch: 4490, Loss: 0.5297348707914352, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 4500, Loss: 0.5543564707040787, Accuracy: 49.88, Precision: 0.51, Recall: 0.44\n",
            "Epoch: 0, Batch: 4510, Loss: 0.4721387982368469, Accuracy: 49.7, Precision: 0.45, Recall: 0.53\n",
            "Epoch: 0, Batch: 4520, Loss: 0.4640749007463455, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 4530, Loss: 0.5497328281402588, Accuracy: 49.86, Precision: 0.57, Recall: 0.49\n",
            "Epoch: 0, Batch: 4540, Loss: 0.5264733552932739, Accuracy: 49.6, Precision: 0.48, Recall: 0.6\n",
            "Epoch: 0, Batch: 4550, Loss: 0.5045813322067261, Accuracy: 50.12, Precision: 0.52, Recall: 0.53\n",
            "Epoch: 0, Batch: 4560, Loss: 0.6358456492424012, Accuracy: 49.68, Precision: 0.52, Recall: 0.42\n",
            "Epoch: 0, Batch: 4570, Loss: 0.6520492106676101, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 4580, Loss: 0.5420755594968796, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 4590, Loss: 0.516819429397583, Accuracy: 50.56, Precision: 0.48, Recall: 0.36\n",
            "Epoch: 0, Batch: 4600, Loss: 0.4929418295621872, Accuracy: 51.8, Precision: 0.41, Recall: 0.4\n",
            "Epoch: 0, Batch: 4610, Loss: 0.6118105679750443, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 4620, Loss: 0.5343696773052216, Accuracy: 50.3, Precision: 0.47, Recall: 0.45\n",
            "Epoch: 0, Batch: 4630, Loss: 0.5205452293157578, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 4640, Loss: 0.5654327392578125, Accuracy: 50.36, Precision: 0.44, Recall: 0.47\n",
            "Epoch: 0, Batch: 4650, Loss: 0.5717831283807755, Accuracy: 53.36, Precision: 0.64, Recall: 0.62\n",
            "Epoch: 0, Batch: 4660, Loss: 0.5455283284187317, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 4670, Loss: 0.5057061731815338, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 4680, Loss: 0.6496629565954208, Accuracy: 51.82, Precision: 0.43, Recall: 0.37\n",
            "Epoch: 0, Batch: 4690, Loss: 0.5210856258869171, Accuracy: 50.48, Precision: 0.44, Recall: 0.46\n",
            "Epoch: 0, Batch: 4700, Loss: 0.6151865541934967, Accuracy: 51.08, Precision: 0.44, Recall: 0.41\n",
            "Epoch: 0, Batch: 4710, Loss: 0.49664968252182007, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 4720, Loss: 0.5312755644321442, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 4730, Loss: 0.4995929837226868, Accuracy: 49.5, Precision: 0.55, Recall: 0.45\n",
            "Epoch: 0, Batch: 4740, Loss: 0.5424796283245087, Accuracy: 50.66, Precision: 0.39, Recall: 0.47\n",
            "Epoch: 0, Batch: 4750, Loss: 0.5066744357347488, Accuracy: 51.36, Precision: 0.46, Recall: 0.33\n",
            "Epoch: 0, Batch: 4760, Loss: 0.593960189819336, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 4770, Loss: 0.539250048995018, Accuracy: 49.78, Precision: 0.39, Recall: 0.51\n",
            "Epoch: 0, Batch: 4780, Loss: 0.5280891984701157, Accuracy: 49.22, Precision: 0.53, Recall: 0.37\n",
            "Epoch: 0, Batch: 4790, Loss: 0.5544528752565384, Accuracy: 49.64, Precision: 0.52, Recall: 0.41\n",
            "Epoch: 0, Batch: 4800, Loss: 0.6099335968494415, Accuracy: 51.02, Precision: 0.53, Recall: 0.67\n",
            "Epoch: 0, Batch: 4810, Loss: 0.4632112354040146, Accuracy: 52.0, Precision: 0.6, Recall: 0.6\n",
            "Epoch: 0, Batch: 4820, Loss: 0.47811667919158934, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 4830, Loss: 0.5345273077487945, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 4840, Loss: 0.5888098299503326, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 4850, Loss: 0.5201768040657043, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 4860, Loss: 0.5528147488832473, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 4870, Loss: 0.5163459420204163, Accuracy: 50.0, Precision: 0.5, Recall: 0.61\n",
            "Epoch: 0, Batch: 4880, Loss: 0.5567762702703476, Accuracy: 50.32, Precision: 0.58, Recall: 0.52\n",
            "Epoch: 0, Batch: 4890, Loss: 0.44671127796173093, Accuracy: 50.9, Precision: 0.55, Recall: 0.59\n",
            "Epoch: 0, Batch: 4900, Loss: 0.5794081926345825, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 4910, Loss: 0.5512134164571763, Accuracy: 51.4, Precision: 0.4, Recall: 0.43\n",
            "Epoch: 0, Batch: 4920, Loss: 0.6088129997253418, Accuracy: 47.3, Precision: 0.59, Recall: 0.35\n",
            "Epoch: 0, Batch: 4930, Loss: 0.6118533819913864, Accuracy: 48.8, Precision: 0.4, Recall: 0.56\n",
            "Epoch: 0, Batch: 4940, Loss: 0.5399748384952545, Accuracy: 50.96, Precision: 0.46, Recall: 0.38\n",
            "Epoch: 0, Batch: 4950, Loss: 0.6254120200872422, Accuracy: 49.52, Precision: 0.56, Recall: 0.46\n",
            "Epoch: 0, Batch: 4960, Loss: 0.5811623364686966, Accuracy: 51.56, Precision: 0.56, Recall: 0.63\n",
            "Epoch: 0, Batch: 4970, Loss: 0.5341198414564132, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 4980, Loss: 0.48766225278377534, Accuracy: 50.16, Precision: 0.46, Recall: 0.48\n",
            "Epoch: 0, Batch: 4990, Loss: 0.6029893070459366, Accuracy: 49.62, Precision: 0.51, Recall: 0.31\n",
            "Epoch: 0, Batch: 5000, Loss: 0.5426010400056839, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 5010, Loss: 0.6270226180553437, Accuracy: 50.36, Precision: 0.44, Recall: 0.47\n",
            "Epoch: 0, Batch: 5020, Loss: 0.5042815953493118, Accuracy: 52.52, Precision: 0.44, Recall: 0.29\n",
            "Epoch: 0, Batch: 5030, Loss: 0.5591045498847962, Accuracy: 48.92, Precision: 0.56, Recall: 0.41\n",
            "Epoch: 0, Batch: 5040, Loss: 0.45009835362434386, Accuracy: 50.2, Precision: 0.45, Recall: 0.48\n",
            "Epoch: 0, Batch: 5050, Loss: 0.47090222537517545, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 5060, Loss: 0.5505527764558792, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 5070, Loss: 0.42402372062206267, Accuracy: 50.0, Precision: 0.5, Recall: 0.39\n",
            "Epoch: 0, Batch: 5080, Loss: 0.46558556854724886, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 5090, Loss: 0.5590730011463165, Accuracy: 50.12, Precision: 0.52, Recall: 0.53\n",
            "Epoch: 0, Batch: 5100, Loss: 0.4943810537457466, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 5110, Loss: 0.5250759690999984, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 5120, Loss: 0.5162309259176254, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 5130, Loss: 0.5501684606075287, Accuracy: 48.8, Precision: 0.62, Recall: 0.45\n",
            "Epoch: 0, Batch: 5140, Loss: 0.535877388715744, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 5150, Loss: 0.5498977988958359, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 5160, Loss: 0.515683314204216, Accuracy: 51.76, Precision: 0.42, Recall: 0.39\n",
            "Epoch: 0, Batch: 5170, Loss: 0.5199413150548935, Accuracy: 50.64, Precision: 0.48, Recall: 0.34\n",
            "Epoch: 0, Batch: 5180, Loss: 0.5586758345365525, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 5190, Loss: 0.4847603440284729, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 5200, Loss: 0.6193404972553254, Accuracy: 50.4, Precision: 0.48, Recall: 0.4\n",
            "Epoch: 0, Batch: 5210, Loss: 0.49954756498336794, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 5220, Loss: 0.5563754051923752, Accuracy: 49.3, Precision: 0.57, Recall: 0.45\n",
            "Epoch: 0, Batch: 5230, Loss: 0.5465482175350189, Accuracy: 52.64, Precision: 0.56, Recall: 0.72\n",
            "Epoch: 0, Batch: 5240, Loss: 0.620157516002655, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 5250, Loss: 0.4751458913087845, Accuracy: 50.0, Precision: 0.5, Recall: 0.38\n",
            "Epoch: 0, Batch: 5260, Loss: 0.5720264106988907, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 5270, Loss: 0.5328271061182022, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 5280, Loss: 0.5497626751661301, Accuracy: 51.0, Precision: 0.55, Recall: 0.6\n",
            "Epoch: 0, Batch: 5290, Loss: 0.6084837824106216, Accuracy: 50.54, Precision: 0.53, Recall: 0.59\n",
            "Epoch: 0, Batch: 5300, Loss: 0.49662765562534333, Accuracy: 49.82, Precision: 0.49, Recall: 0.59\n",
            "Epoch: 0, Batch: 5310, Loss: 0.4815131574869156, Accuracy: 52.24, Precision: 0.43, Recall: 0.34\n",
            "Epoch: 0, Batch: 5320, Loss: 0.4774141669273376, Accuracy: 50.16, Precision: 0.49, Recall: 0.42\n",
            "Epoch: 0, Batch: 5330, Loss: 0.44077879190444946, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 5340, Loss: 0.45086142122745515, Accuracy: 49.9, Precision: 0.49, Recall: 0.55\n",
            "Epoch: 0, Batch: 5350, Loss: 0.5379065170884132, Accuracy: 51.4, Precision: 0.57, Recall: 0.6\n",
            "Epoch: 0, Batch: 5360, Loss: 0.46517485082149507, Accuracy: 52.34, Precision: 0.41, Recall: 0.37\n",
            "Epoch: 0, Batch: 5370, Loss: 0.5114843130111695, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 5380, Loss: 0.5190503567457199, Accuracy: 50.0, Precision: 0.5, Recall: 0.59\n",
            "Epoch: 0, Batch: 5390, Loss: 0.6257253795862198, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 5400, Loss: 0.478383332490921, Accuracy: 49.82, Precision: 0.59, Recall: 0.49\n",
            "Epoch: 0, Batch: 5410, Loss: 0.548272094130516, Accuracy: 50.0, Precision: 0.44, Recall: 0.5\n",
            "Epoch: 0, Batch: 5420, Loss: 0.5068308740854264, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 5430, Loss: 0.5566586881875992, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "Epoch: 0, Batch: 5440, Loss: 0.48720732033252717, Accuracy: 51.08, Precision: 0.59, Recall: 0.56\n",
            "Epoch: 0, Batch: 5450, Loss: 0.4861453533172607, Accuracy: 49.76, Precision: 0.48, Recall: 0.56\n",
            "Epoch: 0, Batch: 5460, Loss: 0.5652288913726806, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 5470, Loss: 0.5413384318351746, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 5480, Loss: 0.5190069198608398, Accuracy: 49.86, Precision: 0.49, Recall: 0.57\n",
            "Epoch: 0, Batch: 5490, Loss: 0.5062346398830414, Accuracy: 49.98, Precision: 0.51, Recall: 0.49\n",
            "Epoch: 0, Batch: 5500, Loss: 0.4848808288574219, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 5510, Loss: 0.47224792540073396, Accuracy: 51.44, Precision: 0.59, Recall: 0.58\n",
            "Epoch: 0, Batch: 5520, Loss: 0.568288454413414, Accuracy: 50.48, Precision: 0.52, Recall: 0.62\n",
            "Epoch: 0, Batch: 5530, Loss: 0.49161737561225893, Accuracy: 50.72, Precision: 0.44, Recall: 0.44\n",
            "Epoch: 0, Batch: 5540, Loss: 0.5116414219141007, Accuracy: 50.0, Precision: 0.5, Recall: 0.38\n",
            "Epoch: 0, Batch: 5550, Loss: 0.4782571792602539, Accuracy: 50.72, Precision: 0.59, Recall: 0.54\n",
            "Epoch: 0, Batch: 5560, Loss: 0.5521050244569778, Accuracy: 49.0, Precision: 0.45, Recall: 0.6\n",
            "Epoch: 0, Batch: 5570, Loss: 0.48763889372348784, Accuracy: 52.1, Precision: 0.43, Recall: 0.35\n",
            "Epoch: 0, Batch: 5580, Loss: 0.4911358967423439, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 5590, Loss: 0.6039514929056168, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 5600, Loss: 0.4842223018407822, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 5610, Loss: 0.5702223509550095, Accuracy: 49.64, Precision: 0.44, Recall: 0.53\n",
            "Epoch: 0, Batch: 5620, Loss: 0.4641885608434677, Accuracy: 51.0, Precision: 0.45, Recall: 0.4\n",
            "Epoch: 0, Batch: 5630, Loss: 0.5111775770783424, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 5640, Loss: 0.48806411921978, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 5650, Loss: 0.44672698676586153, Accuracy: 50.14, Precision: 0.57, Recall: 0.51\n",
            "Epoch: 0, Batch: 5660, Loss: 0.5776871979236603, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 5670, Loss: 0.5640647351741791, Accuracy: 49.84, Precision: 0.52, Recall: 0.46\n",
            "Epoch: 0, Batch: 5680, Loss: 0.40457940101623535, Accuracy: 50.6, Precision: 0.53, Recall: 0.6\n",
            "Epoch: 0, Batch: 5690, Loss: 0.599644610285759, Accuracy: 50.7, Precision: 0.55, Recall: 0.57\n",
            "Epoch: 0, Batch: 5700, Loss: 0.5412991613149643, Accuracy: 49.76, Precision: 0.48, Recall: 0.56\n",
            "Epoch: 0, Batch: 5710, Loss: 0.5626377165317535, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 5720, Loss: 0.49700246155261996, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 5730, Loss: 0.5099686175584793, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 5740, Loss: 0.4550762981176376, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 5750, Loss: 0.5185812324285507, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 5760, Loss: 0.6531387880444527, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 5770, Loss: 0.6349531710147858, Accuracy: 50.0, Precision: 0.55, Recall: 0.5\n",
            "Epoch: 0, Batch: 5780, Loss: 0.5268774092197418, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 5790, Loss: 0.46979126930236814, Accuracy: 50.72, Precision: 0.41, Recall: 0.46\n",
            "Epoch: 0, Batch: 5800, Loss: 0.5497808426618576, Accuracy: 49.4, Precision: 0.56, Recall: 0.45\n",
            "Epoch: 0, Batch: 5810, Loss: 0.4692073315382004, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 5820, Loss: 0.5927045404911041, Accuracy: 49.2, Precision: 0.45, Recall: 0.58\n",
            "Epoch: 0, Batch: 5830, Loss: 0.5667667150497436, Accuracy: 50.6, Precision: 0.48, Recall: 0.35\n",
            "Epoch: 0, Batch: 5840, Loss: 0.5435940235853195, Accuracy: 48.88, Precision: 0.58, Recall: 0.43\n",
            "Epoch: 0, Batch: 5850, Loss: 0.5657692313194275, Accuracy: 52.32, Precision: 0.54, Recall: 0.79\n",
            "Epoch: 0, Batch: 5860, Loss: 0.528279247879982, Accuracy: 49.6, Precision: 0.46, Recall: 0.55\n",
            "Epoch: 0, Batch: 5870, Loss: 0.5639785349369049, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 5880, Loss: 0.5247392326593399, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 5890, Loss: 0.5226136356592178, Accuracy: 50.98, Precision: 0.43, Recall: 0.43\n",
            "Epoch: 0, Batch: 5900, Loss: 0.5160515606403351, Accuracy: 50.0, Precision: 0.56, Recall: 0.5\n",
            "Epoch: 0, Batch: 5910, Loss: 0.5785583615303039, Accuracy: 51.26, Precision: 0.57, Recall: 0.59\n",
            "Epoch: 0, Batch: 5920, Loss: 0.42563893347978593, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 5930, Loss: 0.5678965240716934, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 5940, Loss: 0.4765245527029037, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 5950, Loss: 0.49901975840330126, Accuracy: 50.42, Precision: 0.47, Recall: 0.43\n",
            "Epoch: 0, Batch: 5960, Loss: 0.5906853258609772, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 5970, Loss: 0.44704450368881227, Accuracy: 50.14, Precision: 0.43, Recall: 0.49\n",
            "Epoch: 0, Batch: 5980, Loss: 0.5206732451915741, Accuracy: 51.96, Precision: 0.43, Recall: 0.36\n",
            "Epoch: 0, Batch: 5990, Loss: 0.5808287054300308, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 6000, Loss: 0.5094188779592514, Accuracy: 50.42, Precision: 0.43, Recall: 0.47\n",
            "Epoch: 0, Batch: 6010, Loss: 0.5623102784156799, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 6020, Loss: 0.5514926493167878, Accuracy: 52.16, Precision: 0.41, Recall: 0.38\n",
            "Epoch: 0, Batch: 6030, Loss: 0.49858769178390505, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 6040, Loss: 0.5848986864089966, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 6050, Loss: 0.5654596716165543, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 6060, Loss: 0.5059474855661392, Accuracy: 49.84, Precision: 0.49, Recall: 0.58\n",
            "Epoch: 0, Batch: 6070, Loss: 0.5629964023828506, Accuracy: 49.6, Precision: 0.52, Recall: 0.4\n",
            "Epoch: 0, Batch: 6080, Loss: 0.6241969496011734, Accuracy: 49.76, Precision: 0.44, Recall: 0.52\n",
            "Epoch: 0, Batch: 6090, Loss: 0.5019257664680481, Accuracy: 50.1, Precision: 0.55, Recall: 0.51\n",
            "Epoch: 0, Batch: 6100, Loss: 0.5540460526943207, Accuracy: 50.88, Precision: 0.39, Recall: 0.46\n",
            "Epoch: 0, Batch: 6110, Loss: 0.5624971687793732, Accuracy: 51.7, Precision: 0.45, Recall: 0.33\n",
            "Epoch: 0, Batch: 6120, Loss: 0.584621924161911, Accuracy: 49.28, Precision: 0.53, Recall: 0.38\n",
            "Epoch: 0, Batch: 6130, Loss: 0.5641473323106766, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 6140, Loss: 0.4701750338077545, Accuracy: 50.36, Precision: 0.52, Recall: 0.59\n",
            "Epoch: 0, Batch: 6150, Loss: 0.5760957568883895, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 6160, Loss: 0.49338377714157106, Accuracy: 51.68, Precision: 0.43, Recall: 0.38\n",
            "Epoch: 0, Batch: 6170, Loss: 0.5707561373710632, Accuracy: 48.7, Precision: 0.55, Recall: 0.37\n",
            "Epoch: 0, Batch: 6180, Loss: 0.5905000746250153, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 6190, Loss: 0.5501450747251511, Accuracy: 50.0, Precision: 0.44, Recall: 0.5\n",
            "Epoch: 0, Batch: 6200, Loss: 0.5774879634380341, Accuracy: 51.5, Precision: 0.45, Recall: 0.35\n",
            "Epoch: 0, Batch: 6210, Loss: 0.48057045340538024, Accuracy: 50.0, Precision: 0.58, Recall: 0.5\n",
            "Epoch: 0, Batch: 6220, Loss: 0.5159214079380036, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 6230, Loss: 0.5853600829839707, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 6240, Loss: 0.4398710042238235, Accuracy: 50.8, Precision: 0.58, Recall: 0.55\n",
            "Epoch: 0, Batch: 6250, Loss: 0.5894556879997254, Accuracy: 50.2, Precision: 0.55, Recall: 0.52\n",
            "Epoch: 0, Batch: 6260, Loss: 0.5740097880363464, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 6270, Loss: 0.4843956470489502, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 6280, Loss: 0.46149367094039917, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 6290, Loss: 0.627937400341034, Accuracy: 49.92, Precision: 0.54, Recall: 0.49\n",
            "Epoch: 0, Batch: 6300, Loss: 0.5145272970199585, Accuracy: 49.88, Precision: 0.47, Recall: 0.52\n",
            "Epoch: 0, Batch: 6310, Loss: 0.5606466591358185, Accuracy: 51.12, Precision: 0.43, Recall: 0.42\n",
            "Epoch: 0, Batch: 6320, Loss: 0.5291262626647949, Accuracy: 48.56, Precision: 0.58, Recall: 0.41\n",
            "Epoch: 0, Batch: 6330, Loss: 0.6345130115747452, Accuracy: 52.1, Precision: 0.57, Recall: 0.65\n",
            "Epoch: 0, Batch: 6340, Loss: 0.5199004650115967, Accuracy: 50.4, Precision: 0.52, Recall: 0.6\n",
            "Epoch: 0, Batch: 6350, Loss: 0.5091125249862671, Accuracy: 49.96, Precision: 0.51, Recall: 0.48\n",
            "Epoch: 0, Batch: 6360, Loss: 0.5285383105278015, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 6370, Loss: 0.4641210526227951, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 6380, Loss: 0.5098172873258591, Accuracy: 49.92, Precision: 0.46, Recall: 0.51\n",
            "Epoch: 0, Batch: 6390, Loss: 0.5979705542325974, Accuracy: 49.88, Precision: 0.51, Recall: 0.44\n",
            "Epoch: 0, Batch: 6400, Loss: 0.47284228056669236, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 6410, Loss: 0.4963757425546646, Accuracy: 50.06, Precision: 0.53, Recall: 0.51\n",
            "Epoch: 0, Batch: 6420, Loss: 0.5116768628358841, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 6430, Loss: 0.47576703429222106, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 6440, Loss: 0.3950127840042114, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 6450, Loss: 0.4930428326129913, Accuracy: 50.16, Precision: 0.48, Recall: 0.46\n",
            "Epoch: 0, Batch: 6460, Loss: 0.7848275423049926, Accuracy: 50.48, Precision: 0.58, Recall: 0.53\n",
            "Epoch: 0, Batch: 6470, Loss: 0.631231763958931, Accuracy: 49.7, Precision: 0.45, Recall: 0.53\n",
            "Epoch: 0, Batch: 6480, Loss: 0.5886965423822403, Accuracy: 48.6, Precision: 0.57, Recall: 0.4\n",
            "Epoch: 0, Batch: 6490, Loss: 0.48213321566581724, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 6500, Loss: 0.549306434392929, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 6510, Loss: 0.5154214560985565, Accuracy: 49.88, Precision: 0.49, Recall: 0.56\n",
            "Epoch: 0, Batch: 6520, Loss: 0.5285477966070176, Accuracy: 50.0, Precision: 0.5, Recall: 0.42\n",
            "Epoch: 0, Batch: 6530, Loss: 0.4858457237482071, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "Epoch: 0, Batch: 6540, Loss: 0.5437472879886627, Accuracy: 50.72, Precision: 0.41, Recall: 0.46\n",
            "Epoch: 0, Batch: 6550, Loss: 0.4466326028108597, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 6560, Loss: 0.5252846568822861, Accuracy: 50.26, Precision: 0.49, Recall: 0.37\n",
            "Epoch: 0, Batch: 6570, Loss: 0.5450656682252883, Accuracy: 49.86, Precision: 0.43, Recall: 0.51\n",
            "Epoch: 0, Batch: 6580, Loss: 0.5256127178668976, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 6590, Loss: 0.45788012742996215, Accuracy: 49.7, Precision: 0.55, Recall: 0.47\n",
            "Epoch: 0, Batch: 6600, Loss: 0.5058307200670242, Accuracy: 53.36, Precision: 0.62, Recall: 0.64\n",
            "Epoch: 0, Batch: 6610, Loss: 0.5107515037059784, Accuracy: 50.28, Precision: 0.51, Recall: 0.64\n",
            "Epoch: 0, Batch: 6620, Loss: 0.514481046795845, Accuracy: 49.9, Precision: 0.51, Recall: 0.45\n",
            "Epoch: 0, Batch: 6630, Loss: 0.5154926180839539, Accuracy: 51.4, Precision: 0.45, Recall: 0.36\n",
            "Epoch: 0, Batch: 6640, Loss: 0.4825038522481918, Accuracy: 50.5, Precision: 0.55, Recall: 0.55\n",
            "Epoch: 0, Batch: 6650, Loss: 0.5434383124113082, Accuracy: 49.92, Precision: 0.46, Recall: 0.51\n",
            "Epoch: 0, Batch: 6660, Loss: 0.5173923432826996, Accuracy: 50.54, Precision: 0.41, Recall: 0.47\n",
            "Epoch: 0, Batch: 6670, Loss: 0.5012514144182205, Accuracy: 50.0, Precision: 0.5, Recall: 0.39\n",
            "Epoch: 0, Batch: 6680, Loss: 0.6123383074998856, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 6690, Loss: 0.5385304927825928, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "Epoch: 0, Batch: 6700, Loss: 0.6035954296588898, Accuracy: 49.88, Precision: 0.47, Recall: 0.52\n",
            "Epoch: 0, Batch: 6710, Loss: 0.46180647015571596, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 6720, Loss: 0.5924390465021133, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 6730, Loss: 0.5408058732748031, Accuracy: 51.28, Precision: 0.58, Recall: 0.58\n",
            "Epoch: 0, Batch: 6740, Loss: 0.5031327605247498, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 6750, Loss: 0.37373563051223757, Accuracy: 51.08, Precision: 0.44, Recall: 0.41\n",
            "Epoch: 0, Batch: 6760, Loss: 0.4900983214378357, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 6770, Loss: 0.4891151636838913, Accuracy: 50.2, Precision: 0.51, Recall: 0.6\n",
            "Epoch: 0, Batch: 6780, Loss: 0.48819704353809357, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 6790, Loss: 0.4853066712617874, Accuracy: 49.92, Precision: 0.51, Recall: 0.46\n",
            "Epoch: 0, Batch: 6800, Loss: 0.5096224665641784, Accuracy: 54.5, Precision: 0.65, Recall: 0.65\n",
            "Epoch: 0, Batch: 6810, Loss: 0.611626672744751, Accuracy: 49.64, Precision: 0.48, Recall: 0.59\n",
            "Epoch: 0, Batch: 6820, Loss: 0.4570492148399353, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 6830, Loss: 0.49556354582309725, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 6840, Loss: 0.4979987770318985, Accuracy: 50.08, Precision: 0.46, Recall: 0.49\n",
            "Epoch: 0, Batch: 6850, Loss: 0.5756744325160981, Accuracy: 49.66, Precision: 0.51, Recall: 0.33\n",
            "Epoch: 0, Batch: 6860, Loss: 0.555980795621872, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 6870, Loss: 0.5294053256511688, Accuracy: 50.84, Precision: 0.43, Recall: 0.44\n",
            "Epoch: 0, Batch: 6880, Loss: 0.49628845751285555, Accuracy: 50.98, Precision: 0.57, Recall: 0.57\n",
            "Epoch: 0, Batch: 6890, Loss: 0.6302937626838684, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 6900, Loss: 0.5554411858320236, Accuracy: 51.1, Precision: 0.55, Recall: 0.61\n",
            "Epoch: 0, Batch: 6910, Loss: 0.4566617518663406, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 6920, Loss: 0.5279941976070404, Accuracy: 49.46, Precision: 0.53, Recall: 0.41\n",
            "Epoch: 0, Batch: 6930, Loss: 0.6199617028236389, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 6940, Loss: 0.5689336270093918, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 6950, Loss: 0.4727835327386856, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 6960, Loss: 0.5238444536924363, Accuracy: 49.86, Precision: 0.49, Recall: 0.57\n",
            "Epoch: 0, Batch: 6970, Loss: 0.6097854882478714, Accuracy: 50.0, Precision: 0.56, Recall: 0.5\n",
            "Epoch: 0, Batch: 6980, Loss: 0.5129248768091201, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 6990, Loss: 0.48405571579933165, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 7000, Loss: 0.5960690945386886, Accuracy: 49.04, Precision: 0.58, Recall: 0.44\n",
            "Epoch: 0, Batch: 7010, Loss: 0.4624622732400894, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 7020, Loss: 0.573184934258461, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 7030, Loss: 0.5559908300638199, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 7040, Loss: 0.4553589016199112, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 7050, Loss: 0.4692910611629486, Accuracy: 49.92, Precision: 0.49, Recall: 0.54\n",
            "Epoch: 0, Batch: 7060, Loss: 0.535333639383316, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 7070, Loss: 0.5138513386249542, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 7080, Loss: 0.5638927489519119, Accuracy: 51.44, Precision: 0.42, Recall: 0.41\n",
            "Epoch: 0, Batch: 7090, Loss: 0.4648951441049576, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 7100, Loss: 0.5034598380327224, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 7110, Loss: 0.5250387877225876, Accuracy: 50.2, Precision: 0.52, Recall: 0.55\n",
            "Epoch: 0, Batch: 7120, Loss: 0.5887267410755157, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 7130, Loss: 0.43279857039451597, Accuracy: 50.16, Precision: 0.48, Recall: 0.46\n",
            "Epoch: 0, Batch: 7140, Loss: 0.47751778066158296, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 7150, Loss: 0.4442669600248337, Accuracy: 50.28, Precision: 0.57, Recall: 0.52\n",
            "Epoch: 0, Batch: 7160, Loss: 0.4857127457857132, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 7170, Loss: 0.5042592093348504, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 7180, Loss: 0.5576434075832367, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 7190, Loss: 0.48904978930950166, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 7200, Loss: 0.6342816710472107, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 7210, Loss: 0.48441981375217436, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 7220, Loss: 0.5182754963636398, Accuracy: 49.02, Precision: 0.57, Recall: 0.43\n",
            "Epoch: 0, Batch: 7230, Loss: 0.46652822494506835, Accuracy: 50.12, Precision: 0.51, Recall: 0.56\n",
            "Epoch: 0, Batch: 7240, Loss: 0.5763007372617721, Accuracy: 50.0, Precision: 0.5, Recall: 0.59\n",
            "Epoch: 0, Batch: 7250, Loss: 0.4939840346574783, Accuracy: 51.2, Precision: 0.45, Recall: 0.38\n",
            "Epoch: 0, Batch: 7260, Loss: 0.5292554348707199, Accuracy: 48.92, Precision: 0.59, Recall: 0.44\n",
            "Epoch: 0, Batch: 7270, Loss: 0.505241647362709, Accuracy: 48.72, Precision: 0.46, Recall: 0.66\n",
            "Epoch: 0, Batch: 7280, Loss: 0.5624080121517181, Accuracy: 50.08, Precision: 0.46, Recall: 0.49\n",
            "Epoch: 0, Batch: 7290, Loss: 0.5874099940061569, Accuracy: 50.38, Precision: 0.49, Recall: 0.31\n",
            "Epoch: 0, Batch: 7300, Loss: 0.5292626202106476, Accuracy: 51.6, Precision: 0.6, Recall: 0.58\n",
            "Epoch: 0, Batch: 7310, Loss: 0.5470941483974456, Accuracy: 50.28, Precision: 0.51, Recall: 0.64\n",
            "Epoch: 0, Batch: 7320, Loss: 0.47653923034667967, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 7330, Loss: 0.5577267169952392, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 7340, Loss: 0.5054622143507004, Accuracy: 50.84, Precision: 0.47, Recall: 0.36\n",
            "Epoch: 0, Batch: 7350, Loss: 0.459158319234848, Accuracy: 50.56, Precision: 0.57, Recall: 0.54\n",
            "Epoch: 0, Batch: 7360, Loss: 0.54816332757473, Accuracy: 52.88, Precision: 0.59, Recall: 0.66\n",
            "Epoch: 0, Batch: 7370, Loss: 0.5027735739946365, Accuracy: 51.0, Precision: 0.55, Recall: 0.6\n",
            "Epoch: 0, Batch: 7380, Loss: 0.5347044676542282, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 7390, Loss: 0.6125333338975907, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 7400, Loss: 0.4911672532558441, Accuracy: 50.8, Precision: 0.58, Recall: 0.55\n",
            "Epoch: 0, Batch: 7410, Loss: 0.5411329612135887, Accuracy: 50.2, Precision: 0.51, Recall: 0.6\n",
            "Epoch: 0, Batch: 7420, Loss: 0.48907927572727206, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 7430, Loss: 0.468490806221962, Accuracy: 50.44, Precision: 0.48, Recall: 0.39\n",
            "Epoch: 0, Batch: 7440, Loss: 0.49936174750328066, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 7450, Loss: 0.38165461719036103, Accuracy: 50.0, Precision: 0.45, Recall: 0.5\n",
            "Epoch: 0, Batch: 7460, Loss: 0.5666637182235718, Accuracy: 49.6, Precision: 0.55, Recall: 0.46\n",
            "Epoch: 0, Batch: 7470, Loss: 0.539009290933609, Accuracy: 52.88, Precision: 0.58, Recall: 0.68\n",
            "Epoch: 0, Batch: 7480, Loss: 0.576427087187767, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 7490, Loss: 0.49847449362277985, Accuracy: 50.0, Precision: 0.5, Recall: 0.42\n",
            "Epoch: 0, Batch: 7500, Loss: 0.4413896858692169, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 7510, Loss: 0.5671686559915543, Accuracy: 49.8, Precision: 0.49, Recall: 0.6\n",
            "Epoch: 0, Batch: 7520, Loss: 0.56741753667593, Accuracy: 50.6, Precision: 0.48, Recall: 0.35\n",
            "Epoch: 0, Batch: 7530, Loss: 0.5379288405179977, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 7540, Loss: 0.5654966592788696, Accuracy: 50.9, Precision: 0.53, Recall: 0.65\n",
            "Epoch: 0, Batch: 7550, Loss: 0.49516547918319703, Accuracy: 49.84, Precision: 0.52, Recall: 0.46\n",
            "Epoch: 0, Batch: 7560, Loss: 0.5116907209157944, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 7570, Loss: 0.46760670840740204, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 7580, Loss: 0.4659674078226089, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 7590, Loss: 0.5064955174922943, Accuracy: 49.88, Precision: 0.53, Recall: 0.48\n",
            "Epoch: 0, Batch: 7600, Loss: 0.5625172019004822, Accuracy: 49.82, Precision: 0.49, Recall: 0.59\n",
            "Epoch: 0, Batch: 7610, Loss: 0.3852008283138275, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 7620, Loss: 0.4569985240697861, Accuracy: 51.04, Precision: 0.46, Recall: 0.37\n",
            "Epoch: 0, Batch: 7630, Loss: 0.4803648978471756, Accuracy: 51.76, Precision: 0.58, Recall: 0.61\n",
            "Epoch: 0, Batch: 7640, Loss: 0.5280122265219689, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 7650, Loss: 0.5975424006581307, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 7660, Loss: 0.46988206505775454, Accuracy: 50.3, Precision: 0.47, Recall: 0.45\n",
            "Epoch: 0, Batch: 7670, Loss: 0.46965802907943727, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 7680, Loss: 0.5870273321866989, Accuracy: 50.16, Precision: 0.46, Recall: 0.48\n",
            "Epoch: 0, Batch: 7690, Loss: 0.6056606620550156, Accuracy: 48.8, Precision: 0.55, Recall: 0.38\n",
            "Epoch: 0, Batch: 7700, Loss: 0.5235668599605561, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 7710, Loss: 0.5732916384935379, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 7720, Loss: 0.5284593373537063, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 7730, Loss: 0.4223683923482895, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 7740, Loss: 0.48273598253726957, Accuracy: 50.8, Precision: 0.58, Recall: 0.55\n",
            "Epoch: 0, Batch: 7750, Loss: 0.5401564508676528, Accuracy: 51.92, Precision: 0.56, Recall: 0.66\n",
            "Epoch: 0, Batch: 7760, Loss: 0.4272723749279976, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 7770, Loss: 0.5707218736410141, Accuracy: 49.6, Precision: 0.54, Recall: 0.45\n",
            "Epoch: 0, Batch: 7780, Loss: 0.48664900064468386, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 7790, Loss: 0.4349598720669746, Accuracy: 53.96, Precision: 0.61, Recall: 0.68\n",
            "Epoch: 0, Batch: 7800, Loss: 0.5637988775968552, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 7810, Loss: 0.5281857013702392, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 7820, Loss: 0.47987398952245713, Accuracy: 50.0, Precision: 0.5, Recall: 0.41\n",
            "Epoch: 0, Batch: 7830, Loss: 0.5555996656417846, Accuracy: 50.48, Precision: 0.48, Recall: 0.38\n",
            "Epoch: 0, Batch: 7840, Loss: 0.5361760854721069, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 7850, Loss: 0.4353571027517319, Accuracy: 50.28, Precision: 0.57, Recall: 0.52\n",
            "Epoch: 0, Batch: 7860, Loss: 0.46356741786003114, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 7870, Loss: 0.4685306489467621, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 7880, Loss: 0.5523267954587936, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 7890, Loss: 0.5025795757770538, Accuracy: 51.2, Precision: 0.55, Recall: 0.62\n",
            "Epoch: 0, Batch: 7900, Loss: 0.5092455804347992, Accuracy: 51.62, Precision: 0.59, Recall: 0.59\n",
            "Epoch: 0, Batch: 7910, Loss: 0.5079632252454758, Accuracy: 50.1, Precision: 0.51, Recall: 0.55\n",
            "Epoch: 0, Batch: 7920, Loss: 0.507584348320961, Accuracy: 50.42, Precision: 0.57, Recall: 0.53\n",
            "Epoch: 0, Batch: 7930, Loss: 0.567925563454628, Accuracy: 49.52, Precision: 0.47, Recall: 0.58\n",
            "Epoch: 0, Batch: 7940, Loss: 0.4959194645285606, Accuracy: 50.98, Precision: 0.57, Recall: 0.57\n",
            "Epoch: 0, Batch: 7950, Loss: 0.5595850765705108, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 7960, Loss: 0.5769581168889999, Accuracy: 49.44, Precision: 0.54, Recall: 0.43\n",
            "Epoch: 0, Batch: 7970, Loss: 0.5175955772399903, Accuracy: 51.6, Precision: 0.58, Recall: 0.6\n",
            "Epoch: 0, Batch: 7980, Loss: 0.49280120730400084, Accuracy: 50.96, Precision: 0.54, Recall: 0.62\n",
            "Epoch: 0, Batch: 7990, Loss: 0.3990300014615059, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 8000, Loss: 0.534271939098835, Accuracy: 49.6, Precision: 0.52, Recall: 0.4\n",
            "Epoch: 0, Batch: 8010, Loss: 0.4846370294690132, Accuracy: 49.76, Precision: 0.47, Recall: 0.54\n",
            "Epoch: 0, Batch: 8020, Loss: 0.4837824523448944, Accuracy: 49.52, Precision: 0.53, Recall: 0.42\n",
            "Epoch: 0, Batch: 8030, Loss: 0.5201462954282761, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 8040, Loss: 0.4766515329480171, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 8050, Loss: 0.3963803470134735, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 8060, Loss: 0.5500251397490501, Accuracy: 49.82, Precision: 0.49, Recall: 0.59\n",
            "Epoch: 0, Batch: 8070, Loss: 0.47213830053806305, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 8080, Loss: 0.4446313723921776, Accuracy: 49.88, Precision: 0.53, Recall: 0.48\n",
            "Epoch: 0, Batch: 8090, Loss: 0.48982768058776854, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 8100, Loss: 0.4982776492834091, Accuracy: 51.56, Precision: 0.44, Recall: 0.37\n",
            "Epoch: 0, Batch: 8110, Loss: 0.5507598370313644, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 8120, Loss: 0.453538216650486, Accuracy: 50.84, Precision: 0.56, Recall: 0.57\n",
            "Epoch: 0, Batch: 8130, Loss: 0.4309063643217087, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 8140, Loss: 0.48258923888206484, Accuracy: 51.08, Precision: 0.41, Recall: 0.44\n",
            "Epoch: 0, Batch: 8150, Loss: 0.5340168386697769, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 8160, Loss: 0.41832670718431475, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 8170, Loss: 0.5598754107952117, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 8180, Loss: 0.5584627985954285, Accuracy: 49.88, Precision: 0.52, Recall: 0.47\n",
            "Epoch: 0, Batch: 8190, Loss: 0.4487780034542084, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 8200, Loss: 0.4891450434923172, Accuracy: 51.3, Precision: 0.55, Recall: 0.63\n",
            "Epoch: 0, Batch: 8210, Loss: 0.5232575923204422, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 8220, Loss: 0.4968511700630188, Accuracy: 51.0, Precision: 0.45, Recall: 0.4\n",
            "Epoch: 0, Batch: 8230, Loss: 0.5933873772621154, Accuracy: 49.84, Precision: 0.52, Recall: 0.46\n",
            "Epoch: 0, Batch: 8240, Loss: 0.46652282774448395, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 8250, Loss: 0.5008630603551865, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 8260, Loss: 0.4170035898685455, Accuracy: 50.84, Precision: 0.44, Recall: 0.43\n",
            "Epoch: 0, Batch: 8270, Loss: 0.5720837652683258, Accuracy: 50.2, Precision: 0.6, Recall: 0.51\n",
            "Epoch: 0, Batch: 8280, Loss: 0.4846517205238342, Accuracy: 50.48, Precision: 0.52, Recall: 0.62\n",
            "Epoch: 0, Batch: 8290, Loss: 0.5156509667634964, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 8300, Loss: 0.42601599395275114, Accuracy: 49.9, Precision: 0.51, Recall: 0.45\n",
            "Epoch: 0, Batch: 8310, Loss: 0.5621401086449623, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 8320, Loss: 0.4617558628320694, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 8330, Loss: 0.46946028620004654, Accuracy: 49.76, Precision: 0.46, Recall: 0.53\n",
            "Epoch: 0, Batch: 8340, Loss: 0.4890616059303284, Accuracy: 50.12, Precision: 0.56, Recall: 0.51\n",
            "Epoch: 0, Batch: 8350, Loss: 0.4394024446606636, Accuracy: 50.3, Precision: 0.53, Recall: 0.55\n",
            "Epoch: 0, Batch: 8360, Loss: 0.5302002549171447, Accuracy: 50.1, Precision: 0.51, Recall: 0.55\n",
            "Epoch: 0, Batch: 8370, Loss: 0.4736727476119995, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 8380, Loss: 0.5461963921785354, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 8390, Loss: 0.41441796720027924, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 8400, Loss: 0.47912130802869796, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "Epoch: 0, Batch: 8410, Loss: 0.48767375349998476, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 8420, Loss: 0.5561746656894684, Accuracy: 49.56, Precision: 0.48, Recall: 0.61\n",
            "Epoch: 0, Batch: 8430, Loss: 0.5241164535284042, Accuracy: 53.92, Precision: 0.36, Recall: 0.36\n",
            "Epoch: 0, Batch: 8440, Loss: 0.5137702614068985, Accuracy: 49.44, Precision: 0.57, Recall: 0.46\n",
            "Epoch: 0, Batch: 8450, Loss: 0.43488427698612214, Accuracy: 51.0, Precision: 0.55, Recall: 0.6\n",
            "Epoch: 0, Batch: 8460, Loss: 0.4999899104237556, Accuracy: 53.08, Precision: 0.39, Recall: 0.36\n",
            "Epoch: 0, Batch: 8470, Loss: 0.433822825551033, Accuracy: 51.44, Precision: 0.44, Recall: 0.38\n",
            "Epoch: 0, Batch: 8480, Loss: 0.551391951739788, Accuracy: 49.92, Precision: 0.54, Recall: 0.49\n",
            "Epoch: 0, Batch: 8490, Loss: 0.5126900911331177, Accuracy: 49.84, Precision: 0.42, Recall: 0.51\n",
            "Epoch: 0, Batch: 8500, Loss: 0.4884469240903854, Accuracy: 49.6, Precision: 0.55, Recall: 0.46\n",
            "Epoch: 0, Batch: 8510, Loss: 0.5276499092578888, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 8520, Loss: 0.5074924528598785, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 8530, Loss: 0.4212853014469147, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 8540, Loss: 0.4208822578191757, Accuracy: 50.1, Precision: 0.51, Recall: 0.55\n",
            "Epoch: 0, Batch: 8550, Loss: 0.48859158158302307, Accuracy: 51.8, Precision: 0.41, Recall: 0.4\n",
            "Epoch: 0, Batch: 8560, Loss: 0.5772696435451508, Accuracy: 53.78, Precision: 0.41, Recall: 0.29\n",
            "Epoch: 0, Batch: 8570, Loss: 0.47833303213119505, Accuracy: 49.84, Precision: 0.52, Recall: 0.46\n",
            "Epoch: 0, Batch: 8580, Loss: 0.4712589681148529, Accuracy: 50.16, Precision: 0.51, Recall: 0.58\n",
            "Epoch: 0, Batch: 8590, Loss: 0.5179297238588333, Accuracy: 49.58, Precision: 0.57, Recall: 0.47\n",
            "Epoch: 0, Batch: 8600, Loss: 0.49327492862939837, Accuracy: 53.96, Precision: 0.59, Recall: 0.72\n",
            "Epoch: 0, Batch: 8610, Loss: 0.46048676818609235, Accuracy: 52.16, Precision: 0.59, Recall: 0.62\n",
            "Epoch: 0, Batch: 8620, Loss: 0.4444041758775711, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 8630, Loss: 0.5798590779304504, Accuracy: 50.78, Precision: 0.47, Recall: 0.37\n",
            "Epoch: 0, Batch: 8640, Loss: 0.5434099823236466, Accuracy: 50.1, Precision: 0.49, Recall: 0.45\n",
            "Epoch: 0, Batch: 8650, Loss: 0.40715197622776034, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 8660, Loss: 0.49986552000045775, Accuracy: 49.88, Precision: 0.48, Recall: 0.53\n",
            "Epoch: 0, Batch: 8670, Loss: 0.48008733689785005, Accuracy: 49.76, Precision: 0.54, Recall: 0.47\n",
            "Epoch: 0, Batch: 8680, Loss: 0.3990374252200127, Accuracy: 50.16, Precision: 0.48, Recall: 0.46\n",
            "Epoch: 0, Batch: 8690, Loss: 0.5366237193346024, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 8700, Loss: 0.5162597388029099, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 8710, Loss: 0.44712830036878587, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 8720, Loss: 0.436370787024498, Accuracy: 50.0, Precision: 0.5, Recall: 0.41\n",
            "Epoch: 0, Batch: 8730, Loss: 0.5268595859408378, Accuracy: 51.2, Precision: 0.56, Recall: 0.6\n",
            "Epoch: 0, Batch: 8740, Loss: 0.4355526059865952, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 8750, Loss: 0.5061738938093185, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 8760, Loss: 0.5472844004631042, Accuracy: 50.22, Precision: 0.49, Recall: 0.39\n",
            "Epoch: 0, Batch: 8770, Loss: 0.47316896766424177, Accuracy: 50.36, Precision: 0.41, Recall: 0.48\n",
            "Epoch: 0, Batch: 8780, Loss: 0.5309656709432602, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 8790, Loss: 0.48115704357624056, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 8800, Loss: 0.4955188050866127, Accuracy: 50.18, Precision: 0.41, Recall: 0.49\n",
            "Epoch: 0, Batch: 8810, Loss: 0.5922001212835312, Accuracy: 49.04, Precision: 0.62, Recall: 0.46\n",
            "Epoch: 0, Batch: 8820, Loss: 0.5005933940410614, Accuracy: 49.76, Precision: 0.47, Recall: 0.54\n",
            "Epoch: 0, Batch: 8830, Loss: 0.47573994994163515, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 8840, Loss: 0.44063542038202286, Accuracy: 50.0, Precision: 0.5, Recall: 0.42\n",
            "Epoch: 0, Batch: 8850, Loss: 0.45901346057653425, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 8860, Loss: 0.5699644982814789, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 8870, Loss: 0.5251746982336044, Accuracy: 51.12, Precision: 0.43, Recall: 0.42\n",
            "Epoch: 0, Batch: 8880, Loss: 0.47850667536258695, Accuracy: 50.2, Precision: 0.55, Recall: 0.52\n",
            "Epoch: 0, Batch: 8890, Loss: 0.49120521545410156, Accuracy: 52.88, Precision: 0.59, Recall: 0.66\n",
            "Epoch: 0, Batch: 8900, Loss: 0.5071486502885818, Accuracy: 50.48, Precision: 0.44, Recall: 0.46\n",
            "Epoch: 0, Batch: 8910, Loss: 0.4758890330791473, Accuracy: 50.9, Precision: 0.47, Recall: 0.35\n",
            "Epoch: 0, Batch: 8920, Loss: 0.49459663927555086, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 8930, Loss: 0.49159887731075286, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 8940, Loss: 0.5000497698783875, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 8950, Loss: 0.4928042143583298, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 8960, Loss: 0.4906197011470795, Accuracy: 51.6, Precision: 0.4, Recall: 0.42\n",
            "Epoch: 0, Batch: 8970, Loss: 0.5764479130506516, Accuracy: 47.6, Precision: 0.6, Recall: 0.38\n",
            "Epoch: 0, Batch: 8980, Loss: 0.45584707856178286, Accuracy: 50.0, Precision: 0.5, Recall: 0.57\n",
            "Epoch: 0, Batch: 8990, Loss: 0.46496354043483734, Accuracy: 49.82, Precision: 0.47, Recall: 0.53\n",
            "Epoch: 0, Batch: 9000, Loss: 0.6218374162912369, Accuracy: 51.6, Precision: 0.42, Recall: 0.4\n",
            "Epoch: 0, Batch: 9010, Loss: 0.4894274681806564, Accuracy: 54.14, Precision: 0.41, Recall: 0.27\n",
            "Epoch: 0, Batch: 9020, Loss: 0.5490869432687759, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 9030, Loss: 0.4700544744729996, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 9040, Loss: 0.45519493520259857, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 9050, Loss: 0.44700738191604616, Accuracy: 50.18, Precision: 0.49, Recall: 0.41\n",
            "Epoch: 0, Batch: 9060, Loss: 0.4998701840639114, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 9070, Loss: 0.5132930129766464, Accuracy: 52.24, Precision: 0.58, Recall: 0.64\n",
            "Epoch: 0, Batch: 9080, Loss: 0.4898522734642029, Accuracy: 50.8, Precision: 0.54, Recall: 0.6\n",
            "Epoch: 0, Batch: 9090, Loss: 0.4833212584257126, Accuracy: 49.78, Precision: 0.51, Recall: 0.39\n",
            "Epoch: 0, Batch: 9100, Loss: 0.48151127696037294, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 9110, Loss: 0.40159493386745454, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 9120, Loss: 0.4898963510990143, Accuracy: 49.44, Precision: 0.46, Recall: 0.57\n",
            "Epoch: 0, Batch: 9130, Loss: 0.4943755820393562, Accuracy: 49.96, Precision: 0.51, Recall: 0.48\n",
            "Epoch: 0, Batch: 9140, Loss: 0.5211522668600083, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 9150, Loss: 0.4733942076563835, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 9160, Loss: 0.48093306720256807, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 9170, Loss: 0.505318321287632, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 9180, Loss: 0.5650358885526657, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 9190, Loss: 0.5015486657619477, Accuracy: 50.72, Precision: 0.44, Recall: 0.44\n",
            "Epoch: 0, Batch: 9200, Loss: 0.504448264837265, Accuracy: 49.52, Precision: 0.54, Recall: 0.44\n",
            "Epoch: 0, Batch: 9210, Loss: 0.6302663654088974, Accuracy: 49.7, Precision: 0.53, Recall: 0.45\n",
            "Epoch: 0, Batch: 9220, Loss: 0.4944631546735764, Accuracy: 51.8, Precision: 0.55, Recall: 0.68\n",
            "Epoch: 0, Batch: 9230, Loss: 0.48444509506225586, Accuracy: 50.72, Precision: 0.44, Recall: 0.44\n",
            "Epoch: 0, Batch: 9240, Loss: 0.567448404431343, Accuracy: 51.36, Precision: 0.46, Recall: 0.33\n",
            "Epoch: 0, Batch: 9250, Loss: 0.5365705013275146, Accuracy: 49.1, Precision: 0.59, Recall: 0.45\n",
            "Epoch: 0, Batch: 9260, Loss: 0.5563533127307891, Accuracy: 49.7, Precision: 0.47, Recall: 0.55\n",
            "Epoch: 0, Batch: 9270, Loss: 0.46329001635313033, Accuracy: 50.0, Precision: 0.5, Recall: 0.57\n",
            "Epoch: 0, Batch: 9280, Loss: 0.4337646886706352, Accuracy: 49.7, Precision: 0.53, Recall: 0.45\n",
            "Epoch: 0, Batch: 9290, Loss: 0.47071945369243623, Accuracy: 51.1, Precision: 0.45, Recall: 0.39\n",
            "Epoch: 0, Batch: 9300, Loss: 0.43148949444293977, Accuracy: 51.44, Precision: 0.42, Recall: 0.41\n",
            "Epoch: 0, Batch: 9310, Loss: 0.4319361984729767, Accuracy: 50.2, Precision: 0.55, Recall: 0.52\n",
            "Epoch: 0, Batch: 9320, Loss: 0.46293331384658815, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 9330, Loss: 0.5706351071596145, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 9340, Loss: 0.34752767384052274, Accuracy: 51.28, Precision: 0.42, Recall: 0.42\n",
            "Epoch: 0, Batch: 9350, Loss: 0.4953855127096176, Accuracy: 51.6, Precision: 0.42, Recall: 0.4\n",
            "Epoch: 0, Batch: 9360, Loss: 0.5063944756984711, Accuracy: 50.1, Precision: 0.49, Recall: 0.45\n",
            "Epoch: 0, Batch: 9370, Loss: 0.5657767921686172, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 9380, Loss: 0.45481422245502473, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 9390, Loss: 0.5385874390602112, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 9400, Loss: 0.523321983218193, Accuracy: 50.2, Precision: 0.52, Recall: 0.55\n",
            "Epoch: 0, Batch: 9410, Loss: 0.5536369413137436, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 9420, Loss: 0.512039652466774, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 9430, Loss: 0.501360085606575, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 9440, Loss: 0.39243918657302856, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 9450, Loss: 0.3984653130173683, Accuracy: 50.9, Precision: 0.41, Recall: 0.45\n",
            "Epoch: 0, Batch: 9460, Loss: 0.39540947824716566, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 9470, Loss: 0.5301907569169998, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 9480, Loss: 0.5412475407123566, Accuracy: 49.98, Precision: 0.51, Recall: 0.49\n",
            "Epoch: 0, Batch: 9490, Loss: 0.4752614825963974, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 9500, Loss: 0.4564175769686699, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 9510, Loss: 0.4420604959130287, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 9520, Loss: 0.5082171022891998, Accuracy: 51.54, Precision: 0.57, Recall: 0.61\n",
            "Epoch: 0, Batch: 9530, Loss: 0.537522605061531, Accuracy: 51.0, Precision: 0.45, Recall: 0.4\n",
            "Epoch: 0, Batch: 9540, Loss: 0.5569718211889267, Accuracy: 53.2, Precision: 0.42, Recall: 0.3\n",
            "Epoch: 0, Batch: 9550, Loss: 0.5217056542634964, Accuracy: 49.64, Precision: 0.53, Recall: 0.44\n",
            "Epoch: 0, Batch: 9560, Loss: 0.4674394756555557, Accuracy: 49.9, Precision: 0.45, Recall: 0.51\n",
            "Epoch: 0, Batch: 9570, Loss: 0.5714362144470215, Accuracy: 49.76, Precision: 0.53, Recall: 0.46\n",
            "Epoch: 0, Batch: 9580, Loss: 0.5180218160152436, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 9590, Loss: 0.5131560295820237, Accuracy: 50.44, Precision: 0.52, Recall: 0.61\n",
            "Epoch: 0, Batch: 9600, Loss: 0.48057090640068056, Accuracy: 51.68, Precision: 0.43, Recall: 0.38\n",
            "Epoch: 0, Batch: 9610, Loss: 0.5076048776507378, Accuracy: 50.16, Precision: 0.58, Recall: 0.51\n",
            "Epoch: 0, Batch: 9620, Loss: 0.48124136328697203, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 9630, Loss: 0.5448068380355835, Accuracy: 50.12, Precision: 0.49, Recall: 0.44\n",
            "Epoch: 0, Batch: 9640, Loss: 0.5603107541799546, Accuracy: 49.44, Precision: 0.54, Recall: 0.43\n",
            "Epoch: 0, Batch: 9650, Loss: 0.4719767063856125, Accuracy: 51.92, Precision: 0.58, Recall: 0.62\n",
            "Epoch: 0, Batch: 9660, Loss: 0.5011554211378098, Accuracy: 51.2, Precision: 0.56, Recall: 0.6\n",
            "Epoch: 0, Batch: 9670, Loss: 0.4659945100545883, Accuracy: 53.24, Precision: 0.59, Recall: 0.68\n",
            "Epoch: 0, Batch: 9680, Loss: 0.5366736650466919, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 9690, Loss: 0.4781484603881836, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 9700, Loss: 0.612391722202301, Accuracy: 49.82, Precision: 0.59, Recall: 0.49\n",
            "Epoch: 0, Batch: 9710, Loss: 0.5031018674373626, Accuracy: 50.96, Precision: 0.53, Recall: 0.66\n",
            "Epoch: 0, Batch: 9720, Loss: 0.5142575770616531, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 9730, Loss: 0.571994012594223, Accuracy: 50.64, Precision: 0.46, Recall: 0.42\n",
            "Epoch: 0, Batch: 9740, Loss: 0.5135418385267257, Accuracy: 51.04, Precision: 0.46, Recall: 0.37\n",
            "Epoch: 0, Batch: 9750, Loss: 0.5109869778156281, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 9760, Loss: 0.4929178595542908, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 9770, Loss: 0.5113017082214355, Accuracy: 50.56, Precision: 0.43, Recall: 0.46\n",
            "Epoch: 0, Batch: 9780, Loss: 0.5035229653120041, Accuracy: 50.56, Precision: 0.48, Recall: 0.36\n",
            "Epoch: 0, Batch: 9790, Loss: 0.5482753723859787, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 9800, Loss: 0.581918329000473, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 9810, Loss: 0.49672922790050505, Accuracy: 50.16, Precision: 0.46, Recall: 0.48\n",
            "Epoch: 0, Batch: 9820, Loss: 0.5082275748252869, Accuracy: 51.8, Precision: 0.44, Recall: 0.35\n",
            "Epoch: 0, Batch: 9830, Loss: 0.46249885857105255, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 9840, Loss: 0.42484374791383744, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 9850, Loss: 0.5505656227469444, Accuracy: 52.64, Precision: 0.61, Recall: 0.62\n",
            "Epoch: 0, Batch: 9860, Loss: 0.5532532766461372, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 9870, Loss: 0.448716701567173, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 9880, Loss: 0.4923054128885269, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 9890, Loss: 0.43152508437633513, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 9900, Loss: 0.45730607211589813, Accuracy: 50.42, Precision: 0.43, Recall: 0.47\n",
            "Epoch: 0, Batch: 9910, Loss: 0.4858919858932495, Accuracy: 50.28, Precision: 0.49, Recall: 0.36\n",
            "Epoch: 0, Batch: 9920, Loss: 0.43651147186756134, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 9930, Loss: 0.5158615320920944, Accuracy: 50.32, Precision: 0.42, Recall: 0.48\n",
            "Epoch: 0, Batch: 9940, Loss: 0.5173432171344757, Accuracy: 49.52, Precision: 0.56, Recall: 0.46\n",
            "Epoch: 0, Batch: 9950, Loss: 0.4957154214382172, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 9960, Loss: 0.5251264154911042, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 9970, Loss: 0.5212494611740113, Accuracy: 51.26, Precision: 0.41, Recall: 0.43\n",
            "Epoch: 0, Batch: 9980, Loss: 0.5126036807894707, Accuracy: 49.36, Precision: 0.54, Recall: 0.42\n",
            "Epoch: 0, Batch: 9990, Loss: 0.42658444344997404, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 10000, Loss: 0.5318343490362167, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 10010, Loss: 0.5291665703058243, Accuracy: 49.82, Precision: 0.49, Recall: 0.59\n",
            "Epoch: 0, Batch: 10020, Loss: 0.5013872295618057, Accuracy: 49.76, Precision: 0.53, Recall: 0.46\n",
            "Epoch: 0, Batch: 10030, Loss: 0.5132580429315567, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 10040, Loss: 0.47756522297859194, Accuracy: 50.3, Precision: 0.53, Recall: 0.55\n",
            "Epoch: 0, Batch: 10050, Loss: 0.45782415866851806, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 10060, Loss: 0.5394901692867279, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 10070, Loss: 0.4747478514909744, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 10080, Loss: 0.5842817574739456, Accuracy: 49.68, Precision: 0.52, Recall: 0.42\n",
            "Epoch: 0, Batch: 10090, Loss: 0.4727130889892578, Accuracy: 49.64, Precision: 0.41, Recall: 0.52\n",
            "Epoch: 0, Batch: 10100, Loss: 0.4964394301176071, Accuracy: 49.58, Precision: 0.53, Recall: 0.43\n",
            "Epoch: 0, Batch: 10110, Loss: 0.4515994220972061, Accuracy: 50.88, Precision: 0.39, Recall: 0.46\n",
            "Epoch: 0, Batch: 10120, Loss: 0.5327828794717788, Accuracy: 52.94, Precision: 0.43, Recall: 0.29\n",
            "Epoch: 0, Batch: 10130, Loss: 0.5324954718351365, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 10140, Loss: 0.4704991355538368, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 10150, Loss: 0.515981936454773, Accuracy: 50.24, Precision: 0.44, Recall: 0.48\n",
            "Epoch: 0, Batch: 10160, Loss: 0.44406954050064085, Accuracy: 57.82, Precision: 0.33, Recall: 0.27\n",
            "Epoch: 0, Batch: 10170, Loss: 0.4197381317615509, Accuracy: 53.96, Precision: 0.41, Recall: 0.28\n",
            "Epoch: 0, Batch: 10180, Loss: 0.545337775349617, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 10190, Loss: 0.5474426716566085, Accuracy: 49.82, Precision: 0.47, Recall: 0.53\n",
            "Epoch: 0, Batch: 10200, Loss: 0.5724299013614654, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 10210, Loss: 0.5603097051382064, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 10220, Loss: 0.3894071772694588, Accuracy: 51.08, Precision: 0.59, Recall: 0.56\n",
            "Epoch: 0, Batch: 10230, Loss: 0.44710941016674044, Accuracy: 50.14, Precision: 0.51, Recall: 0.57\n",
            "Epoch: 0, Batch: 10240, Loss: 0.508327379822731, Accuracy: 49.7, Precision: 0.53, Recall: 0.45\n",
            "Epoch: 0, Batch: 10250, Loss: 0.49032760560512545, Accuracy: 50.18, Precision: 0.51, Recall: 0.59\n",
            "Epoch: 0, Batch: 10260, Loss: 0.4547171160578728, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 10270, Loss: 0.5068449974060059, Accuracy: 50.48, Precision: 0.48, Recall: 0.38\n",
            "Epoch: 0, Batch: 10280, Loss: 0.47497027516365053, Accuracy: 50.8, Precision: 0.58, Recall: 0.55\n",
            "Epoch: 0, Batch: 10290, Loss: 0.4342736184597015, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 10300, Loss: 0.48493334501981733, Accuracy: 50.7, Precision: 0.57, Recall: 0.55\n",
            "Epoch: 0, Batch: 10310, Loss: 0.4738063871860504, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 10320, Loss: 0.5295309007167817, Accuracy: 52.0, Precision: 0.4, Recall: 0.4\n",
            "Epoch: 0, Batch: 10330, Loss: 0.5245972514152527, Accuracy: 50.8, Precision: 0.48, Recall: 0.3\n",
            "Epoch: 0, Batch: 10340, Loss: 0.549032774567604, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 10350, Loss: 0.47537511885166167, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 10360, Loss: 0.4589105933904648, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 10370, Loss: 0.46414354592561724, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 10380, Loss: 0.4771000578999519, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 10390, Loss: 0.6200373560190201, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 10400, Loss: 0.423256479203701, Accuracy: 51.08, Precision: 0.44, Recall: 0.41\n",
            "Epoch: 0, Batch: 10410, Loss: 0.4978420227766037, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 10420, Loss: 0.487671372294426, Accuracy: 51.32, Precision: 0.44, Recall: 0.39\n",
            "Epoch: 0, Batch: 10430, Loss: 0.42991427183151243, Accuracy: 51.2, Precision: 0.45, Recall: 0.38\n",
            "Epoch: 0, Batch: 10440, Loss: 0.4574389711022377, Accuracy: 52.1, Precision: 0.57, Recall: 0.65\n",
            "Epoch: 0, Batch: 10450, Loss: 0.5625950843095779, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 10460, Loss: 0.5236906915903091, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 10470, Loss: 0.47730256915092467, Accuracy: 50.2, Precision: 0.45, Recall: 0.48\n",
            "Epoch: 0, Batch: 10480, Loss: 0.5386402785778046, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 10490, Loss: 0.47345864176750185, Accuracy: 52.24, Precision: 0.43, Recall: 0.34\n",
            "Epoch: 0, Batch: 10500, Loss: 0.46702615916728973, Accuracy: 49.8, Precision: 0.51, Recall: 0.4\n",
            "Epoch: 0, Batch: 10510, Loss: 0.4623454749584198, Accuracy: 49.82, Precision: 0.47, Recall: 0.53\n",
            "Epoch: 0, Batch: 10520, Loss: 0.4763605177402496, Accuracy: 50.04, Precision: 0.48, Recall: 0.49\n",
            "Epoch: 0, Batch: 10530, Loss: 0.4302601724863052, Accuracy: 51.6, Precision: 0.6, Recall: 0.58\n",
            "Epoch: 0, Batch: 10540, Loss: 0.47846418619155884, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 10550, Loss: 0.45673998147249223, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 10560, Loss: 0.48892935961484907, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 10570, Loss: 0.4753405421972275, Accuracy: 50.0, Precision: 0.55, Recall: 0.5\n",
            "Epoch: 0, Batch: 10580, Loss: 0.4424707397818565, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 10590, Loss: 0.4406643033027649, Accuracy: 49.98, Precision: 0.51, Recall: 0.49\n",
            "Epoch: 0, Batch: 10600, Loss: 0.4923142209649086, Accuracy: 50.8, Precision: 0.58, Recall: 0.55\n",
            "Epoch: 0, Batch: 10610, Loss: 0.47697192132472993, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 10620, Loss: 0.461758017539978, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 10630, Loss: 0.5602456435561181, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 10640, Loss: 0.5226653218269348, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 10650, Loss: 0.4879577875137329, Accuracy: 52.24, Precision: 0.42, Recall: 0.36\n",
            "Epoch: 0, Batch: 10660, Loss: 0.381377837061882, Accuracy: 56.0, Precision: 0.35, Recall: 0.3\n",
            "Epoch: 0, Batch: 10670, Loss: 0.5426155388355255, Accuracy: 49.8, Precision: 0.51, Recall: 0.4\n",
            "Epoch: 0, Batch: 10680, Loss: 0.4201493442058563, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 10690, Loss: 0.6003269910812378, Accuracy: 52.38, Precision: 0.43, Recall: 0.33\n",
            "Epoch: 0, Batch: 10700, Loss: 0.39694325923919677, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 10710, Loss: 0.4813567504286766, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 10720, Loss: 0.4045190379023552, Accuracy: 57.6, Precision: 0.31, Recall: 0.3\n",
            "Epoch: 0, Batch: 10730, Loss: 0.5312872886657715, Accuracy: 51.36, Precision: 0.46, Recall: 0.33\n",
            "Epoch: 0, Batch: 10740, Loss: 0.494901043176651, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 10750, Loss: 0.3895695134997368, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 10760, Loss: 0.5269979119300843, Accuracy: 51.08, Precision: 0.56, Recall: 0.59\n",
            "Epoch: 0, Batch: 10770, Loss: 0.42864868342876433, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 10780, Loss: 0.4811181828379631, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 10790, Loss: 0.5229357719421387, Accuracy: 50.1, Precision: 0.49, Recall: 0.45\n",
            "Epoch: 0, Batch: 10800, Loss: 0.47048030495643617, Accuracy: 51.4, Precision: 0.4, Recall: 0.43\n",
            "Epoch: 0, Batch: 10810, Loss: 0.46464663594961164, Accuracy: 49.34, Precision: 0.53, Recall: 0.39\n",
            "Epoch: 0, Batch: 10820, Loss: 0.5378322005271912, Accuracy: 50.2, Precision: 0.6, Recall: 0.51\n",
            "Epoch: 0, Batch: 10830, Loss: 0.5190201759338379, Accuracy: 49.32, Precision: 0.48, Recall: 0.67\n",
            "Epoch: 0, Batch: 10840, Loss: 0.43341329991817473, Accuracy: 51.56, Precision: 0.44, Recall: 0.37\n",
            "Epoch: 0, Batch: 10850, Loss: 0.5068043023347855, Accuracy: 50.6, Precision: 0.6, Recall: 0.53\n",
            "Epoch: 0, Batch: 10860, Loss: 0.43685178756713866, Accuracy: 49.92, Precision: 0.49, Recall: 0.54\n",
            "Epoch: 0, Batch: 10870, Loss: 0.5391958266496658, Accuracy: 50.96, Precision: 0.42, Recall: 0.44\n",
            "Epoch: 0, Batch: 10880, Loss: 0.5762960582971572, Accuracy: 50.0, Precision: 0.5, Recall: 0.33\n",
            "Epoch: 0, Batch: 10890, Loss: 0.523814257979393, Accuracy: 51.92, Precision: 0.44, Recall: 0.34\n",
            "Epoch: 0, Batch: 10900, Loss: 0.4425588309764862, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 10910, Loss: 0.5677639245986938, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 10920, Loss: 0.4164025545120239, Accuracy: 50.3, Precision: 0.47, Recall: 0.45\n",
            "Epoch: 0, Batch: 10930, Loss: 0.5121323198080063, Accuracy: 50.72, Precision: 0.47, Recall: 0.38\n",
            "Epoch: 0, Batch: 10940, Loss: 0.5514391899108887, Accuracy: 49.88, Precision: 0.51, Recall: 0.44\n",
            "Epoch: 0, Batch: 10950, Loss: 0.4340926453471184, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 10960, Loss: 0.4821272552013397, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 10970, Loss: 0.3739609122276306, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 10980, Loss: 0.40856520235538485, Accuracy: 50.64, Precision: 0.46, Recall: 0.42\n",
            "Epoch: 0, Batch: 10990, Loss: 0.5184350609779358, Accuracy: 49.88, Precision: 0.48, Recall: 0.53\n",
            "Epoch: 0, Batch: 11000, Loss: 0.461469766497612, Accuracy: 51.0, Precision: 0.6, Recall: 0.55\n",
            "Epoch: 0, Batch: 11010, Loss: 0.41224375665187835, Accuracy: 52.1, Precision: 0.57, Recall: 0.65\n",
            "Epoch: 0, Batch: 11020, Loss: 0.532243911921978, Accuracy: 50.0, Precision: 0.41, Recall: 0.5\n",
            "Epoch: 0, Batch: 11030, Loss: 0.5471704542636872, Accuracy: 51.16, Precision: 0.48, Recall: 0.21\n",
            "Epoch: 0, Batch: 11040, Loss: 0.5186643421649932, Accuracy: 49.9, Precision: 0.45, Recall: 0.51\n",
            "Epoch: 0, Batch: 11050, Loss: 0.46467070281505585, Accuracy: 49.88, Precision: 0.47, Recall: 0.52\n",
            "Epoch: 0, Batch: 11060, Loss: 0.5421193599700928, Accuracy: 51.4, Precision: 0.45, Recall: 0.36\n",
            "Epoch: 0, Batch: 11070, Loss: 0.46609289944171906, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 11080, Loss: 0.5255500316619873, Accuracy: 51.3, Precision: 0.63, Recall: 0.55\n",
            "Epoch: 0, Batch: 11090, Loss: 0.40464458614587784, Accuracy: 49.86, Precision: 0.49, Recall: 0.57\n",
            "Epoch: 0, Batch: 11100, Loss: 0.4421148061752319, Accuracy: 54.42, Precision: 0.63, Recall: 0.67\n",
            "Epoch: 0, Batch: 11110, Loss: 0.411393316090107, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 11120, Loss: 0.5037944138050079, Accuracy: 50.16, Precision: 0.49, Recall: 0.42\n",
            "Epoch: 0, Batch: 11130, Loss: 0.4776294767856598, Accuracy: 50.6, Precision: 0.4, Recall: 0.47\n",
            "Epoch: 0, Batch: 11140, Loss: 0.5183244183659553, Accuracy: 50.28, Precision: 0.49, Recall: 0.36\n",
            "Epoch: 0, Batch: 11150, Loss: 0.5689415395259857, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 11160, Loss: 0.5150142669677734, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 11170, Loss: 0.5386034190654755, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 11180, Loss: 0.4840620577335358, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 11190, Loss: 0.4814965516328812, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 11200, Loss: 0.4895875722169876, Accuracy: 51.26, Precision: 0.43, Recall: 0.41\n",
            "Epoch: 0, Batch: 11210, Loss: 0.5077682703733444, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 11220, Loss: 0.5358508944511413, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 11230, Loss: 0.4770877301692963, Accuracy: 49.88, Precision: 0.52, Recall: 0.47\n",
            "Epoch: 0, Batch: 11240, Loss: 0.482514750957489, Accuracy: 50.0, Precision: 0.44, Recall: 0.5\n",
            "Epoch: 0, Batch: 11250, Loss: 0.5144827425479889, Accuracy: 50.16, Precision: 0.49, Recall: 0.42\n",
            "Epoch: 0, Batch: 11260, Loss: 0.4404024213552475, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 11270, Loss: 0.47122977375984193, Accuracy: 49.96, Precision: 0.51, Recall: 0.48\n",
            "Epoch: 0, Batch: 11280, Loss: 0.5669008195400238, Accuracy: 49.84, Precision: 0.46, Recall: 0.52\n",
            "Epoch: 0, Batch: 11290, Loss: 0.49654518961906435, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 11300, Loss: 0.5355581909418106, Accuracy: 49.4, Precision: 0.55, Recall: 0.44\n",
            "Epoch: 0, Batch: 11310, Loss: 0.45731120854616164, Accuracy: 49.7, Precision: 0.47, Recall: 0.55\n",
            "Epoch: 0, Batch: 11320, Loss: 0.572046372294426, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 11330, Loss: 0.490520703792572, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 11340, Loss: 0.5373468488454819, Accuracy: 52.4, Precision: 0.4, Recall: 0.38\n",
            "Epoch: 0, Batch: 11350, Loss: 0.5026080012321472, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 11360, Loss: 0.5201763585209846, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 11370, Loss: 0.49519064724445344, Accuracy: 51.2, Precision: 0.55, Recall: 0.62\n",
            "Epoch: 0, Batch: 11380, Loss: 0.502451604604721, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 11390, Loss: 0.39840716421604155, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 11400, Loss: 0.5170604646205902, Accuracy: 52.24, Precision: 0.42, Recall: 0.36\n",
            "Epoch: 0, Batch: 11410, Loss: 0.4465507581830025, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 11420, Loss: 0.3312506452202797, Accuracy: 49.94, Precision: 0.53, Recall: 0.49\n",
            "Epoch: 0, Batch: 11430, Loss: 0.46690271645784376, Accuracy: 50.64, Precision: 0.54, Recall: 0.58\n",
            "Epoch: 0, Batch: 11440, Loss: 0.5138603657484054, Accuracy: 49.76, Precision: 0.46, Recall: 0.53\n",
            "Epoch: 0, Batch: 11450, Loss: 0.422774538397789, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 11460, Loss: 0.5215038955211639, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 11470, Loss: 0.5869568556547164, Accuracy: 50.48, Precision: 0.42, Recall: 0.47\n",
            "Epoch: 0, Batch: 11480, Loss: 0.5532236784696579, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 11490, Loss: 0.5109307885169982, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 11500, Loss: 0.4255885720252991, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 11510, Loss: 0.5348550885915756, Accuracy: 49.52, Precision: 0.53, Recall: 0.42\n",
            "Epoch: 0, Batch: 11520, Loss: 0.41662718653678893, Accuracy: 50.12, Precision: 0.51, Recall: 0.56\n",
            "Epoch: 0, Batch: 11530, Loss: 0.5299383133649826, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 11540, Loss: 0.4846572935581207, Accuracy: 50.44, Precision: 0.48, Recall: 0.39\n",
            "Epoch: 0, Batch: 11550, Loss: 0.48909778743982313, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 11560, Loss: 0.4484211400151253, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 11570, Loss: 0.3790600419044495, Accuracy: 50.8, Precision: 0.4, Recall: 0.46\n",
            "Epoch: 0, Batch: 11580, Loss: 0.4712984383106232, Accuracy: 50.96, Precision: 0.47, Recall: 0.34\n",
            "Epoch: 0, Batch: 11590, Loss: 0.5089589178562164, Accuracy: 50.48, Precision: 0.44, Recall: 0.46\n",
            "Epoch: 0, Batch: 11600, Loss: 0.52306370139122, Accuracy: 50.64, Precision: 0.46, Recall: 0.42\n",
            "Epoch: 0, Batch: 11610, Loss: 0.49522094428539276, Accuracy: 49.74, Precision: 0.51, Recall: 0.37\n",
            "Epoch: 0, Batch: 11620, Loss: 0.4768838122487068, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 11630, Loss: 0.5036931842565536, Accuracy: 50.8, Precision: 0.55, Recall: 0.58\n",
            "Epoch: 0, Batch: 11640, Loss: 0.47887127101421356, Accuracy: 49.76, Precision: 0.54, Recall: 0.47\n",
            "Epoch: 0, Batch: 11650, Loss: 0.4703038245439529, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 11660, Loss: 0.4084982633590698, Accuracy: 50.24, Precision: 0.52, Recall: 0.56\n",
            "Epoch: 0, Batch: 11670, Loss: 0.39846193939447405, Accuracy: 50.54, Precision: 0.53, Recall: 0.59\n",
            "Epoch: 0, Batch: 11680, Loss: 0.5694136619567871, Accuracy: 49.88, Precision: 0.51, Recall: 0.44\n",
            "Epoch: 0, Batch: 11690, Loss: 0.43338888585567475, Accuracy: 49.86, Precision: 0.57, Recall: 0.49\n",
            "Epoch: 0, Batch: 11700, Loss: 0.515410204231739, Accuracy: 50.6, Precision: 0.53, Recall: 0.6\n",
            "Epoch: 0, Batch: 11710, Loss: 0.44046794921159743, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 11720, Loss: 0.45337938964366914, Accuracy: 51.6, Precision: 0.58, Recall: 0.6\n",
            "Epoch: 0, Batch: 11730, Loss: 0.37239506244659426, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 11740, Loss: 0.5281450003385544, Accuracy: 51.8, Precision: 0.4, Recall: 0.41\n",
            "Epoch: 0, Batch: 11750, Loss: 0.4215479180216789, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 11760, Loss: 0.5683535307645797, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 11770, Loss: 0.5338287472724914, Accuracy: 50.6, Precision: 0.56, Recall: 0.55\n",
            "Epoch: 0, Batch: 11780, Loss: 0.4898086905479431, Accuracy: 50.6, Precision: 0.4, Recall: 0.47\n",
            "Epoch: 0, Batch: 11790, Loss: 0.48148603141307833, Accuracy: 51.8, Precision: 0.45, Recall: 0.32\n",
            "Epoch: 0, Batch: 11800, Loss: 0.5074780285358429, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 11810, Loss: 0.4743949919939041, Accuracy: 51.44, Precision: 0.44, Recall: 0.38\n",
            "Epoch: 0, Batch: 11820, Loss: 0.434223310649395, Accuracy: 50.64, Precision: 0.42, Recall: 0.46\n",
            "Epoch: 0, Batch: 11830, Loss: 0.5541195183992386, Accuracy: 49.48, Precision: 0.52, Recall: 0.37\n",
            "Epoch: 0, Batch: 11840, Loss: 0.543496260046959, Accuracy: 51.54, Precision: 0.43, Recall: 0.39\n",
            "Epoch: 0, Batch: 11850, Loss: 0.4219650447368622, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 11860, Loss: 0.4045805513858795, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 11870, Loss: 0.5204025268554687, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 11880, Loss: 0.46890475898981093, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 11890, Loss: 0.4954713508486748, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 11900, Loss: 0.49294805228710176, Accuracy: 50.12, Precision: 0.56, Recall: 0.51\n",
            "Epoch: 0, Batch: 11910, Loss: 0.458696511387825, Accuracy: 50.3, Precision: 0.47, Recall: 0.45\n",
            "Epoch: 0, Batch: 11920, Loss: 0.42625208795070646, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 11930, Loss: 0.5415718883275986, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 11940, Loss: 0.4908990353345871, Accuracy: 50.84, Precision: 0.57, Recall: 0.56\n",
            "Epoch: 0, Batch: 11950, Loss: 0.492596361041069, Accuracy: 52.86, Precision: 0.39, Recall: 0.37\n",
            "Epoch: 0, Batch: 11960, Loss: 0.5183830916881561, Accuracy: 49.12, Precision: 0.54, Recall: 0.39\n",
            "Epoch: 0, Batch: 11970, Loss: 0.5949215173721314, Accuracy: 49.68, Precision: 0.48, Recall: 0.58\n",
            "Epoch: 0, Batch: 11980, Loss: 0.5047772467136383, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 11990, Loss: 0.4956140726804733, Accuracy: 50.24, Precision: 0.49, Recall: 0.38\n",
            "Epoch: 0, Batch: 12000, Loss: 0.41392607390880587, Accuracy: 50.2, Precision: 0.45, Recall: 0.48\n",
            "Epoch: 0, Batch: 12010, Loss: 0.48245631754398344, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 12020, Loss: 0.5354363799095154, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 12030, Loss: 0.46210670471191406, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 12040, Loss: 0.39643008857965467, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 12050, Loss: 0.4747199431061745, Accuracy: 49.88, Precision: 0.47, Recall: 0.52\n",
            "Epoch: 0, Batch: 12060, Loss: 0.4693174779415131, Accuracy: 49.9, Precision: 0.51, Recall: 0.45\n",
            "Epoch: 0, Batch: 12070, Loss: 0.49485494792461393, Accuracy: 51.6, Precision: 0.45, Recall: 0.34\n",
            "Epoch: 0, Batch: 12080, Loss: 0.5592843472957612, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 12090, Loss: 0.5252982169389725, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 12100, Loss: 0.43692359030246736, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 12110, Loss: 0.4893744088709354, Accuracy: 51.26, Precision: 0.43, Recall: 0.41\n",
            "Epoch: 0, Batch: 12120, Loss: 0.49734059125185015, Accuracy: 50.28, Precision: 0.57, Recall: 0.52\n",
            "Epoch: 0, Batch: 12130, Loss: 0.4215715914964676, Accuracy: 50.4, Precision: 0.55, Recall: 0.54\n",
            "Epoch: 0, Batch: 12140, Loss: 0.4691344559192657, Accuracy: 51.12, Precision: 0.43, Recall: 0.42\n",
            "Epoch: 0, Batch: 12150, Loss: 0.4510694921016693, Accuracy: 50.0, Precision: 0.5, Recall: 0.41\n",
            "Epoch: 0, Batch: 12160, Loss: 0.34509619176387785, Accuracy: 51.0, Precision: 0.55, Recall: 0.6\n",
            "Epoch: 0, Batch: 12170, Loss: 0.5320663899183273, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 12180, Loss: 0.6551776766777039, Accuracy: 50.04, Precision: 0.48, Recall: 0.49\n",
            "Epoch: 0, Batch: 12190, Loss: 0.4063252195715904, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 12200, Loss: 0.48308428972959516, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 12210, Loss: 0.4634914830327034, Accuracy: 50.32, Precision: 0.42, Recall: 0.48\n",
            "Epoch: 0, Batch: 12220, Loss: 0.4306460961699486, Accuracy: 50.2, Precision: 0.52, Recall: 0.55\n",
            "Epoch: 0, Batch: 12230, Loss: 0.5099820554256439, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 12240, Loss: 0.49260297417640686, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 12250, Loss: 0.46065826117992403, Accuracy: 50.3, Precision: 0.47, Recall: 0.45\n",
            "Epoch: 0, Batch: 12260, Loss: 0.5236220240592957, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 12270, Loss: 0.4493952751159668, Accuracy: 51.4, Precision: 0.55, Recall: 0.64\n",
            "Epoch: 0, Batch: 12280, Loss: 0.4844063714146614, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 12290, Loss: 0.34225466549396516, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 12300, Loss: 0.436648428440094, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 12310, Loss: 0.4690147936344147, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 12320, Loss: 0.4179836377501488, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 12330, Loss: 0.48015491366386415, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 12340, Loss: 0.49415438920259475, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 12350, Loss: 0.515538626909256, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 12360, Loss: 0.5738880693912506, Accuracy: 50.84, Precision: 0.47, Recall: 0.36\n",
            "Epoch: 0, Batch: 12370, Loss: 0.4893797516822815, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 12380, Loss: 0.49535765647888186, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 12390, Loss: 0.4485960558056831, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 12400, Loss: 0.39270955324172974, Accuracy: 50.84, Precision: 0.43, Recall: 0.44\n",
            "Epoch: 0, Batch: 12410, Loss: 0.46952980756759644, Accuracy: 50.64, Precision: 0.46, Recall: 0.42\n",
            "Epoch: 0, Batch: 12420, Loss: 0.4571111649274826, Accuracy: 52.52, Precision: 0.41, Recall: 0.36\n",
            "Epoch: 0, Batch: 12430, Loss: 0.3811519965529442, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 12440, Loss: 0.5049968808889389, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 12450, Loss: 0.5449335172772407, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 12460, Loss: 0.49303570091724397, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 12470, Loss: 0.402848955988884, Accuracy: 49.46, Precision: 0.41, Recall: 0.53\n",
            "Epoch: 0, Batch: 12480, Loss: 0.5157689154148102, Accuracy: 50.24, Precision: 0.49, Recall: 0.38\n",
            "Epoch: 0, Batch: 12490, Loss: 0.5418128192424774, Accuracy: 49.72, Precision: 0.52, Recall: 0.43\n",
            "Epoch: 0, Batch: 12500, Loss: 0.46690243780612944, Accuracy: 49.84, Precision: 0.42, Recall: 0.51\n",
            "Epoch: 0, Batch: 12510, Loss: 0.5438428357243538, Accuracy: 49.92, Precision: 0.54, Recall: 0.49\n",
            "Epoch: 0, Batch: 12520, Loss: 0.41836330443620684, Accuracy: 51.6, Precision: 0.42, Recall: 0.4\n",
            "Epoch: 0, Batch: 12530, Loss: 0.41624460816383363, Accuracy: 54.48, Precision: 0.36, Recall: 0.34\n",
            "Epoch: 0, Batch: 12540, Loss: 0.46452818214893343, Accuracy: 50.0, Precision: 0.5, Recall: 0.38\n",
            "Epoch: 0, Batch: 12550, Loss: 0.4998000502586365, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 12560, Loss: 0.4835834577679634, Accuracy: 53.12, Precision: 0.38, Recall: 0.37\n",
            "Epoch: 0, Batch: 12570, Loss: 0.36502247899770734, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 12580, Loss: 0.5565074846148491, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 12590, Loss: 0.49034543335437775, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 12600, Loss: 0.4374771684408188, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 12610, Loss: 0.4711996287107468, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 12620, Loss: 0.4510639399290085, Accuracy: 50.0, Precision: 0.57, Recall: 0.5\n",
            "Epoch: 0, Batch: 12630, Loss: 0.4993919268250465, Accuracy: 49.8, Precision: 0.55, Recall: 0.48\n",
            "Epoch: 0, Batch: 12640, Loss: 0.520192950963974, Accuracy: 51.36, Precision: 0.54, Recall: 0.67\n",
            "Epoch: 0, Batch: 12650, Loss: 0.4328094869852066, Accuracy: 51.54, Precision: 0.57, Recall: 0.61\n",
            "Epoch: 0, Batch: 12660, Loss: 0.4341191828250885, Accuracy: 50.56, Precision: 0.57, Recall: 0.54\n",
            "Epoch: 0, Batch: 12670, Loss: 0.41882416754961016, Accuracy: 50.72, Precision: 0.54, Recall: 0.59\n",
            "Epoch: 0, Batch: 12680, Loss: 0.520309628546238, Accuracy: 50.7, Precision: 0.43, Recall: 0.45\n",
            "Epoch: 0, Batch: 12690, Loss: 0.41619947254657746, Accuracy: 50.4, Precision: 0.6, Recall: 0.52\n",
            "Epoch: 0, Batch: 12700, Loss: 0.4918597310781479, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 12710, Loss: 0.44124959111213685, Accuracy: 51.2, Precision: 0.4, Recall: 0.44\n",
            "Epoch: 0, Batch: 12720, Loss: 0.5211353808641433, Accuracy: 49.16, Precision: 0.57, Recall: 0.44\n",
            "Epoch: 0, Batch: 12730, Loss: 0.6565226256847382, Accuracy: 50.3, Precision: 0.53, Recall: 0.55\n",
            "Epoch: 0, Batch: 12740, Loss: 0.41467555016279223, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 12750, Loss: 0.5522499084472656, Accuracy: 53.6, Precision: 0.4, Recall: 0.32\n",
            "Epoch: 0, Batch: 12760, Loss: 0.45373998284339906, Accuracy: 49.5, Precision: 0.55, Recall: 0.45\n",
            "Epoch: 0, Batch: 12770, Loss: 0.37991648018360136, Accuracy: 49.28, Precision: 0.46, Recall: 0.59\n",
            "Epoch: 0, Batch: 12780, Loss: 0.5420180350542069, Accuracy: 51.28, Precision: 0.42, Recall: 0.42\n",
            "Epoch: 0, Batch: 12790, Loss: 0.44333450198173524, Accuracy: 49.8, Precision: 0.55, Recall: 0.48\n",
            "Epoch: 0, Batch: 12800, Loss: 0.4369824767112732, Accuracy: 49.5, Precision: 0.55, Recall: 0.45\n",
            "Epoch: 0, Batch: 12810, Loss: 0.45451897382736206, Accuracy: 51.1, Precision: 0.55, Recall: 0.61\n",
            "Epoch: 0, Batch: 12820, Loss: 0.524860805273056, Accuracy: 49.28, Precision: 0.44, Recall: 0.56\n",
            "Epoch: 0, Batch: 12830, Loss: 0.4041602075099945, Accuracy: 50.36, Precision: 0.59, Recall: 0.52\n",
            "Epoch: 0, Batch: 12840, Loss: 0.47896924763917925, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 12850, Loss: 0.5902261555194854, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 12860, Loss: 0.423049134016037, Accuracy: 50.0, Precision: 0.5, Recall: 0.42\n",
            "Epoch: 0, Batch: 12870, Loss: 0.46196867525577545, Accuracy: 50.84, Precision: 0.56, Recall: 0.57\n",
            "Epoch: 0, Batch: 12880, Loss: 0.4438938319683075, Accuracy: 50.72, Precision: 0.53, Recall: 0.62\n",
            "Epoch: 0, Batch: 12890, Loss: 0.5770590335130692, Accuracy: 51.32, Precision: 0.56, Recall: 0.61\n",
            "Epoch: 0, Batch: 12900, Loss: 0.4078367352485657, Accuracy: 53.38, Precision: 0.63, Recall: 0.63\n",
            "Epoch: 0, Batch: 12910, Loss: 0.5317815259099007, Accuracy: 49.92, Precision: 0.46, Recall: 0.51\n",
            "Epoch: 0, Batch: 12920, Loss: 0.4895887583494186, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 12930, Loss: 0.4502679318189621, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 12940, Loss: 0.5371519923210144, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 12950, Loss: 0.49804501980543137, Accuracy: 49.92, Precision: 0.49, Recall: 0.54\n",
            "Epoch: 0, Batch: 12960, Loss: 0.49746142625808715, Accuracy: 52.0, Precision: 0.4, Recall: 0.4\n",
            "Epoch: 0, Batch: 12970, Loss: 0.4343114733695984, Accuracy: 50.7, Precision: 0.45, Recall: 0.43\n",
            "Epoch: 0, Batch: 12980, Loss: 0.6239242911338806, Accuracy: 48.92, Precision: 0.53, Recall: 0.32\n",
            "Epoch: 0, Batch: 12990, Loss: 0.46843846440315245, Accuracy: 50.8, Precision: 0.54, Recall: 0.6\n",
            "Epoch: 0, Batch: 13000, Loss: 0.46518245339393616, Accuracy: 50.16, Precision: 0.51, Recall: 0.58\n",
            "Epoch: 0, Batch: 13010, Loss: 0.46513636261224744, Accuracy: 49.76, Precision: 0.53, Recall: 0.46\n",
            "Epoch: 0, Batch: 13020, Loss: 0.4502533346414566, Accuracy: 50.06, Precision: 0.53, Recall: 0.51\n",
            "Epoch: 0, Batch: 13030, Loss: 0.42681691944599154, Accuracy: 52.6, Precision: 0.6, Recall: 0.63\n",
            "Epoch: 0, Batch: 13040, Loss: 0.4808583289384842, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 13050, Loss: 0.44403848946094515, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 13060, Loss: 0.5781516343355179, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 13070, Loss: 0.4230548456311226, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 13080, Loss: 0.4022007703781128, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 13090, Loss: 0.4984306782484055, Accuracy: 49.0, Precision: 0.45, Recall: 0.6\n",
            "Epoch: 0, Batch: 13100, Loss: 0.40588117241859434, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 13110, Loss: 0.44719323217868806, Accuracy: 50.36, Precision: 0.59, Recall: 0.52\n",
            "Epoch: 0, Batch: 13120, Loss: 0.5098666399717331, Accuracy: 49.72, Precision: 0.48, Recall: 0.57\n",
            "Epoch: 0, Batch: 13130, Loss: 0.4592463061213493, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 13140, Loss: 0.4353927507996559, Accuracy: 51.68, Precision: 0.43, Recall: 0.38\n",
            "Epoch: 0, Batch: 13150, Loss: 0.4924059063196182, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 13160, Loss: 0.47325508296489716, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 13170, Loss: 0.4970729619264603, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 13180, Loss: 0.44406654238700866, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 13190, Loss: 0.5108031451702117, Accuracy: 50.4, Precision: 0.55, Recall: 0.54\n",
            "Epoch: 0, Batch: 13200, Loss: 0.38555134534835817, Accuracy: 50.36, Precision: 0.52, Recall: 0.59\n",
            "Epoch: 0, Batch: 13210, Loss: 0.4559087008237839, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 13220, Loss: 0.5845055460929871, Accuracy: 50.36, Precision: 0.59, Recall: 0.52\n",
            "Epoch: 0, Batch: 13230, Loss: 0.5623983383178711, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 13240, Loss: 0.5624020218849182, Accuracy: 50.18, Precision: 0.41, Recall: 0.49\n",
            "Epoch: 0, Batch: 13250, Loss: 0.35902191549539564, Accuracy: 51.32, Precision: 0.44, Recall: 0.39\n",
            "Epoch: 0, Batch: 13260, Loss: 0.5816366642713546, Accuracy: 48.2, Precision: 0.59, Recall: 0.4\n",
            "Epoch: 0, Batch: 13270, Loss: 0.5065411433577538, Accuracy: 49.8, Precision: 0.49, Recall: 0.6\n",
            "Epoch: 0, Batch: 13280, Loss: 0.5127049088478088, Accuracy: 50.96, Precision: 0.54, Recall: 0.62\n",
            "Epoch: 0, Batch: 13290, Loss: 0.444348481297493, Accuracy: 51.2, Precision: 0.44, Recall: 0.4\n",
            "Epoch: 0, Batch: 13300, Loss: 0.5487427592277527, Accuracy: 50.52, Precision: 0.48, Recall: 0.37\n",
            "Epoch: 0, Batch: 13310, Loss: 0.4659621402621269, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 13320, Loss: 0.4171681448817253, Accuracy: 49.88, Precision: 0.47, Recall: 0.52\n",
            "Epoch: 0, Batch: 13330, Loss: 0.44198846220970156, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 13340, Loss: 0.47344523668289185, Accuracy: 50.7, Precision: 0.45, Recall: 0.43\n",
            "Epoch: 0, Batch: 13350, Loss: 0.45016416907310486, Accuracy: 51.08, Precision: 0.44, Recall: 0.41\n",
            "Epoch: 0, Batch: 13360, Loss: 0.4525412917137146, Accuracy: 50.48, Precision: 0.44, Recall: 0.46\n",
            "Epoch: 0, Batch: 13370, Loss: 0.4444217249751091, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 13380, Loss: 0.4313305586576462, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 13390, Loss: 0.5568687945604325, Accuracy: 49.76, Precision: 0.46, Recall: 0.53\n",
            "Epoch: 0, Batch: 13400, Loss: 0.539234733581543, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 13410, Loss: 0.5418168634176255, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 13420, Loss: 0.5806044906377792, Accuracy: 51.08, Precision: 0.44, Recall: 0.41\n",
            "Epoch: 0, Batch: 13430, Loss: 0.5752101361751556, Accuracy: 50.48, Precision: 0.44, Recall: 0.46\n",
            "Epoch: 0, Batch: 13440, Loss: 0.453840383887291, Accuracy: 50.56, Precision: 0.43, Recall: 0.46\n",
            "Epoch: 0, Batch: 13450, Loss: 0.4697790265083313, Accuracy: 50.6, Precision: 0.6, Recall: 0.53\n",
            "Epoch: 0, Batch: 13460, Loss: 0.5021776378154754, Accuracy: 49.86, Precision: 0.43, Recall: 0.51\n",
            "Epoch: 0, Batch: 13470, Loss: 0.4301511198282242, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 13480, Loss: 0.5057208716869355, Accuracy: 51.7, Precision: 0.45, Recall: 0.33\n",
            "Epoch: 0, Batch: 13490, Loss: 0.4207720547914505, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 13500, Loss: 0.4804492011666298, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 13510, Loss: 0.4954870969057083, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 13520, Loss: 0.43728983253240583, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 13530, Loss: 0.49743413031101225, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 13540, Loss: 0.5354523897171021, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 13550, Loss: 0.4781283050775528, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 13560, Loss: 0.5246653497219086, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 13570, Loss: 0.5413399741053582, Accuracy: 50.28, Precision: 0.43, Recall: 0.48\n",
            "Epoch: 0, Batch: 13580, Loss: 0.46724480092525483, Accuracy: 49.9, Precision: 0.55, Recall: 0.49\n",
            "Epoch: 0, Batch: 13590, Loss: 0.4670725777745247, Accuracy: 51.2, Precision: 0.44, Recall: 0.4\n",
            "Epoch: 0, Batch: 13600, Loss: 0.5249992147088051, Accuracy: 49.76, Precision: 0.56, Recall: 0.48\n",
            "Epoch: 0, Batch: 13610, Loss: 0.4235442250967026, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 13620, Loss: 0.5489357233047485, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 13630, Loss: 0.4269946992397308, Accuracy: 49.82, Precision: 0.59, Recall: 0.49\n",
            "Epoch: 0, Batch: 13640, Loss: 0.5567836195230484, Accuracy: 49.56, Precision: 0.39, Recall: 0.52\n",
            "Epoch: 0, Batch: 13650, Loss: 0.5389530271291733, Accuracy: 51.92, Precision: 0.42, Recall: 0.38\n",
            "Epoch: 0, Batch: 13660, Loss: 0.48646249175071715, Accuracy: 49.04, Precision: 0.56, Recall: 0.42\n",
            "Epoch: 0, Batch: 13670, Loss: 0.4409021198749542, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 13680, Loss: 0.3942694991827011, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 13690, Loss: 0.5158347249031067, Accuracy: 49.82, Precision: 0.51, Recall: 0.41\n",
            "Epoch: 0, Batch: 13700, Loss: 0.565160608291626, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 13710, Loss: 0.5413075000047683, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 13720, Loss: 0.49315579831600187, Accuracy: 49.9, Precision: 0.51, Recall: 0.45\n",
            "Epoch: 0, Batch: 13730, Loss: 0.5043013989925385, Accuracy: 49.92, Precision: 0.51, Recall: 0.46\n",
            "Epoch: 0, Batch: 13740, Loss: 0.49236185252666476, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 13750, Loss: 0.5191925033926964, Accuracy: 50.36, Precision: 0.44, Recall: 0.47\n",
            "Epoch: 0, Batch: 13760, Loss: 0.4871879622340202, Accuracy: 49.2, Precision: 0.58, Recall: 0.45\n",
            "Epoch: 0, Batch: 13770, Loss: 0.5292826682329178, Accuracy: 50.0, Precision: 0.45, Recall: 0.5\n",
            "Epoch: 0, Batch: 13780, Loss: 0.4395693868398666, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 13790, Loss: 0.4800297304987907, Accuracy: 49.84, Precision: 0.58, Recall: 0.49\n",
            "Epoch: 0, Batch: 13800, Loss: 0.43338600993156434, Accuracy: 50.64, Precision: 0.54, Recall: 0.58\n",
            "Epoch: 0, Batch: 13810, Loss: 0.44185161888599395, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 13820, Loss: 0.4428636223077774, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 13830, Loss: 0.4002567887306213, Accuracy: 50.24, Precision: 0.48, Recall: 0.44\n",
            "Epoch: 0, Batch: 13840, Loss: 0.532069307565689, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 13850, Loss: 0.40244566798210146, Accuracy: 53.08, Precision: 0.36, Recall: 0.39\n",
            "Epoch: 0, Batch: 13860, Loss: 0.5507868885993957, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 13870, Loss: 0.47984118163585665, Accuracy: 50.2, Precision: 0.52, Recall: 0.55\n",
            "Epoch: 0, Batch: 13880, Loss: 0.5106323853135109, Accuracy: 51.6, Precision: 0.58, Recall: 0.6\n",
            "Epoch: 0, Batch: 13890, Loss: 0.4823197484016418, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 13900, Loss: 0.4758908778429031, Accuracy: 50.16, Precision: 0.46, Recall: 0.48\n",
            "Epoch: 0, Batch: 13910, Loss: 0.4539087235927582, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 13920, Loss: 0.3878846377134323, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 13930, Loss: 0.5200934261083603, Accuracy: 49.72, Precision: 0.48, Recall: 0.57\n",
            "Epoch: 0, Batch: 13940, Loss: 0.4723572537302971, Accuracy: 49.6, Precision: 0.55, Recall: 0.46\n",
            "Epoch: 0, Batch: 13950, Loss: 0.48480099588632586, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 13960, Loss: 0.5878360509872437, Accuracy: 49.76, Precision: 0.47, Recall: 0.54\n",
            "Epoch: 0, Batch: 13970, Loss: 0.46035876870155334, Accuracy: 49.76, Precision: 0.52, Recall: 0.44\n",
            "Epoch: 0, Batch: 13980, Loss: 0.39043867364525797, Accuracy: 52.56, Precision: 0.42, Recall: 0.34\n",
            "Epoch: 0, Batch: 13990, Loss: 0.4770476847887039, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 14000, Loss: 0.512053269147873, Accuracy: 50.0, Precision: 0.41, Recall: 0.5\n",
            "Epoch: 0, Batch: 14010, Loss: 0.5038143187761307, Accuracy: 50.2, Precision: 0.49, Recall: 0.4\n",
            "Epoch: 0, Batch: 14020, Loss: 0.4860280305147171, Accuracy: 49.64, Precision: 0.56, Recall: 0.47\n",
            "Epoch: 0, Batch: 14030, Loss: 0.42703723162412643, Accuracy: 50.7, Precision: 0.55, Recall: 0.57\n",
            "Epoch: 0, Batch: 14040, Loss: 0.4420748382806778, Accuracy: 50.0, Precision: 0.5, Recall: 0.57\n",
            "Epoch: 0, Batch: 14050, Loss: 0.43243466764688493, Accuracy: 50.14, Precision: 0.43, Recall: 0.49\n",
            "Epoch: 0, Batch: 14060, Loss: 0.4875244587659836, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 14070, Loss: 0.48359561562538145, Accuracy: 49.82, Precision: 0.47, Recall: 0.53\n",
            "Epoch: 0, Batch: 14080, Loss: 0.33384767435491086, Accuracy: 52.6, Precision: 0.4, Recall: 0.37\n",
            "Epoch: 0, Batch: 14090, Loss: 0.5409746825695038, Accuracy: 49.88, Precision: 0.52, Recall: 0.47\n",
            "Epoch: 0, Batch: 14100, Loss: 0.40662023425102234, Accuracy: 50.72, Precision: 0.59, Recall: 0.54\n",
            "Epoch: 0, Batch: 14110, Loss: 0.41569755524396895, Accuracy: 49.7, Precision: 0.47, Recall: 0.55\n",
            "Epoch: 0, Batch: 14120, Loss: 0.5714365631341934, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 14130, Loss: 0.47170685082674024, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 14140, Loss: 0.40347047448158263, Accuracy: 50.98, Precision: 0.57, Recall: 0.57\n",
            "Epoch: 0, Batch: 14150, Loss: 0.5117690742015839, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 14160, Loss: 0.5076724261045455, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 14170, Loss: 0.4638306021690369, Accuracy: 50.0, Precision: 0.5, Recall: 0.56\n",
            "Epoch: 0, Batch: 14180, Loss: 0.5682197451591492, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 14190, Loss: 0.44324049800634385, Accuracy: 49.92, Precision: 0.51, Recall: 0.46\n",
            "Epoch: 0, Batch: 14200, Loss: 0.5333615809679031, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 14210, Loss: 0.528728312253952, Accuracy: 50.8, Precision: 0.58, Recall: 0.55\n",
            "Epoch: 0, Batch: 14220, Loss: 0.4474728927016258, Accuracy: 49.2, Precision: 0.42, Recall: 0.55\n",
            "Epoch: 0, Batch: 14230, Loss: 0.45359255373477936, Accuracy: 50.2, Precision: 0.49, Recall: 0.4\n",
            "Epoch: 0, Batch: 14240, Loss: 0.4336947530508041, Accuracy: 50.26, Precision: 0.49, Recall: 0.37\n",
            "Epoch: 0, Batch: 14250, Loss: 0.5499215483665466, Accuracy: 50.48, Precision: 0.58, Recall: 0.53\n",
            "Epoch: 0, Batch: 14260, Loss: 0.45940129905939103, Accuracy: 50.0, Precision: 0.5, Recall: 0.56\n",
            "Epoch: 0, Batch: 14270, Loss: 0.4391717329621315, Accuracy: 50.98, Precision: 0.57, Recall: 0.57\n",
            "Epoch: 0, Batch: 14280, Loss: 0.41163571625947953, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 14290, Loss: 0.49448794424533843, Accuracy: 50.1, Precision: 0.49, Recall: 0.45\n",
            "Epoch: 0, Batch: 14300, Loss: 0.370537069439888, Accuracy: 51.68, Precision: 0.57, Recall: 0.62\n",
            "Epoch: 0, Batch: 14310, Loss: 0.4277327865362167, Accuracy: 49.76, Precision: 0.47, Recall: 0.54\n",
            "Epoch: 0, Batch: 14320, Loss: 0.4565629750490189, Accuracy: 49.88, Precision: 0.52, Recall: 0.47\n",
            "Epoch: 0, Batch: 14330, Loss: 0.5722231388092041, Accuracy: 51.2, Precision: 0.44, Recall: 0.4\n",
            "Epoch: 0, Batch: 14340, Loss: 0.4945198267698288, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 14350, Loss: 0.48421874046325686, Accuracy: 52.56, Precision: 0.42, Recall: 0.34\n",
            "Epoch: 0, Batch: 14360, Loss: 0.3891359344124794, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 14370, Loss: 0.49560352265834806, Accuracy: 50.16, Precision: 0.51, Recall: 0.58\n",
            "Epoch: 0, Batch: 14380, Loss: 0.49811847805976867, Accuracy: 50.36, Precision: 0.44, Recall: 0.47\n",
            "Epoch: 0, Batch: 14390, Loss: 0.4348810836672783, Accuracy: 50.48, Precision: 0.47, Recall: 0.42\n",
            "Epoch: 0, Batch: 14400, Loss: 0.45490299463272094, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 14410, Loss: 0.4363029167056084, Accuracy: 50.18, Precision: 0.51, Recall: 0.59\n",
            "Epoch: 0, Batch: 14420, Loss: 0.554242205619812, Accuracy: 50.4, Precision: 0.52, Recall: 0.6\n",
            "Epoch: 0, Batch: 14430, Loss: 0.5169559955596924, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 14440, Loss: 0.44353300482034685, Accuracy: 51.26, Precision: 0.41, Recall: 0.43\n",
            "Epoch: 0, Batch: 14450, Loss: 0.4033324494957924, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 14460, Loss: 0.4499453216791153, Accuracy: 49.5, Precision: 0.55, Recall: 0.45\n",
            "Epoch: 0, Batch: 14470, Loss: 0.5334005638957023, Accuracy: 50.54, Precision: 0.53, Recall: 0.59\n",
            "Epoch: 0, Batch: 14480, Loss: 0.392488956451416, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 14490, Loss: 0.45168801844120027, Accuracy: 50.0, Precision: 0.55, Recall: 0.5\n",
            "Epoch: 0, Batch: 14500, Loss: 0.5248453080654144, Accuracy: 50.88, Precision: 0.54, Recall: 0.61\n",
            "Epoch: 0, Batch: 14510, Loss: 0.3923636540770531, Accuracy: 49.76, Precision: 0.52, Recall: 0.44\n",
            "Epoch: 0, Batch: 14520, Loss: 0.5841150879859924, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 14530, Loss: 0.45990381240844724, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 14540, Loss: 0.45985321551561353, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 14550, Loss: 0.576603677868843, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 14560, Loss: 0.4724724531173706, Accuracy: 50.48, Precision: 0.47, Recall: 0.42\n",
            "Epoch: 0, Batch: 14570, Loss: 0.47361322343349455, Accuracy: 49.72, Precision: 0.52, Recall: 0.43\n",
            "Epoch: 0, Batch: 14580, Loss: 0.48838443458080294, Accuracy: 50.72, Precision: 0.56, Recall: 0.56\n",
            "Epoch: 0, Batch: 14590, Loss: 0.44711625576019287, Accuracy: 50.12, Precision: 0.51, Recall: 0.56\n",
            "Epoch: 0, Batch: 14600, Loss: 0.4098878875374794, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 14610, Loss: 0.4581577405333519, Accuracy: 49.96, Precision: 0.51, Recall: 0.48\n",
            "Epoch: 0, Batch: 14620, Loss: 0.5590804308652878, Accuracy: 50.14, Precision: 0.57, Recall: 0.51\n",
            "Epoch: 0, Batch: 14630, Loss: 0.49594151228666306, Accuracy: 49.7, Precision: 0.45, Recall: 0.53\n",
            "Epoch: 0, Batch: 14640, Loss: 0.3689835757017136, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 14650, Loss: 0.45635769963264466, Accuracy: 49.78, Precision: 0.51, Recall: 0.39\n",
            "Epoch: 0, Batch: 14660, Loss: 0.46456862092018125, Accuracy: 51.44, Precision: 0.56, Recall: 0.62\n",
            "Epoch: 0, Batch: 14670, Loss: 0.4545320928096771, Accuracy: 50.2, Precision: 0.51, Recall: 0.6\n",
            "Epoch: 0, Batch: 14680, Loss: 0.4897213488817215, Accuracy: 50.2, Precision: 0.49, Recall: 0.4\n",
            "Epoch: 0, Batch: 14690, Loss: 0.4836827337741852, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 14700, Loss: 0.47437314689159393, Accuracy: 51.12, Precision: 0.43, Recall: 0.42\n",
            "Epoch: 0, Batch: 14710, Loss: 0.4349824398756027, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 14720, Loss: 0.4295702397823334, Accuracy: 50.32, Precision: 0.42, Recall: 0.48\n",
            "Epoch: 0, Batch: 14730, Loss: 0.5057918488979339, Accuracy: 49.78, Precision: 0.51, Recall: 0.39\n",
            "Epoch: 0, Batch: 14740, Loss: 0.4974343866109848, Accuracy: 50.0, Precision: 0.5, Recall: 0.35\n",
            "Epoch: 0, Batch: 14750, Loss: 0.47090548276901245, Accuracy: 49.28, Precision: 0.44, Recall: 0.56\n",
            "Epoch: 0, Batch: 14760, Loss: 0.43761929869651794, Accuracy: 51.56, Precision: 0.44, Recall: 0.37\n",
            "Epoch: 0, Batch: 14770, Loss: 0.4847945600748062, Accuracy: 51.44, Precision: 0.41, Recall: 0.42\n",
            "Epoch: 0, Batch: 14780, Loss: 0.4799404889345169, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 14790, Loss: 0.4815083980560303, Accuracy: 52.86, Precision: 0.39, Recall: 0.37\n",
            "Epoch: 0, Batch: 14800, Loss: 0.5141448542475701, Accuracy: 49.9, Precision: 0.55, Recall: 0.49\n",
            "Epoch: 0, Batch: 14810, Loss: 0.5316007167100907, Accuracy: 49.46, Precision: 0.47, Recall: 0.59\n",
            "Epoch: 0, Batch: 14820, Loss: 0.39604525119066236, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 14830, Loss: 0.5149253219366073, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 14840, Loss: 0.40088552683591844, Accuracy: 50.72, Precision: 0.62, Recall: 0.53\n",
            "Epoch: 0, Batch: 14850, Loss: 0.4506455630064011, Accuracy: 49.72, Precision: 0.43, Recall: 0.52\n",
            "Epoch: 0, Batch: 14860, Loss: 0.5070630222558975, Accuracy: 50.12, Precision: 0.44, Recall: 0.49\n",
            "Epoch: 0, Batch: 14870, Loss: 0.4823332726955414, Accuracy: 49.76, Precision: 0.54, Recall: 0.47\n",
            "Epoch: 0, Batch: 14880, Loss: 0.5116491258144379, Accuracy: 51.0, Precision: 0.45, Recall: 0.4\n",
            "Epoch: 0, Batch: 14890, Loss: 0.4178899943828583, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 14900, Loss: 0.3447893589735031, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 14910, Loss: 0.4236671358346939, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 14920, Loss: 0.4409731075167656, Accuracy: 51.98, Precision: 0.39, Recall: 0.41\n",
            "Epoch: 0, Batch: 14930, Loss: 0.5207797378301621, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 14940, Loss: 0.5444290816783905, Accuracy: 50.48, Precision: 0.47, Recall: 0.42\n",
            "Epoch: 0, Batch: 14950, Loss: 0.5154191792011261, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 14960, Loss: 0.5648868307471275, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 14970, Loss: 0.5487729728221893, Accuracy: 49.86, Precision: 0.49, Recall: 0.57\n",
            "Epoch: 0, Batch: 14980, Loss: 0.5301390796899795, Accuracy: 49.6, Precision: 0.52, Recall: 0.4\n",
            "Epoch: 0, Batch: 14990, Loss: 0.4887191116809845, Accuracy: 49.7, Precision: 0.55, Recall: 0.47\n",
            "Epoch: 0, Batch: 15000, Loss: 0.4347014307975769, Accuracy: 51.28, Precision: 0.58, Recall: 0.58\n",
            "Epoch: 0, Batch: 15010, Loss: 0.43310806155204773, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 15020, Loss: 0.5529185593128204, Accuracy: 50.0, Precision: 0.54, Recall: 0.5\n",
            "Epoch: 0, Batch: 15030, Loss: 0.4208223357796669, Accuracy: 50.96, Precision: 0.47, Recall: 0.34\n",
            "Epoch: 0, Batch: 15040, Loss: 0.4006771594285965, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 15050, Loss: 0.41860264390707014, Accuracy: 50.18, Precision: 0.51, Recall: 0.59\n",
            "Epoch: 0, Batch: 15060, Loss: 0.6005290687084198, Accuracy: 50.22, Precision: 0.49, Recall: 0.39\n",
            "Epoch: 0, Batch: 15070, Loss: 0.3548882454633713, Accuracy: 50.84, Precision: 0.44, Recall: 0.43\n",
            "Epoch: 0, Batch: 15080, Loss: 0.5391051530838012, Accuracy: 49.84, Precision: 0.52, Recall: 0.46\n",
            "Epoch: 0, Batch: 15090, Loss: 0.517579972743988, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 15100, Loss: 0.5359246134757996, Accuracy: 50.0, Precision: 0.5, Recall: 0.35\n",
            "Epoch: 0, Batch: 15110, Loss: 0.49955334365367887, Accuracy: 51.62, Precision: 0.41, Recall: 0.41\n",
            "Epoch: 0, Batch: 15120, Loss: 0.476015567779541, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 15130, Loss: 0.5655210584402084, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 15140, Loss: 0.48341902494430544, Accuracy: 51.8, Precision: 0.55, Recall: 0.68\n",
            "Epoch: 0, Batch: 15150, Loss: 0.43083032965660095, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 15160, Loss: 0.4744968831539154, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 15170, Loss: 0.4994786590337753, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 15180, Loss: 0.5427813172340393, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 15190, Loss: 0.4853629395365715, Accuracy: 49.64, Precision: 0.53, Recall: 0.44\n",
            "Epoch: 0, Batch: 15200, Loss: 0.4691276580095291, Accuracy: 49.82, Precision: 0.47, Recall: 0.53\n",
            "Epoch: 0, Batch: 15210, Loss: 0.4849884152412415, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 15220, Loss: 0.4704081892967224, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 15230, Loss: 0.4989867269992828, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 15240, Loss: 0.43570520281791686, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 15250, Loss: 0.4403750956058502, Accuracy: 50.0, Precision: 0.5, Recall: 0.59\n",
            "Epoch: 0, Batch: 15260, Loss: 0.4059585928916931, Accuracy: 50.42, Precision: 0.47, Recall: 0.43\n",
            "Epoch: 0, Batch: 15270, Loss: 0.396470832824707, Accuracy: 50.88, Precision: 0.46, Recall: 0.39\n",
            "Epoch: 0, Batch: 15280, Loss: 0.5078785002231598, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 15290, Loss: 0.523849131166935, Accuracy: 50.5, Precision: 0.55, Recall: 0.55\n",
            "Epoch: 0, Batch: 15300, Loss: 0.4572641134262085, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 15310, Loss: 0.48819689750671386, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 15320, Loss: 0.37609521895647047, Accuracy: 51.76, Precision: 0.58, Recall: 0.61\n",
            "Epoch: 0, Batch: 15330, Loss: 0.48880604207515715, Accuracy: 50.72, Precision: 0.56, Recall: 0.56\n",
            "Epoch: 0, Batch: 15340, Loss: 0.40654548853635786, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 15350, Loss: 0.5322654366493225, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 15360, Loss: 0.34977654069662095, Accuracy: 52.2, Precision: 0.4, Recall: 0.39\n",
            "Epoch: 0, Batch: 15370, Loss: 0.45705753564834595, Accuracy: 51.82, Precision: 0.43, Recall: 0.37\n",
            "Epoch: 0, Batch: 15380, Loss: 0.42036223262548444, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 15390, Loss: 0.47653823494911196, Accuracy: 50.08, Precision: 0.51, Recall: 0.54\n",
            "Epoch: 0, Batch: 15400, Loss: 0.4829643338918686, Accuracy: 51.44, Precision: 0.58, Recall: 0.59\n",
            "Epoch: 0, Batch: 15410, Loss: 0.49039362370967865, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 15420, Loss: 0.5970750689506531, Accuracy: 52.16, Precision: 0.44, Recall: 0.32\n",
            "Epoch: 0, Batch: 15430, Loss: 0.4328876078128815, Accuracy: 50.7, Precision: 0.45, Recall: 0.43\n",
            "Epoch: 0, Batch: 15440, Loss: 0.5001012593507767, Accuracy: 50.84, Precision: 0.43, Recall: 0.44\n",
            "Epoch: 0, Batch: 15450, Loss: 0.5475054115056992, Accuracy: 49.36, Precision: 0.54, Recall: 0.42\n",
            "Epoch: 0, Batch: 15460, Loss: 0.4447995647788048, Accuracy: 49.88, Precision: 0.48, Recall: 0.53\n",
            "Epoch: 0, Batch: 15470, Loss: 0.4378974333405495, Accuracy: 50.24, Precision: 0.56, Recall: 0.52\n",
            "Epoch: 0, Batch: 15480, Loss: 0.3656793460249901, Accuracy: 50.12, Precision: 0.52, Recall: 0.53\n",
            "Epoch: 0, Batch: 15490, Loss: 0.3534011721611023, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 15500, Loss: 0.48278927654027937, Accuracy: 51.44, Precision: 0.41, Recall: 0.42\n",
            "Epoch: 0, Batch: 15510, Loss: 0.47168714106082915, Accuracy: 49.16, Precision: 0.57, Recall: 0.44\n",
            "Epoch: 0, Batch: 15520, Loss: 0.4408679246902466, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 15530, Loss: 0.5851467192173004, Accuracy: 51.76, Precision: 0.58, Recall: 0.61\n",
            "Epoch: 0, Batch: 15540, Loss: 0.40018420070409777, Accuracy: 50.12, Precision: 0.52, Recall: 0.53\n",
            "Epoch: 0, Batch: 15550, Loss: 0.5164120748639107, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 15560, Loss: 0.5666388541460037, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 15570, Loss: 0.5072280406951905, Accuracy: 49.92, Precision: 0.46, Recall: 0.51\n",
            "Epoch: 0, Batch: 15580, Loss: 0.4957623541355133, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 15590, Loss: 0.45884125530719755, Accuracy: 51.6, Precision: 0.45, Recall: 0.34\n",
            "Epoch: 0, Batch: 15600, Loss: 0.5072947174310685, Accuracy: 49.88, Precision: 0.52, Recall: 0.47\n",
            "Epoch: 0, Batch: 15610, Loss: 0.46398296654224397, Accuracy: 49.88, Precision: 0.47, Recall: 0.52\n",
            "Epoch: 0, Batch: 15620, Loss: 0.4145737409591675, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 15630, Loss: 0.45332667529582976, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 15640, Loss: 0.4792413771152496, Accuracy: 50.84, Precision: 0.44, Recall: 0.43\n",
            "Epoch: 0, Batch: 15650, Loss: 0.5327946603298187, Accuracy: 49.76, Precision: 0.53, Recall: 0.46\n",
            "Epoch: 0, Batch: 15660, Loss: 0.5167251944541931, Accuracy: 51.82, Precision: 0.57, Recall: 0.63\n",
            "Epoch: 0, Batch: 15670, Loss: 0.4586140543222427, Accuracy: 50.36, Precision: 0.52, Recall: 0.59\n",
            "Epoch: 0, Batch: 15680, Loss: 0.5043151438236236, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 15690, Loss: 0.5115899950265884, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 15700, Loss: 0.4328271523118019, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 15710, Loss: 0.36578060537576673, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 15720, Loss: 0.44057911932468413, Accuracy: 51.44, Precision: 0.38, Recall: 0.44\n",
            "Epoch: 0, Batch: 15730, Loss: 0.4996765896677971, Accuracy: 50.66, Precision: 0.47, Recall: 0.39\n",
            "Epoch: 0, Batch: 15740, Loss: 0.6167538642883301, Accuracy: 49.2, Precision: 0.54, Recall: 0.4\n",
            "Epoch: 0, Batch: 15750, Loss: 0.4544942781329155, Accuracy: 50.48, Precision: 0.53, Recall: 0.58\n",
            "Epoch: 0, Batch: 15760, Loss: 0.5077262222766876, Accuracy: 50.24, Precision: 0.38, Recall: 0.49\n",
            "Epoch: 0, Batch: 15770, Loss: 0.566669899225235, Accuracy: 49.44, Precision: 0.54, Recall: 0.43\n",
            "Epoch: 0, Batch: 15780, Loss: 0.49125289022922514, Accuracy: 50.96, Precision: 0.44, Recall: 0.42\n",
            "Epoch: 0, Batch: 15790, Loss: 0.4049275040626526, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "Epoch: 0, Batch: 15800, Loss: 0.4831963911652565, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 15810, Loss: 0.4849176287651062, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 15820, Loss: 0.3649633422493935, Accuracy: 50.2, Precision: 0.45, Recall: 0.48\n",
            "Epoch: 0, Batch: 15830, Loss: 0.4683237478137016, Accuracy: 49.3, Precision: 0.57, Recall: 0.45\n",
            "Epoch: 0, Batch: 15840, Loss: 0.4234477713704109, Accuracy: 53.4, Precision: 0.6, Recall: 0.67\n",
            "Epoch: 0, Batch: 15850, Loss: 0.5377539753913879, Accuracy: 49.7, Precision: 0.45, Recall: 0.53\n",
            "Epoch: 0, Batch: 15860, Loss: 0.4697947263717651, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 15870, Loss: 0.40205008536577225, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 15880, Loss: 0.45461800545454023, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 15890, Loss: 0.42664304077625276, Accuracy: 50.08, Precision: 0.51, Recall: 0.54\n",
            "Epoch: 0, Batch: 15900, Loss: 0.4891163736581802, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 15910, Loss: 0.41108027696609495, Accuracy: 52.52, Precision: 0.41, Recall: 0.36\n",
            "Epoch: 0, Batch: 15920, Loss: 0.3863190069794655, Accuracy: 51.08, Precision: 0.44, Recall: 0.41\n",
            "Epoch: 0, Batch: 15930, Loss: 0.6303613781929016, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 15940, Loss: 0.4631353676319122, Accuracy: 50.1, Precision: 0.51, Recall: 0.55\n",
            "Epoch: 0, Batch: 15950, Loss: 0.3710187315940857, Accuracy: 50.08, Precision: 0.51, Recall: 0.54\n",
            "Epoch: 0, Batch: 15960, Loss: 0.448916058242321, Accuracy: 50.48, Precision: 0.62, Recall: 0.52\n",
            "Epoch: 0, Batch: 15970, Loss: 0.5071034103631973, Accuracy: 50.14, Precision: 0.43, Recall: 0.49\n",
            "Epoch: 0, Batch: 15980, Loss: 0.43655542135238645, Accuracy: 49.98, Precision: 0.51, Recall: 0.49\n",
            "Epoch: 0, Batch: 15990, Loss: 0.45430571138858794, Accuracy: 50.48, Precision: 0.48, Recall: 0.38\n",
            "Epoch: 0, Batch: 16000, Loss: 0.5170710623264313, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 16010, Loss: 0.48469571173191073, Accuracy: 51.76, Precision: 0.61, Recall: 0.58\n",
            "Epoch: 0, Batch: 16020, Loss: 0.3703285172581673, Accuracy: 53.52, Precision: 0.61, Recall: 0.66\n",
            "Epoch: 0, Batch: 16030, Loss: 0.4863832086324692, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 16040, Loss: 0.4577390432357788, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 16050, Loss: 0.4437319189310074, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 16060, Loss: 0.4138319969177246, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 16070, Loss: 0.4360566958785057, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 16080, Loss: 0.45228825211524964, Accuracy: 50.7, Precision: 0.45, Recall: 0.43\n",
            "Epoch: 0, Batch: 16090, Loss: 0.4887973487377167, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 16100, Loss: 0.4651940524578094, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 16110, Loss: 0.4592017143964767, Accuracy: 50.42, Precision: 0.57, Recall: 0.53\n",
            "Epoch: 0, Batch: 16120, Loss: 0.4708226233720779, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 16130, Loss: 0.39514768719673155, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 16140, Loss: 0.45421128869056704, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 16150, Loss: 0.6648239687085151, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 16160, Loss: 0.5013619944453239, Accuracy: 49.5, Precision: 0.55, Recall: 0.45\n",
            "Epoch: 0, Batch: 16170, Loss: 0.5426373660564423, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 16180, Loss: 0.42713913023471833, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 16190, Loss: 0.39887108504772184, Accuracy: 50.06, Precision: 0.53, Recall: 0.51\n",
            "Epoch: 0, Batch: 16200, Loss: 0.48544067740440366, Accuracy: 50.84, Precision: 0.57, Recall: 0.56\n",
            "Epoch: 0, Batch: 16210, Loss: 0.4985720604658127, Accuracy: 50.5, Precision: 0.55, Recall: 0.55\n",
            "Epoch: 0, Batch: 16220, Loss: 0.5147109061479569, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 16230, Loss: 0.4755526274442673, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 16240, Loss: 0.3809269845485687, Accuracy: 50.0, Precision: 0.55, Recall: 0.5\n",
            "Epoch: 0, Batch: 16250, Loss: 0.5014119356870651, Accuracy: 50.16, Precision: 0.51, Recall: 0.58\n",
            "Epoch: 0, Batch: 16260, Loss: 0.48045326620340345, Accuracy: 50.72, Precision: 0.44, Recall: 0.44\n",
            "Epoch: 0, Batch: 16270, Loss: 0.4645289063453674, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 16280, Loss: 0.3792960584163666, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 16290, Loss: 0.3693951368331909, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 16300, Loss: 0.37132282704114916, Accuracy: 50.96, Precision: 0.44, Recall: 0.42\n",
            "Epoch: 0, Batch: 16310, Loss: 0.5323719128966331, Accuracy: 50.9, Precision: 0.47, Recall: 0.35\n",
            "Epoch: 0, Batch: 16320, Loss: 0.5523816138505936, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 16330, Loss: 0.38332707732915877, Accuracy: 50.7, Precision: 0.45, Recall: 0.43\n",
            "Epoch: 0, Batch: 16340, Loss: 0.4361203461885452, Accuracy: 49.82, Precision: 0.51, Recall: 0.41\n",
            "Epoch: 0, Batch: 16350, Loss: 0.46228850185871123, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 16360, Loss: 0.4737430945038795, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 16370, Loss: 0.5240580543875695, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 16380, Loss: 0.4106371641159058, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 16390, Loss: 0.5086394339799881, Accuracy: 50.24, Precision: 0.48, Recall: 0.44\n",
            "Epoch: 0, Batch: 16400, Loss: 0.4380550026893616, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 16410, Loss: 0.4880896806716919, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 16420, Loss: 0.4631835162639618, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 16430, Loss: 0.4299933761358261, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 16440, Loss: 0.42487135231494905, Accuracy: 49.3, Precision: 0.43, Recall: 0.55\n",
            "Epoch: 0, Batch: 16450, Loss: 0.49281649887561796, Accuracy: 50.66, Precision: 0.47, Recall: 0.39\n",
            "Epoch: 0, Batch: 16460, Loss: 0.49631400108337403, Accuracy: 49.76, Precision: 0.51, Recall: 0.38\n",
            "Epoch: 0, Batch: 16470, Loss: 0.47115679681301115, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 16480, Loss: 0.47756480276584623, Accuracy: 49.92, Precision: 0.51, Recall: 0.46\n",
            "Epoch: 0, Batch: 16490, Loss: 0.4196018844842911, Accuracy: 52.0, Precision: 0.4, Recall: 0.4\n",
            "Epoch: 0, Batch: 16500, Loss: 0.5482205957174301, Accuracy: 50.0, Precision: 0.51, Recall: 0.5\n",
            "Epoch: 0, Batch: 16510, Loss: 0.5285964667797088, Accuracy: 51.2, Precision: 0.62, Recall: 0.55\n",
            "Epoch: 0, Batch: 16520, Loss: 0.41244908422231674, Accuracy: 52.8, Precision: 0.57, Recall: 0.7\n",
            "Epoch: 0, Batch: 16530, Loss: 0.3902567341923714, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 16540, Loss: 0.4704871132969856, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 16550, Loss: 0.4488209158182144, Accuracy: 49.98, Precision: 0.51, Recall: 0.49\n",
            "Epoch: 0, Batch: 16560, Loss: 0.41589838564395903, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 16570, Loss: 0.5414132356643677, Accuracy: 49.76, Precision: 0.54, Recall: 0.47\n",
            "Epoch: 0, Batch: 16580, Loss: 0.5223609536886216, Accuracy: 50.42, Precision: 0.43, Recall: 0.47\n",
            "Epoch: 0, Batch: 16590, Loss: 0.48318584859371183, Accuracy: 49.28, Precision: 0.59, Recall: 0.46\n",
            "Epoch: 0, Batch: 16600, Loss: 0.40043126940727236, Accuracy: 50.2, Precision: 0.51, Recall: 0.6\n",
            "Epoch: 0, Batch: 16610, Loss: 0.42314945310354235, Accuracy: 53.2, Precision: 0.6, Recall: 0.66\n",
            "Epoch: 0, Batch: 16620, Loss: 0.4873119413852692, Accuracy: 50.36, Precision: 0.44, Recall: 0.47\n",
            "Epoch: 0, Batch: 16630, Loss: 0.4636661022901535, Accuracy: 49.86, Precision: 0.57, Recall: 0.49\n",
            "Epoch: 0, Batch: 16640, Loss: 0.5797089159488678, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 16650, Loss: 0.4229078724980354, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 16660, Loss: 0.5004850178956985, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 16670, Loss: 0.44800226092338563, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 16680, Loss: 0.4493592530488968, Accuracy: 49.52, Precision: 0.53, Recall: 0.42\n",
            "Epoch: 0, Batch: 16690, Loss: 0.4006049014627934, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 16700, Loss: 0.5487080603837967, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 16710, Loss: 0.4400147616863251, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 16720, Loss: 0.5168071389198303, Accuracy: 50.0, Precision: 0.62, Recall: 0.5\n",
            "Epoch: 0, Batch: 16730, Loss: 0.42990819215774534, Accuracy: 49.7, Precision: 0.47, Recall: 0.55\n",
            "Epoch: 0, Batch: 16740, Loss: 0.5860643208026886, Accuracy: 50.08, Precision: 0.51, Recall: 0.54\n",
            "Epoch: 0, Batch: 16750, Loss: 0.6148197710514068, Accuracy: 50.84, Precision: 0.43, Recall: 0.44\n",
            "Epoch: 0, Batch: 16760, Loss: 0.45747746229171754, Accuracy: 51.96, Precision: 0.43, Recall: 0.36\n",
            "Epoch: 0, Batch: 16770, Loss: 0.46319850385189054, Accuracy: 49.8, Precision: 0.52, Recall: 0.45\n",
            "Epoch: 0, Batch: 16780, Loss: 0.47159457206726074, Accuracy: 49.6, Precision: 0.48, Recall: 0.6\n",
            "Epoch: 0, Batch: 16790, Loss: 0.4875521153211594, Accuracy: 49.58, Precision: 0.53, Recall: 0.43\n",
            "Epoch: 0, Batch: 16800, Loss: 0.45237003564834594, Accuracy: 49.9, Precision: 0.55, Recall: 0.49\n",
            "Epoch: 0, Batch: 16810, Loss: 0.4769112437963486, Accuracy: 51.44, Precision: 0.56, Recall: 0.62\n",
            "Epoch: 0, Batch: 16820, Loss: 0.4899358212947845, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 16830, Loss: 0.4054467484354973, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 16840, Loss: 0.45258512198925016, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 16850, Loss: 0.42223620861768724, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 16860, Loss: 0.5262724429368972, Accuracy: 50.14, Precision: 0.51, Recall: 0.57\n",
            "Epoch: 0, Batch: 16870, Loss: 0.4459997832775116, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 16880, Loss: 0.4572769343852997, Accuracy: 49.9, Precision: 0.55, Recall: 0.49\n",
            "Epoch: 0, Batch: 16890, Loss: 0.5398709595203399, Accuracy: 49.88, Precision: 0.48, Recall: 0.53\n",
            "Epoch: 0, Batch: 16900, Loss: 0.3818004816770554, Accuracy: 52.64, Precision: 0.61, Recall: 0.62\n",
            "Epoch: 0, Batch: 16910, Loss: 0.5403086096048355, Accuracy: 49.78, Precision: 0.49, Recall: 0.61\n",
            "Epoch: 0, Batch: 16920, Loss: 0.4068234086036682, Accuracy: 50.1, Precision: 0.49, Recall: 0.45\n",
            "Epoch: 0, Batch: 16930, Loss: 0.41303771138191225, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 16940, Loss: 0.5275782495737076, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 16950, Loss: 0.5552045732736588, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 16960, Loss: 0.49051074087619784, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 16970, Loss: 0.47697352468967436, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 16980, Loss: 0.4811802476644516, Accuracy: 49.52, Precision: 0.58, Recall: 0.47\n",
            "Epoch: 0, Batch: 16990, Loss: 0.46732217669487, Accuracy: 49.34, Precision: 0.47, Recall: 0.61\n",
            "Epoch: 0, Batch: 17000, Loss: 0.47212581932544706, Accuracy: 51.8, Precision: 0.41, Recall: 0.4\n",
            "Epoch: 0, Batch: 17010, Loss: 0.5148384690284729, Accuracy: 49.48, Precision: 0.52, Recall: 0.37\n",
            "Epoch: 0, Batch: 17020, Loss: 0.4452536329627037, Accuracy: 49.68, Precision: 0.52, Recall: 0.42\n",
            "Epoch: 0, Batch: 17030, Loss: 0.5109930843114853, Accuracy: 50.08, Precision: 0.51, Recall: 0.54\n",
            "Epoch: 0, Batch: 17040, Loss: 0.5579861283302308, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 17050, Loss: 0.4042538583278656, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 17060, Loss: 0.42764697670936586, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 17070, Loss: 0.47948835492134095, Accuracy: 49.9, Precision: 0.51, Recall: 0.45\n",
            "Epoch: 0, Batch: 17080, Loss: 0.4593526110053062, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 17090, Loss: 0.42149282693862916, Accuracy: 50.4, Precision: 0.55, Recall: 0.54\n",
            "Epoch: 0, Batch: 17100, Loss: 0.5515633225440979, Accuracy: 50.84, Precision: 0.44, Recall: 0.43\n",
            "Epoch: 0, Batch: 17110, Loss: 0.4654468759894371, Accuracy: 50.0, Precision: 0.59, Recall: 0.5\n",
            "Epoch: 0, Batch: 17120, Loss: 0.4927047148346901, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 17130, Loss: 0.3940606638789177, Accuracy: 50.48, Precision: 0.44, Recall: 0.46\n",
            "Epoch: 0, Batch: 17140, Loss: 0.4468536555767059, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 17150, Loss: 0.3600151091814041, Accuracy: 51.96, Precision: 0.43, Recall: 0.36\n",
            "Epoch: 0, Batch: 17160, Loss: 0.5004037946462632, Accuracy: 50.18, Precision: 0.53, Recall: 0.53\n",
            "Epoch: 0, Batch: 17170, Loss: 0.42551553100347517, Accuracy: 50.04, Precision: 0.48, Recall: 0.49\n",
            "Epoch: 0, Batch: 17180, Loss: 0.4799001842737198, Accuracy: 49.94, Precision: 0.53, Recall: 0.49\n",
            "Epoch: 0, Batch: 17190, Loss: 0.4870725184679031, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 17200, Loss: 0.3711672991514206, Accuracy: 52.2, Precision: 0.4, Recall: 0.39\n",
            "Epoch: 0, Batch: 17210, Loss: 0.4403378039598465, Accuracy: 50.22, Precision: 0.49, Recall: 0.39\n",
            "Epoch: 0, Batch: 17220, Loss: 0.520086744427681, Accuracy: 49.84, Precision: 0.46, Recall: 0.52\n",
            "Epoch: 0, Batch: 17230, Loss: 0.4669232934713364, Accuracy: 50.0, Precision: 0.44, Recall: 0.5\n",
            "Epoch: 0, Batch: 17240, Loss: 0.510862621665001, Accuracy: 50.28, Precision: 0.49, Recall: 0.36\n",
            "Epoch: 0, Batch: 17250, Loss: 0.44657313227653506, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 17260, Loss: 0.4735616594552994, Accuracy: 50.2, Precision: 0.51, Recall: 0.6\n",
            "Epoch: 0, Batch: 17270, Loss: 0.513970109820366, Accuracy: 49.7, Precision: 0.55, Recall: 0.47\n",
            "Epoch: 0, Batch: 17280, Loss: 0.3799612894654274, Accuracy: 49.36, Precision: 0.46, Recall: 0.58\n",
            "Epoch: 0, Batch: 17290, Loss: 0.44003805369138715, Accuracy: 50.56, Precision: 0.57, Recall: 0.54\n",
            "Epoch: 0, Batch: 17300, Loss: 0.39382488578557967, Accuracy: 50.72, Precision: 0.56, Recall: 0.56\n",
            "Epoch: 0, Batch: 17310, Loss: 0.5754978448152542, Accuracy: 50.16, Precision: 0.51, Recall: 0.58\n",
            "Epoch: 0, Batch: 17320, Loss: 0.471248123049736, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 17330, Loss: 0.42236449718475344, Accuracy: 51.44, Precision: 0.44, Recall: 0.38\n",
            "Epoch: 0, Batch: 17340, Loss: 0.3932749927043915, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 17350, Loss: 0.42291364520788194, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 17360, Loss: 0.5207145482301712, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 17370, Loss: 0.4062190786004066, Accuracy: 50.18, Precision: 0.59, Recall: 0.51\n",
            "Epoch: 0, Batch: 17380, Loss: 0.5254348292946815, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 17390, Loss: 0.5209817975759506, Accuracy: 50.64, Precision: 0.52, Recall: 0.66\n",
            "Epoch: 0, Batch: 17400, Loss: 0.4661582291126251, Accuracy: 50.28, Precision: 0.43, Recall: 0.48\n",
            "Epoch: 0, Batch: 17410, Loss: 0.5578080356121063, Accuracy: 49.8, Precision: 0.51, Recall: 0.4\n",
            "Epoch: 0, Batch: 17420, Loss: 0.4391114413738251, Accuracy: 51.12, Precision: 0.42, Recall: 0.43\n",
            "Epoch: 0, Batch: 17430, Loss: 0.48044039607048034, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 17440, Loss: 0.49068695306777954, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 17450, Loss: 0.4263892248272896, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 17460, Loss: 0.4902655392885208, Accuracy: 50.72, Precision: 0.41, Recall: 0.46\n",
            "Epoch: 0, Batch: 17470, Loss: 0.48680459558963773, Accuracy: 50.18, Precision: 0.49, Recall: 0.41\n",
            "Epoch: 0, Batch: 17480, Loss: 0.46465346217155457, Accuracy: 51.44, Precision: 0.42, Recall: 0.41\n",
            "Epoch: 0, Batch: 17490, Loss: 0.3758591145277023, Accuracy: 50.3, Precision: 0.53, Recall: 0.55\n",
            "Epoch: 0, Batch: 17500, Loss: 0.49405366480350493, Accuracy: 50.88, Precision: 0.46, Recall: 0.39\n",
            "Epoch: 0, Batch: 17510, Loss: 0.4215539485216141, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 17520, Loss: 0.42453687489032743, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 17530, Loss: 0.4199122369289398, Accuracy: 52.4, Precision: 0.58, Recall: 0.65\n",
            "Epoch: 0, Batch: 17540, Loss: 0.5156647443771363, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 17550, Loss: 0.49197169318795203, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 17560, Loss: 0.5184668093919754, Accuracy: 50.42, Precision: 0.43, Recall: 0.47\n",
            "Epoch: 0, Batch: 17570, Loss: 0.45699903666973113, Accuracy: 49.92, Precision: 0.46, Recall: 0.51\n",
            "Epoch: 0, Batch: 17580, Loss: 0.5480774983763694, Accuracy: 50.0, Precision: 0.55, Recall: 0.5\n",
            "Epoch: 0, Batch: 17590, Loss: 0.45216144919395446, Accuracy: 50.36, Precision: 0.48, Recall: 0.41\n",
            "Epoch: 0, Batch: 17600, Loss: 0.5069918632507324, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 17610, Loss: 0.3762662872672081, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 17620, Loss: 0.48204975128173827, Accuracy: 50.72, Precision: 0.56, Recall: 0.56\n",
            "Epoch: 0, Batch: 17630, Loss: 0.5681476563215255, Accuracy: 50.12, Precision: 0.44, Recall: 0.49\n",
            "Epoch: 0, Batch: 17640, Loss: 0.42896075248718263, Accuracy: 51.0, Precision: 0.6, Recall: 0.55\n",
            "Epoch: 0, Batch: 17650, Loss: 0.4961159259080887, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 17660, Loss: 0.4342981219291687, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 17670, Loss: 0.3820939570665359, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 17680, Loss: 0.4127802550792694, Accuracy: 50.24, Precision: 0.56, Recall: 0.52\n",
            "Epoch: 0, Batch: 17690, Loss: 0.4776224657893181, Accuracy: 49.46, Precision: 0.47, Recall: 0.59\n",
            "Epoch: 0, Batch: 17700, Loss: 0.5385636746883392, Accuracy: 51.92, Precision: 0.42, Recall: 0.38\n",
            "Epoch: 0, Batch: 17710, Loss: 0.4955788552761078, Accuracy: 52.1, Precision: 0.43, Recall: 0.35\n",
            "Epoch: 0, Batch: 17720, Loss: 0.42492592632770537, Accuracy: 49.92, Precision: 0.54, Recall: 0.49\n",
            "Epoch: 0, Batch: 17730, Loss: 0.46502898037433626, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 17740, Loss: 0.5079407006502151, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 17750, Loss: 0.5448902755975723, Accuracy: 49.88, Precision: 0.44, Recall: 0.51\n",
            "Epoch: 0, Batch: 17760, Loss: 0.5264263689517975, Accuracy: 49.74, Precision: 0.51, Recall: 0.37\n",
            "Epoch: 0, Batch: 17770, Loss: 0.518432030081749, Accuracy: 49.88, Precision: 0.53, Recall: 0.48\n",
            "Epoch: 0, Batch: 17780, Loss: 0.40918428599834444, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 17790, Loss: 0.5427953213453293, Accuracy: 49.6, Precision: 0.46, Recall: 0.55\n",
            "Epoch: 0, Batch: 17800, Loss: 0.5153804570436478, Accuracy: 53.96, Precision: 0.41, Recall: 0.28\n",
            "Epoch: 0, Batch: 17810, Loss: 0.49202347695827486, Accuracy: 51.7, Precision: 0.45, Recall: 0.33\n",
            "Epoch: 0, Batch: 17820, Loss: 0.45221506953239443, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 17830, Loss: 0.4864453047513962, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 17840, Loss: 0.4757842242717743, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 17850, Loss: 0.43287228643894193, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 17860, Loss: 0.4433354020118713, Accuracy: 50.24, Precision: 0.56, Recall: 0.52\n",
            "Epoch: 0, Batch: 17870, Loss: 0.4266288250684738, Accuracy: 50.66, Precision: 0.53, Recall: 0.61\n",
            "Epoch: 0, Batch: 17880, Loss: 0.5193905383348465, Accuracy: 50.26, Precision: 0.51, Recall: 0.63\n",
            "Epoch: 0, Batch: 17890, Loss: 0.44282921105623246, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 17900, Loss: 0.5632755219936371, Accuracy: 52.4, Precision: 0.44, Recall: 0.3\n",
            "Epoch: 0, Batch: 17910, Loss: 0.43020195364952085, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 17920, Loss: 0.5025017887353898, Accuracy: 49.6, Precision: 0.45, Recall: 0.54\n",
            "Epoch: 0, Batch: 17930, Loss: 0.3967857867479324, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 17940, Loss: 0.4101569354534149, Accuracy: 50.48, Precision: 0.47, Recall: 0.42\n",
            "Epoch: 0, Batch: 17950, Loss: 0.47197477519512177, Accuracy: 51.4, Precision: 0.45, Recall: 0.36\n",
            "Epoch: 0, Batch: 17960, Loss: 0.462793818116188, Accuracy: 50.3, Precision: 0.53, Recall: 0.55\n",
            "Epoch: 0, Batch: 17970, Loss: 0.4506088986992836, Accuracy: 51.44, Precision: 0.59, Recall: 0.58\n",
            "Epoch: 0, Batch: 17980, Loss: 0.44592465460300446, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 17990, Loss: 0.37434712424874306, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 18000, Loss: 0.431054013967514, Accuracy: 49.96, Precision: 0.51, Recall: 0.48\n",
            "Epoch: 0, Batch: 18010, Loss: 0.4900840878486633, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 18020, Loss: 0.5520958513021469, Accuracy: 50.8, Precision: 0.58, Recall: 0.55\n",
            "Epoch: 0, Batch: 18030, Loss: 0.4887192815542221, Accuracy: 50.96, Precision: 0.54, Recall: 0.62\n",
            "Epoch: 0, Batch: 18040, Loss: 0.48493589013814925, Accuracy: 50.2, Precision: 0.45, Recall: 0.48\n",
            "Epoch: 0, Batch: 18050, Loss: 0.422827222943306, Accuracy: 49.4, Precision: 0.55, Recall: 0.44\n",
            "Epoch: 0, Batch: 18060, Loss: 0.5455147415399552, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 18070, Loss: 0.42243448197841643, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 18080, Loss: 0.45079234838485716, Accuracy: 49.64, Precision: 0.52, Recall: 0.41\n",
            "Epoch: 0, Batch: 18090, Loss: 0.47509883493185046, Accuracy: 50.3, Precision: 0.53, Recall: 0.55\n",
            "Epoch: 0, Batch: 18100, Loss: 0.4594868034124374, Accuracy: 49.76, Precision: 0.47, Recall: 0.54\n",
            "Epoch: 0, Batch: 18110, Loss: 0.48284812867641447, Accuracy: 50.84, Precision: 0.44, Recall: 0.43\n",
            "Epoch: 0, Batch: 18120, Loss: 0.3892062172293663, Accuracy: 50.0, Precision: 0.5, Recall: 0.42\n",
            "Epoch: 0, Batch: 18130, Loss: 0.3970468588173389, Accuracy: 50.64, Precision: 0.42, Recall: 0.46\n",
            "Epoch: 0, Batch: 18140, Loss: 0.4638797342777252, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 18150, Loss: 0.42373918890953066, Accuracy: 52.64, Precision: 0.39, Recall: 0.38\n",
            "Epoch: 0, Batch: 18160, Loss: 0.46191307008266447, Accuracy: 50.44, Precision: 0.48, Recall: 0.39\n",
            "Epoch: 0, Batch: 18170, Loss: 0.43550672829151155, Accuracy: 51.2, Precision: 0.56, Recall: 0.6\n",
            "Epoch: 0, Batch: 18180, Loss: 0.5220395624637604, Accuracy: 49.88, Precision: 0.44, Recall: 0.51\n",
            "Epoch: 0, Batch: 18190, Loss: 0.6710418999195099, Accuracy: 49.8, Precision: 0.51, Recall: 0.4\n",
            "Epoch: 0, Batch: 18200, Loss: 0.479189233481884, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 18210, Loss: 0.4140211999416351, Accuracy: 50.24, Precision: 0.56, Recall: 0.52\n",
            "Epoch: 0, Batch: 18220, Loss: 0.5340150982141495, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 18230, Loss: 0.37967604845762254, Accuracy: 50.1, Precision: 0.55, Recall: 0.51\n",
            "Epoch: 0, Batch: 18240, Loss: 0.4890459209680557, Accuracy: 51.2, Precision: 0.55, Recall: 0.62\n",
            "Epoch: 0, Batch: 18250, Loss: 0.4344916969537735, Accuracy: 50.56, Precision: 0.43, Recall: 0.46\n",
            "Epoch: 0, Batch: 18260, Loss: 0.3889944300055504, Accuracy: 50.48, Precision: 0.47, Recall: 0.42\n",
            "Epoch: 0, Batch: 18270, Loss: 0.33414876759052276, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 18280, Loss: 0.3936303988099098, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 18290, Loss: 0.5156204536557197, Accuracy: 50.0, Precision: 0.5, Recall: 0.42\n",
            "Epoch: 0, Batch: 18300, Loss: 0.37418670654296876, Accuracy: 51.44, Precision: 0.38, Recall: 0.44\n",
            "Epoch: 0, Batch: 18310, Loss: 0.3957706719636917, Accuracy: 50.12, Precision: 0.49, Recall: 0.44\n",
            "Epoch: 0, Batch: 18320, Loss: 0.40177854895591736, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 18330, Loss: 0.45239103883504866, Accuracy: 50.7, Precision: 0.43, Recall: 0.45\n",
            "Epoch: 0, Batch: 18340, Loss: 0.46629912704229354, Accuracy: 51.82, Precision: 0.43, Recall: 0.37\n",
            "Epoch: 0, Batch: 18350, Loss: 0.5656855940818787, Accuracy: 51.36, Precision: 0.46, Recall: 0.33\n",
            "Epoch: 0, Batch: 18360, Loss: 0.41237673461437224, Accuracy: 49.88, Precision: 0.49, Recall: 0.56\n",
            "Epoch: 0, Batch: 18370, Loss: 0.47042360007762907, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 18380, Loss: 0.5113149344921112, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 18390, Loss: 0.4311607748270035, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 18400, Loss: 0.5222710937261581, Accuracy: 50.08, Precision: 0.51, Recall: 0.54\n",
            "Epoch: 0, Batch: 18410, Loss: 0.41263637393713, Accuracy: 49.8, Precision: 0.45, Recall: 0.52\n",
            "Epoch: 0, Batch: 18420, Loss: 0.4419701725244522, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 18430, Loss: 0.38175258338451384, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 18440, Loss: 0.469293075799942, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 18450, Loss: 0.44900588393211366, Accuracy: 51.6, Precision: 0.58, Recall: 0.6\n",
            "Epoch: 0, Batch: 18460, Loss: 0.3838504210114479, Accuracy: 50.08, Precision: 0.48, Recall: 0.48\n",
            "Epoch: 0, Batch: 18470, Loss: 0.4449834585189819, Accuracy: 50.98, Precision: 0.43, Recall: 0.43\n",
            "Epoch: 0, Batch: 18480, Loss: 0.45241468250751493, Accuracy: 50.12, Precision: 0.49, Recall: 0.44\n",
            "Epoch: 0, Batch: 18490, Loss: 0.5117996335029602, Accuracy: 50.12, Precision: 0.52, Recall: 0.53\n",
            "Epoch: 0, Batch: 18500, Loss: 0.45965837836265566, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 18510, Loss: 0.5282751858234406, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 18520, Loss: 0.3548153653740883, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 18530, Loss: 0.47761492133140565, Accuracy: 49.88, Precision: 0.44, Recall: 0.51\n",
            "Epoch: 0, Batch: 18540, Loss: 0.4160480543971062, Accuracy: 50.78, Precision: 0.47, Recall: 0.37\n",
            "Epoch: 0, Batch: 18550, Loss: 0.4962585985660553, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 18560, Loss: 0.4702842891216278, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 18570, Loss: 0.5237126022577285, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 18580, Loss: 0.5885734856128693, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 18590, Loss: 0.3164272323250771, Accuracy: 50.32, Precision: 0.46, Recall: 0.46\n",
            "Epoch: 0, Batch: 18600, Loss: 0.48781200051307677, Accuracy: 49.76, Precision: 0.54, Recall: 0.47\n",
            "Epoch: 0, Batch: 18610, Loss: 0.45097826719284057, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 18620, Loss: 0.444871886074543, Accuracy: 50.14, Precision: 0.51, Recall: 0.57\n",
            "Epoch: 0, Batch: 18630, Loss: 0.5616037726402283, Accuracy: 49.76, Precision: 0.56, Recall: 0.48\n",
            "Epoch: 0, Batch: 18640, Loss: 0.40060108304023745, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 18650, Loss: 0.3721915423870087, Accuracy: 49.8, Precision: 0.45, Recall: 0.52\n",
            "Epoch: 0, Batch: 18660, Loss: 0.4536184251308441, Accuracy: 49.52, Precision: 0.54, Recall: 0.44\n",
            "Epoch: 0, Batch: 18670, Loss: 0.49361344128847123, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 18680, Loss: 0.4183336481451988, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 18690, Loss: 0.3530207067728043, Accuracy: 50.72, Precision: 0.44, Recall: 0.44\n",
            "Epoch: 0, Batch: 18700, Loss: 0.4197075754404068, Accuracy: 50.0, Precision: 0.57, Recall: 0.5\n",
            "Epoch: 0, Batch: 18710, Loss: 0.4253163546323776, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 18720, Loss: 0.5198356866836548, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 18730, Loss: 0.42917954474687575, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 18740, Loss: 0.4934305101633072, Accuracy: 50.0, Precision: 0.5, Recall: 0.57\n",
            "Epoch: 0, Batch: 18750, Loss: 0.5328442841768265, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 18760, Loss: 0.43797398209571836, Accuracy: 50.24, Precision: 0.46, Recall: 0.47\n",
            "Epoch: 0, Batch: 18770, Loss: 0.40354635417461393, Accuracy: 49.64, Precision: 0.53, Recall: 0.44\n",
            "Epoch: 0, Batch: 18780, Loss: 0.4075700014829636, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 18790, Loss: 0.4552664324641228, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 18800, Loss: 0.4596130311489105, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 18810, Loss: 0.406722204387188, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 18820, Loss: 0.5152492016553879, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 18830, Loss: 0.5619799733161926, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 18840, Loss: 0.5101262152194976, Accuracy: 52.4, Precision: 0.38, Recall: 0.4\n",
            "Epoch: 0, Batch: 18850, Loss: 0.5078220129013061, Accuracy: 49.88, Precision: 0.53, Recall: 0.48\n",
            "Epoch: 0, Batch: 18860, Loss: 0.45034572184085847, Accuracy: 50.04, Precision: 0.48, Recall: 0.49\n",
            "Epoch: 0, Batch: 18870, Loss: 0.5301123067736626, Accuracy: 49.64, Precision: 0.41, Recall: 0.52\n",
            "Epoch: 0, Batch: 18880, Loss: 0.47215147912502287, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 18890, Loss: 0.5209472253918648, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 18900, Loss: 0.39382731169462204, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 18910, Loss: 0.43660213947296145, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 18920, Loss: 0.5204006731510162, Accuracy: 49.98, Precision: 0.51, Recall: 0.49\n",
            "Epoch: 0, Batch: 18930, Loss: 0.5213152080774307, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 18940, Loss: 0.4735421285033226, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 18950, Loss: 0.3989285618066788, Accuracy: 49.88, Precision: 0.52, Recall: 0.47\n",
            "Epoch: 0, Batch: 18960, Loss: 0.4245218694210052, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 18970, Loss: 0.38246615678071977, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 18980, Loss: 0.5146218329668045, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 18990, Loss: 0.37342520132660867, Accuracy: 50.84, Precision: 0.44, Recall: 0.43\n",
            "Epoch: 0, Batch: 19000, Loss: 0.48162309974431994, Accuracy: 49.82, Precision: 0.53, Recall: 0.47\n",
            "Epoch: 0, Batch: 19010, Loss: 0.4062031090259552, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 19020, Loss: 0.37228113114833833, Accuracy: 50.18, Precision: 0.41, Recall: 0.49\n",
            "Epoch: 0, Batch: 19030, Loss: 0.5794740349054337, Accuracy: 50.66, Precision: 0.47, Recall: 0.39\n",
            "Epoch: 0, Batch: 19040, Loss: 0.4324466481804848, Accuracy: 51.0, Precision: 0.45, Recall: 0.4\n",
            "Epoch: 0, Batch: 19050, Loss: 0.37516404688358307, Accuracy: 50.0, Precision: 0.44, Recall: 0.5\n",
            "Epoch: 0, Batch: 19060, Loss: 0.5766741126775742, Accuracy: 50.44, Precision: 0.48, Recall: 0.39\n",
            "Epoch: 0, Batch: 19070, Loss: 0.41204077154397967, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 19080, Loss: 0.4799027770757675, Accuracy: 51.2, Precision: 0.56, Recall: 0.6\n",
            "Epoch: 0, Batch: 19090, Loss: 0.44166931658983233, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 19100, Loss: 0.4304890424013138, Accuracy: 50.44, Precision: 0.48, Recall: 0.39\n",
            "Epoch: 0, Batch: 19110, Loss: 0.5079034671187401, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 19120, Loss: 0.5182372182607651, Accuracy: 50.18, Precision: 0.51, Recall: 0.59\n",
            "Epoch: 0, Batch: 19130, Loss: 0.4240241140127182, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 19140, Loss: 0.5249444276094437, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 19150, Loss: 0.41799818724393845, Accuracy: 49.7, Precision: 0.55, Recall: 0.47\n",
            "Epoch: 0, Batch: 19160, Loss: 0.41129654049873354, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 19170, Loss: 0.36700033098459245, Accuracy: 50.48, Precision: 0.47, Recall: 0.42\n",
            "Epoch: 0, Batch: 19180, Loss: 0.41843152344226836, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 19190, Loss: 0.5696887671947479, Accuracy: 49.68, Precision: 0.54, Recall: 0.46\n",
            "Epoch: 0, Batch: 19200, Loss: 0.4790364995598793, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 19210, Loss: 0.36302185207605364, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 19220, Loss: 0.5546885371208191, Accuracy: 48.8, Precision: 0.56, Recall: 0.4\n",
            "Epoch: 0, Batch: 19230, Loss: 0.4759445130825043, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 19240, Loss: 0.4062639012932777, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 19250, Loss: 0.5070645570755005, Accuracy: 49.8, Precision: 0.55, Recall: 0.48\n",
            "Epoch: 0, Batch: 19260, Loss: 0.4706034421920776, Accuracy: 50.4, Precision: 0.52, Recall: 0.6\n",
            "Epoch: 0, Batch: 19270, Loss: 0.4933869048953056, Accuracy: 49.6, Precision: 0.55, Recall: 0.46\n",
            "Epoch: 0, Batch: 19280, Loss: 0.522424504160881, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 19290, Loss: 0.42172608375549314, Accuracy: 50.64, Precision: 0.46, Recall: 0.42\n",
            "Epoch: 0, Batch: 19300, Loss: 0.5612868443131447, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 19310, Loss: 0.45569905638694763, Accuracy: 50.22, Precision: 0.61, Recall: 0.51\n",
            "Epoch: 0, Batch: 19320, Loss: 0.4385536640882492, Accuracy: 49.82, Precision: 0.47, Recall: 0.53\n",
            "Epoch: 0, Batch: 19330, Loss: 0.3116144180297852, Accuracy: 50.02, Precision: 0.51, Recall: 0.51\n",
            "Epoch: 0, Batch: 19340, Loss: 0.5048419758677483, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 19350, Loss: 0.4681522995233536, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 19360, Loss: 0.42130572348833084, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 19370, Loss: 0.4802114188671112, Accuracy: 52.0, Precision: 0.4, Recall: 0.4\n",
            "Epoch: 0, Batch: 19380, Loss: 0.4509871780872345, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 19390, Loss: 0.4081611707806587, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 19400, Loss: 0.4839338526129723, Accuracy: 50.6, Precision: 0.44, Recall: 0.45\n",
            "Epoch: 0, Batch: 19410, Loss: 0.48114446401596067, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 19420, Loss: 0.4927752375602722, Accuracy: 51.32, Precision: 0.44, Recall: 0.39\n",
            "Epoch: 0, Batch: 19430, Loss: 0.3277451366186142, Accuracy: 51.28, Precision: 0.42, Recall: 0.42\n",
            "Epoch: 0, Batch: 19440, Loss: 0.4414916500449181, Accuracy: 49.92, Precision: 0.51, Recall: 0.46\n",
            "Epoch: 0, Batch: 19450, Loss: 0.3787354722619057, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 19460, Loss: 0.35197668671607973, Accuracy: 50.08, Precision: 0.46, Recall: 0.49\n",
            "Epoch: 0, Batch: 19470, Loss: 0.41978043466806414, Accuracy: 49.74, Precision: 0.63, Recall: 0.49\n",
            "Epoch: 0, Batch: 19480, Loss: 0.4992253303527832, Accuracy: 49.6, Precision: 0.46, Recall: 0.55\n",
            "Epoch: 0, Batch: 19490, Loss: 0.5525549054145813, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 19500, Loss: 0.5276593834161758, Accuracy: 50.32, Precision: 0.49, Recall: 0.34\n",
            "Epoch: 0, Batch: 19510, Loss: 0.43460812270641325, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 19520, Loss: 0.46598516404628754, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 19530, Loss: 0.4462136089801788, Accuracy: 50.98, Precision: 0.57, Recall: 0.57\n",
            "Epoch: 0, Batch: 19540, Loss: 0.4189284235239029, Accuracy: 50.48, Precision: 0.54, Recall: 0.56\n",
            "Epoch: 0, Batch: 19550, Loss: 0.3902011692523956, Accuracy: 50.24, Precision: 0.44, Recall: 0.48\n",
            "Epoch: 0, Batch: 19560, Loss: 0.4774475581943989, Accuracy: 52.34, Precision: 0.41, Recall: 0.37\n",
            "Epoch: 0, Batch: 19570, Loss: 0.40029670000076295, Accuracy: 51.04, Precision: 0.46, Recall: 0.37\n",
            "Epoch: 0, Batch: 19580, Loss: 0.4395187169313431, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 19590, Loss: 0.36042293161153793, Accuracy: 50.54, Precision: 0.53, Recall: 0.59\n",
            "Epoch: 0, Batch: 19600, Loss: 0.38626318275928495, Accuracy: 51.2, Precision: 0.45, Recall: 0.38\n",
            "Epoch: 0, Batch: 19610, Loss: 0.4416757419705391, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 19620, Loss: 0.48883512765169146, Accuracy: 49.04, Precision: 0.42, Recall: 0.56\n",
            "Epoch: 0, Batch: 19630, Loss: 0.41722094267606735, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 19640, Loss: 0.5270258337259293, Accuracy: 50.0, Precision: 0.56, Recall: 0.5\n",
            "Epoch: 0, Batch: 19650, Loss: 0.5538086593151093, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 19660, Loss: 0.39923084527254105, Accuracy: 51.6, Precision: 0.4, Recall: 0.42\n",
            "Epoch: 0, Batch: 19670, Loss: 0.4385056018829346, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 19680, Loss: 0.3979275092482567, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 19690, Loss: 0.5080313354730606, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 19700, Loss: 0.46366511285305023, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 19710, Loss: 0.5322318822145462, Accuracy: 50.12, Precision: 0.51, Recall: 0.56\n",
            "Epoch: 0, Batch: 19720, Loss: 0.37014425843954085, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 19730, Loss: 0.5562462329864502, Accuracy: 49.9, Precision: 0.55, Recall: 0.49\n",
            "Epoch: 0, Batch: 19740, Loss: 0.36484103500843046, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 19750, Loss: 0.5025169014930725, Accuracy: 50.96, Precision: 0.58, Recall: 0.56\n",
            "Epoch: 0, Batch: 19760, Loss: 0.520815733075142, Accuracy: 50.24, Precision: 0.51, Recall: 0.62\n",
            "Epoch: 0, Batch: 19770, Loss: 0.41856165900826453, Accuracy: 50.6, Precision: 0.56, Recall: 0.55\n",
            "Epoch: 0, Batch: 19780, Loss: 0.49458656907081605, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 19790, Loss: 0.3996613651514053, Accuracy: 49.9, Precision: 0.45, Recall: 0.51\n",
            "Epoch: 0, Batch: 19800, Loss: 0.3943755656480789, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 19810, Loss: 0.49601101130247116, Accuracy: 49.6, Precision: 0.52, Recall: 0.4\n",
            "Epoch: 0, Batch: 19820, Loss: 0.48108102977275846, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 19830, Loss: 0.42872912883758546, Accuracy: 50.1, Precision: 0.51, Recall: 0.55\n",
            "Epoch: 0, Batch: 19840, Loss: 0.4668190121650696, Accuracy: 53.6, Precision: 0.41, Recall: 0.3\n",
            "Epoch: 0, Batch: 19850, Loss: 0.5817007511854172, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 19860, Loss: 0.5145967036485672, Accuracy: 50.96, Precision: 0.42, Recall: 0.44\n",
            "Epoch: 0, Batch: 19870, Loss: 0.498891481757164, Accuracy: 49.8, Precision: 0.51, Recall: 0.4\n",
            "Epoch: 0, Batch: 19880, Loss: 0.4579496651887894, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 19890, Loss: 0.5008227854967118, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 19900, Loss: 0.393414731323719, Accuracy: 50.0, Precision: 0.5, Recall: 0.41\n",
            "Epoch: 0, Batch: 19910, Loss: 0.406599223613739, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "Epoch: 0, Batch: 19920, Loss: 0.4646431192755699, Accuracy: 49.88, Precision: 0.56, Recall: 0.49\n",
            "Epoch: 0, Batch: 19930, Loss: 0.443216897547245, Accuracy: 50.98, Precision: 0.57, Recall: 0.57\n",
            "Epoch: 0, Batch: 19940, Loss: 0.4377923130989075, Accuracy: 49.7, Precision: 0.47, Recall: 0.55\n",
            "Epoch: 0, Batch: 19950, Loss: 0.44372668415308, Accuracy: 49.3, Precision: 0.55, Recall: 0.43\n",
            "Epoch: 0, Batch: 19960, Loss: 0.3769829347729683, Accuracy: 50.18, Precision: 0.41, Recall: 0.49\n",
            "Epoch: 0, Batch: 19970, Loss: 0.49924971610307695, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 19980, Loss: 0.46045611798763275, Accuracy: 50.24, Precision: 0.44, Recall: 0.48\n",
            "Epoch: 0, Batch: 19990, Loss: 0.4698076814413071, Accuracy: 50.16, Precision: 0.46, Recall: 0.48\n",
            "Epoch: 0, Batch: 20000, Loss: 0.5125326305627823, Accuracy: 49.58, Precision: 0.53, Recall: 0.43\n",
            "Epoch: 0, Batch: 20010, Loss: 0.49488159716129304, Accuracy: 51.92, Precision: 0.56, Recall: 0.66\n",
            "Epoch: 0, Batch: 20020, Loss: 0.47083313167095187, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 20030, Loss: 0.3769837856292725, Accuracy: 50.0, Precision: 0.5, Recall: 0.39\n",
            "Epoch: 0, Batch: 20040, Loss: 0.48487371057271955, Accuracy: 49.6, Precision: 0.46, Recall: 0.55\n",
            "Epoch: 0, Batch: 20050, Loss: 0.41452830731868745, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 20060, Loss: 0.4027331754565239, Accuracy: 52.64, Precision: 0.39, Recall: 0.38\n",
            "Epoch: 0, Batch: 20070, Loss: 0.4008226662874222, Accuracy: 51.8, Precision: 0.44, Recall: 0.35\n",
            "Epoch: 0, Batch: 20080, Loss: 0.491001632809639, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 20090, Loss: 0.6161794006824494, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 20100, Loss: 0.3659548878669739, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 20110, Loss: 0.4569953352212906, Accuracy: 50.2, Precision: 0.52, Recall: 0.55\n",
            "Epoch: 0, Batch: 20120, Loss: 0.448479899764061, Accuracy: 52.64, Precision: 0.38, Recall: 0.39\n",
            "Epoch: 0, Batch: 20130, Loss: 0.3841787397861481, Accuracy: 50.0, Precision: 0.56, Recall: 0.5\n",
            "Epoch: 0, Batch: 20140, Loss: 0.44681652188301085, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 20150, Loss: 0.4919392853975296, Accuracy: 50.48, Precision: 0.54, Recall: 0.56\n",
            "Epoch: 0, Batch: 20160, Loss: 0.47568644881248473, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 20170, Loss: 0.5474505662918091, Accuracy: 50.14, Precision: 0.57, Recall: 0.51\n",
            "Epoch: 0, Batch: 20180, Loss: 0.41620768904685973, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 20190, Loss: 0.41763656437397, Accuracy: 49.84, Precision: 0.46, Recall: 0.52\n",
            "Epoch: 0, Batch: 20200, Loss: 0.46621933579444885, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 20210, Loss: 0.4226203948259354, Accuracy: 49.76, Precision: 0.52, Recall: 0.44\n",
            "Epoch: 0, Batch: 20220, Loss: 0.49123279452323915, Accuracy: 50.26, Precision: 0.51, Recall: 0.63\n",
            "Epoch: 0, Batch: 20230, Loss: 0.4146127596497536, Accuracy: 52.08, Precision: 0.37, Recall: 0.42\n",
            "Epoch: 0, Batch: 20240, Loss: 0.4779899299144745, Accuracy: 49.52, Precision: 0.52, Recall: 0.38\n",
            "Epoch: 0, Batch: 20250, Loss: 0.48169791996479033, Accuracy: 59.52, Precision: 0.67, Recall: 0.78\n",
            "Epoch: 0, Batch: 20260, Loss: 0.4253452196717262, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 20270, Loss: 0.43937875926494596, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 20280, Loss: 0.4941549330949783, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 20290, Loss: 0.4009981036186218, Accuracy: 50.42, Precision: 0.47, Recall: 0.43\n",
            "Epoch: 0, Batch: 20300, Loss: 0.4421949326992035, Accuracy: 49.64, Precision: 0.48, Recall: 0.59\n",
            "Epoch: 0, Batch: 20310, Loss: 0.5167677164077759, Accuracy: 50.0, Precision: 0.5, Recall: 0.41\n",
            "Epoch: 0, Batch: 20320, Loss: 0.46345439106225966, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 20330, Loss: 0.4732654333114624, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 20340, Loss: 0.3975848197937012, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 20350, Loss: 0.38970405608415604, Accuracy: 49.84, Precision: 0.46, Recall: 0.52\n",
            "Epoch: 0, Batch: 20360, Loss: 0.4448808699846268, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 20370, Loss: 0.40864264518022536, Accuracy: 50.28, Precision: 0.48, Recall: 0.43\n",
            "Epoch: 0, Batch: 20380, Loss: 0.4084378078579903, Accuracy: 49.64, Precision: 0.52, Recall: 0.41\n",
            "Epoch: 0, Batch: 20390, Loss: 0.40289550423622134, Accuracy: 51.82, Precision: 0.37, Recall: 0.43\n",
            "Epoch: 0, Batch: 20400, Loss: 0.3731020107865334, Accuracy: 49.76, Precision: 0.53, Recall: 0.46\n",
            "Epoch: 0, Batch: 20410, Loss: 0.3636534757912159, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 20420, Loss: 0.5096712350845337, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 20430, Loss: 0.45890248417854307, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 20440, Loss: 0.4921765930950642, Accuracy: 52.34, Precision: 0.37, Recall: 0.41\n",
            "Epoch: 0, Batch: 20450, Loss: 0.5519740402698516, Accuracy: 50.9, Precision: 0.47, Recall: 0.35\n",
            "Epoch: 0, Batch: 20460, Loss: 0.4666365385055542, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 20470, Loss: 0.4491846770048141, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 20480, Loss: 0.4909587576985359, Accuracy: 50.16, Precision: 0.46, Recall: 0.48\n",
            "Epoch: 0, Batch: 20490, Loss: 0.43491200506687167, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 20500, Loss: 0.49992812275886533, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 20510, Loss: 0.42313266098499297, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 20520, Loss: 0.4667347878217697, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 20530, Loss: 0.3857641018927097, Accuracy: 50.6, Precision: 0.56, Recall: 0.55\n",
            "Epoch: 0, Batch: 20540, Loss: 0.48833457827568055, Accuracy: 49.88, Precision: 0.47, Recall: 0.52\n",
            "Epoch: 0, Batch: 20550, Loss: 0.5163721218705177, Accuracy: 49.92, Precision: 0.54, Recall: 0.49\n",
            "Epoch: 0, Batch: 20560, Loss: 0.39516666531562805, Accuracy: 51.2, Precision: 0.44, Recall: 0.4\n",
            "Epoch: 0, Batch: 20570, Loss: 0.5076572448015213, Accuracy: 49.92, Precision: 0.46, Recall: 0.51\n",
            "Epoch: 0, Batch: 20580, Loss: 0.4744478315114975, Accuracy: 49.7, Precision: 0.53, Recall: 0.45\n",
            "Epoch: 0, Batch: 20590, Loss: 0.5274056017398834, Accuracy: 50.0, Precision: 0.5, Recall: 0.43\n",
            "Epoch: 0, Batch: 20600, Loss: 0.35452268421649935, Accuracy: 50.8, Precision: 0.55, Recall: 0.58\n",
            "Epoch: 0, Batch: 20610, Loss: 0.45311076641082765, Accuracy: 50.8, Precision: 0.55, Recall: 0.58\n",
            "Epoch: 0, Batch: 20620, Loss: 0.46793260872364045, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 20630, Loss: 0.4087075337767601, Accuracy: 50.24, Precision: 0.46, Recall: 0.47\n",
            "Epoch: 0, Batch: 20640, Loss: 0.4583443433046341, Accuracy: 51.12, Precision: 0.46, Recall: 0.36\n",
            "Epoch: 0, Batch: 20650, Loss: 0.2886786311864853, Accuracy: 50.24, Precision: 0.44, Recall: 0.48\n",
            "Epoch: 0, Batch: 20660, Loss: 0.5226977705955506, Accuracy: 51.12, Precision: 0.42, Recall: 0.43\n",
            "Epoch: 0, Batch: 20670, Loss: 0.3772468611598015, Accuracy: 49.76, Precision: 0.52, Recall: 0.44\n",
            "Epoch: 0, Batch: 20680, Loss: 0.47246176302433013, Accuracy: 50.64, Precision: 0.58, Recall: 0.54\n",
            "Epoch: 0, Batch: 20690, Loss: 0.58985715508461, Accuracy: 50.48, Precision: 0.54, Recall: 0.56\n",
            "Epoch: 0, Batch: 20700, Loss: 0.49884562790393827, Accuracy: 51.08, Precision: 0.59, Recall: 0.56\n",
            "Epoch: 0, Batch: 20710, Loss: 0.48536363020539286, Accuracy: 51.1, Precision: 0.55, Recall: 0.61\n",
            "Epoch: 0, Batch: 20720, Loss: 0.49812965989112856, Accuracy: 50.1, Precision: 0.51, Recall: 0.55\n",
            "Epoch: 0, Batch: 20730, Loss: 0.42291714549064635, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 20740, Loss: 0.5094770163297653, Accuracy: 50.56, Precision: 0.46, Recall: 0.43\n",
            "Epoch: 0, Batch: 20750, Loss: 0.4764417916536331, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 20760, Loss: 0.39533787667751313, Accuracy: 51.08, Precision: 0.41, Recall: 0.44\n",
            "Epoch: 0, Batch: 20770, Loss: 0.4418601930141449, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 20780, Loss: 0.3715816721320152, Accuracy: 50.9, Precision: 0.45, Recall: 0.41\n",
            "Epoch: 0, Batch: 20790, Loss: 0.4444823384284973, Accuracy: 49.94, Precision: 0.53, Recall: 0.49\n",
            "Epoch: 0, Batch: 20800, Loss: 0.3225500777363777, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 20810, Loss: 0.43083973675966264, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 20820, Loss: 0.5175824344158173, Accuracy: 50.12, Precision: 0.48, Recall: 0.47\n",
            "Epoch: 0, Batch: 20830, Loss: 0.42976104766130446, Accuracy: 50.54, Precision: 0.53, Recall: 0.59\n",
            "Epoch: 0, Batch: 20840, Loss: 0.44497174918651583, Accuracy: 50.12, Precision: 0.56, Recall: 0.51\n",
            "Epoch: 0, Batch: 20850, Loss: 0.3593118339776993, Accuracy: 50.4, Precision: 0.46, Recall: 0.45\n",
            "Epoch: 0, Batch: 20860, Loss: 0.38615324795246125, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 20870, Loss: 0.4381510853767395, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 20880, Loss: 0.4588372319936752, Accuracy: 50.9, Precision: 0.55, Recall: 0.59\n",
            "Epoch: 0, Batch: 20890, Loss: 0.4717822939157486, Accuracy: 50.24, Precision: 0.48, Recall: 0.44\n",
            "Epoch: 0, Batch: 20900, Loss: 0.5332505285739899, Accuracy: 49.8, Precision: 0.48, Recall: 0.55\n",
            "Epoch: 0, Batch: 20910, Loss: 0.4792411983013153, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 20920, Loss: 0.4453712165355682, Accuracy: 49.88, Precision: 0.51, Recall: 0.44\n",
            "Epoch: 0, Batch: 20930, Loss: 0.45466354489326477, Accuracy: 50.56, Precision: 0.57, Recall: 0.54\n",
            "Epoch: 0, Batch: 20940, Loss: 0.44332346618175505, Accuracy: 49.6, Precision: 0.48, Recall: 0.6\n",
            "Epoch: 0, Batch: 20950, Loss: 0.4691963106393814, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 20960, Loss: 0.4747494325041771, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 20970, Loss: 0.49167086780071256, Accuracy: 50.32, Precision: 0.42, Recall: 0.48\n",
            "Epoch: 0, Batch: 20980, Loss: 0.4911543905735016, Accuracy: 50.56, Precision: 0.57, Recall: 0.54\n",
            "Epoch: 0, Batch: 20990, Loss: 0.41573968529701233, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 21000, Loss: 0.31021867245435714, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 21010, Loss: 0.3746492490172386, Accuracy: 50.72, Precision: 0.56, Recall: 0.56\n",
            "Epoch: 0, Batch: 21020, Loss: 0.3993056744337082, Accuracy: 51.4, Precision: 0.57, Recall: 0.6\n",
            "Epoch: 0, Batch: 21030, Loss: 0.5734825059771538, Accuracy: 50.98, Precision: 0.43, Recall: 0.43\n",
            "Epoch: 0, Batch: 21040, Loss: 0.560833315551281, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 21050, Loss: 0.48265266716480254, Accuracy: 50.24, Precision: 0.49, Recall: 0.38\n",
            "Epoch: 0, Batch: 21060, Loss: 0.4655035972595215, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 21070, Loss: 0.41629366874694823, Accuracy: 50.48, Precision: 0.52, Recall: 0.62\n",
            "Epoch: 0, Batch: 21080, Loss: 0.5204060733318329, Accuracy: 50.54, Precision: 0.53, Recall: 0.59\n",
            "Epoch: 0, Batch: 21090, Loss: 0.39902625530958175, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 21100, Loss: 0.4139584705233574, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 21110, Loss: 0.5441044613718986, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 21120, Loss: 0.41695816218853, Accuracy: 51.92, Precision: 0.42, Recall: 0.38\n",
            "Epoch: 0, Batch: 21130, Loss: 0.4217535063624382, Accuracy: 51.12, Precision: 0.57, Recall: 0.58\n",
            "Epoch: 0, Batch: 21140, Loss: 0.40990337580442426, Accuracy: 50.6, Precision: 0.55, Recall: 0.56\n",
            "Epoch: 0, Batch: 21150, Loss: 0.515345947444439, Accuracy: 50.2, Precision: 0.55, Recall: 0.52\n",
            "Epoch: 0, Batch: 21160, Loss: 0.4084389515221119, Accuracy: 49.44, Precision: 0.46, Recall: 0.57\n",
            "Epoch: 0, Batch: 21170, Loss: 0.4096512019634247, Accuracy: 51.0, Precision: 0.45, Recall: 0.4\n",
            "Epoch: 0, Batch: 21180, Loss: 0.4778690040111542, Accuracy: 51.76, Precision: 0.42, Recall: 0.39\n",
            "Epoch: 0, Batch: 21190, Loss: 0.4084253191947937, Accuracy: 51.92, Precision: 0.42, Recall: 0.38\n",
            "Epoch: 0, Batch: 21200, Loss: 0.35475843846797944, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 21210, Loss: 0.4285174489021301, Accuracy: 50.28, Precision: 0.57, Recall: 0.52\n",
            "Epoch: 0, Batch: 21220, Loss: 0.44229911267757416, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 21230, Loss: 0.4194778501987457, Accuracy: 50.72, Precision: 0.44, Recall: 0.44\n",
            "Epoch: 0, Batch: 21240, Loss: 0.3676679998636246, Accuracy: 50.24, Precision: 0.48, Recall: 0.44\n",
            "Epoch: 0, Batch: 21250, Loss: 0.4638732224702835, Accuracy: 53.3, Precision: 0.39, Recall: 0.35\n",
            "Epoch: 0, Batch: 21260, Loss: 0.4430256813764572, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 21270, Loss: 0.4955885648727417, Accuracy: 51.28, Precision: 0.42, Recall: 0.42\n",
            "Epoch: 0, Batch: 21280, Loss: 0.39395536333322523, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 21290, Loss: 0.43512520641088487, Accuracy: 49.76, Precision: 0.53, Recall: 0.46\n",
            "Epoch: 0, Batch: 21300, Loss: 0.43407483398914337, Accuracy: 50.0, Precision: 0.57, Recall: 0.5\n",
            "Epoch: 0, Batch: 21310, Loss: 0.5057260200381279, Accuracy: 50.0, Precision: 0.5, Recall: 0.61\n",
            "Epoch: 0, Batch: 21320, Loss: 0.38589566498994826, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 21330, Loss: 0.4549896210432053, Accuracy: 50.12, Precision: 0.49, Recall: 0.44\n",
            "Epoch: 0, Batch: 21340, Loss: 0.47615492939949033, Accuracy: 49.64, Precision: 0.48, Recall: 0.59\n",
            "Epoch: 0, Batch: 21350, Loss: 0.5211781218647957, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 21360, Loss: 0.4242164835333824, Accuracy: 50.0, Precision: 0.52, Recall: 0.5\n",
            "Epoch: 0, Batch: 21370, Loss: 0.48996506780385973, Accuracy: 49.6, Precision: 0.45, Recall: 0.54\n",
            "Epoch: 0, Batch: 21380, Loss: 0.44981936514377596, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 21390, Loss: 0.5324067011475563, Accuracy: 49.92, Precision: 0.54, Recall: 0.49\n",
            "Epoch: 0, Batch: 21400, Loss: 0.4638803690671921, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 21410, Loss: 0.43213253915309907, Accuracy: 49.46, Precision: 0.53, Recall: 0.41\n",
            "Epoch: 0, Batch: 21420, Loss: 0.5205652207136154, Accuracy: 51.04, Precision: 0.37, Recall: 0.46\n",
            "Epoch: 0, Batch: 21430, Loss: 0.498195481300354, Accuracy: 50.66, Precision: 0.47, Recall: 0.39\n",
            "Epoch: 0, Batch: 21440, Loss: 0.5374927014112473, Accuracy: 51.44, Precision: 0.44, Recall: 0.38\n",
            "Epoch: 0, Batch: 21450, Loss: 0.4167836308479309, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 21460, Loss: 0.4450511664152145, Accuracy: 50.64, Precision: 0.58, Recall: 0.54\n",
            "Epoch: 0, Batch: 21470, Loss: 0.4446648329496384, Accuracy: 50.2, Precision: 0.52, Recall: 0.55\n",
            "Epoch: 0, Batch: 21480, Loss: 0.43410049080848695, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 21490, Loss: 0.5696228802204132, Accuracy: 50.3, Precision: 0.55, Recall: 0.53\n",
            "Epoch: 0, Batch: 21500, Loss: 0.40533208549022676, Accuracy: 49.88, Precision: 0.44, Recall: 0.51\n",
            "Epoch: 0, Batch: 21510, Loss: 0.5028838485479354, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 21520, Loss: 0.4176992952823639, Accuracy: 49.96, Precision: 0.52, Recall: 0.49\n",
            "Epoch: 0, Batch: 21530, Loss: 0.43052539229393005, Accuracy: 50.0, Precision: 0.53, Recall: 0.5\n",
            "Epoch: 0, Batch: 21540, Loss: 0.5117550522089005, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 21550, Loss: 0.406393900513649, Accuracy: 51.4, Precision: 0.43, Recall: 0.4\n",
            "Epoch: 0, Batch: 21560, Loss: 0.4903587520122528, Accuracy: 51.0, Precision: 0.45, Recall: 0.4\n",
            "Epoch: 0, Batch: 21570, Loss: 0.4590743437409401, Accuracy: 50.98, Precision: 0.43, Recall: 0.43\n",
            "Epoch: 0, Batch: 21580, Loss: 0.47946117222309115, Accuracy: 50.48, Precision: 0.46, Recall: 0.44\n",
            "Epoch: 0, Batch: 21590, Loss: 0.42096127569675446, Accuracy: 50.0, Precision: 0.46, Recall: 0.5\n",
            "Epoch: 0, Batch: 21600, Loss: 0.3973131820559502, Accuracy: 50.24, Precision: 0.56, Recall: 0.52\n",
            "Epoch: 0, Batch: 21610, Loss: 0.4178121104836464, Accuracy: 50.72, Precision: 0.54, Recall: 0.59\n",
            "Epoch: 0, Batch: 21620, Loss: 0.46678886860609053, Accuracy: 51.96, Precision: 0.36, Recall: 0.43\n",
            "Epoch: 0, Batch: 21630, Loss: 0.46794145107269286, Accuracy: 49.84, Precision: 0.51, Recall: 0.42\n",
            "Epoch: 0, Batch: 21640, Loss: 0.41237024366855624, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 21650, Loss: 0.5601247280836106, Accuracy: 50.12, Precision: 0.49, Recall: 0.44\n",
            "Epoch: 0, Batch: 21660, Loss: 0.41875835955142976, Accuracy: 55.1, Precision: 0.35, Recall: 0.33\n",
            "Epoch: 0, Batch: 21670, Loss: 0.4277177929878235, Accuracy: 49.78, Precision: 0.51, Recall: 0.39\n",
            "Epoch: 0, Batch: 21680, Loss: 0.4931447088718414, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 21690, Loss: 0.4858620330691338, Accuracy: 50.0, Precision: 0.49, Recall: 0.5\n",
            "Epoch: 0, Batch: 21700, Loss: 0.41799630522727965, Accuracy: 50.54, Precision: 0.47, Recall: 0.41\n",
            "Epoch: 0, Batch: 21710, Loss: 0.4009023457765579, Accuracy: 50.98, Precision: 0.43, Recall: 0.43\n",
            "Epoch: 0, Batch: 21720, Loss: 0.34900550693273547, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 21730, Loss: 0.33826655223965646, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 21740, Loss: 0.41403206884860994, Accuracy: 50.72, Precision: 0.46, Recall: 0.41\n",
            "Epoch: 0, Batch: 21750, Loss: 0.42659344524145126, Accuracy: 50.6, Precision: 0.47, Recall: 0.4\n",
            "Epoch: 0, Batch: 21760, Loss: 0.5631364732980728, Accuracy: 50.2, Precision: 0.49, Recall: 0.4\n",
            "Epoch: 0, Batch: 21770, Loss: 0.4307221457362175, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 21780, Loss: 0.3977536201477051, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 21790, Loss: 0.40300295054912566, Accuracy: 50.24, Precision: 0.47, Recall: 0.46\n",
            "Epoch: 0, Batch: 21800, Loss: 0.3881682217121124, Accuracy: 49.86, Precision: 0.51, Recall: 0.43\n",
            "Epoch: 0, Batch: 21810, Loss: 0.39110508263111116, Accuracy: 50.08, Precision: 0.49, Recall: 0.46\n",
            "Epoch: 0, Batch: 21820, Loss: 0.4298178359866142, Accuracy: 49.9, Precision: 0.45, Recall: 0.51\n",
            "Epoch: 0, Batch: 21830, Loss: 0.42976885885000227, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 21840, Loss: 0.4056802898645401, Accuracy: 49.76, Precision: 0.56, Recall: 0.48\n",
            "Epoch: 0, Batch: 21850, Loss: 0.4346037030220032, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 21860, Loss: 0.46919365376234057, Accuracy: 49.92, Precision: 0.48, Recall: 0.52\n",
            "Epoch: 0, Batch: 21870, Loss: 0.31509528756141664, Accuracy: 50.6, Precision: 0.56, Recall: 0.55\n",
            "Epoch: 0, Batch: 21880, Loss: 0.5595719933509826, Accuracy: 50.24, Precision: 0.53, Recall: 0.54\n",
            "Epoch: 0, Batch: 21890, Loss: 0.5030643522739411, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 21900, Loss: 0.37485570311546323, Accuracy: 50.9, Precision: 0.47, Recall: 0.35\n",
            "Epoch: 0, Batch: 21910, Loss: 0.5403165355324745, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 21920, Loss: 0.42307100147008897, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 21930, Loss: 0.41730119585990905, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 21940, Loss: 0.35071278363466263, Accuracy: 52.16, Precision: 0.41, Recall: 0.38\n",
            "Epoch: 0, Batch: 21950, Loss: 0.43717585504055023, Accuracy: 50.48, Precision: 0.58, Recall: 0.53\n",
            "Epoch: 0, Batch: 21960, Loss: 0.4098717361688614, Accuracy: 50.0, Precision: 0.5, Recall: 0.56\n",
            "Epoch: 0, Batch: 21970, Loss: 0.41637229472398757, Accuracy: 49.68, Precision: 0.46, Recall: 0.54\n",
            "Epoch: 0, Batch: 21980, Loss: 0.5890225738286972, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 21990, Loss: 0.41341447830200195, Accuracy: 49.94, Precision: 0.53, Recall: 0.49\n",
            "Epoch: 0, Batch: 22000, Loss: 0.3985471099615097, Accuracy: 50.16, Precision: 0.52, Recall: 0.54\n",
            "Epoch: 0, Batch: 22010, Loss: 0.41302055567502977, Accuracy: 52.2, Precision: 0.39, Recall: 0.4\n",
            "Epoch: 0, Batch: 22020, Loss: 0.4957021027803421, Accuracy: 49.76, Precision: 0.51, Recall: 0.38\n",
            "Epoch: 0, Batch: 22030, Loss: 0.44695409536361697, Accuracy: 50.12, Precision: 0.56, Recall: 0.51\n",
            "Epoch: 0, Batch: 22040, Loss: 0.45143945068120955, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 22050, Loss: 0.4856351166963577, Accuracy: 49.88, Precision: 0.53, Recall: 0.48\n",
            "Epoch: 0, Batch: 22060, Loss: 0.36761172115802765, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 22070, Loss: 0.4419050455093384, Accuracy: 50.9, Precision: 0.55, Recall: 0.59\n",
            "Epoch: 0, Batch: 22080, Loss: 0.4265434563159943, Accuracy: 50.36, Precision: 0.53, Recall: 0.56\n",
            "Epoch: 0, Batch: 22090, Loss: 0.4541798710823059, Accuracy: 50.48, Precision: 0.53, Recall: 0.58\n",
            "Epoch: 0, Batch: 22100, Loss: 0.46165103912353517, Accuracy: 49.28, Precision: 0.54, Recall: 0.41\n",
            "Epoch: 0, Batch: 22110, Loss: 0.3599650800228119, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 22120, Loss: 0.42303926944732667, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 22130, Loss: 0.45016643702983855, Accuracy: 50.0, Precision: 0.5, Recall: 0.46\n",
            "Epoch: 0, Batch: 22140, Loss: 0.467633618414402, Accuracy: 51.26, Precision: 0.43, Recall: 0.41\n",
            "Epoch: 0, Batch: 22150, Loss: 0.49836456030607224, Accuracy: 50.0, Precision: 0.5, Recall: 0.56\n",
            "Epoch: 0, Batch: 22160, Loss: 0.4865290090441704, Accuracy: 50.72, Precision: 0.47, Recall: 0.38\n",
            "Epoch: 0, Batch: 22170, Loss: 0.5171751707792283, Accuracy: 49.98, Precision: 0.51, Recall: 0.49\n",
            "Epoch: 0, Batch: 22180, Loss: 0.4072684466838837, Accuracy: 50.7, Precision: 0.43, Recall: 0.45\n",
            "Epoch: 0, Batch: 22190, Loss: 0.375094398856163, Accuracy: 51.76, Precision: 0.42, Recall: 0.39\n",
            "Epoch: 0, Batch: 22200, Loss: 0.42308740615844725, Accuracy: 50.14, Precision: 0.49, Recall: 0.43\n",
            "Epoch: 0, Batch: 22210, Loss: 0.47101930975914, Accuracy: 50.2, Precision: 0.48, Recall: 0.45\n",
            "Epoch: 0, Batch: 22220, Loss: 0.4541498675942421, Accuracy: 50.2, Precision: 0.52, Recall: 0.55\n",
            "Epoch: 0, Batch: 22230, Loss: 0.5271606981754303, Accuracy: 50.48, Precision: 0.42, Recall: 0.47\n",
            "Epoch: 0, Batch: 22240, Loss: 0.38498255908489226, Accuracy: 49.88, Precision: 0.53, Recall: 0.48\n",
            "Epoch: 0, Batch: 22250, Loss: 0.4121960699558258, Accuracy: 51.44, Precision: 0.62, Recall: 0.56\n",
            "Epoch: 0, Batch: 22260, Loss: 0.3838929757475853, Accuracy: 50.0, Precision: 0.5, Recall: 0.6\n",
            "Epoch: 0, Batch: 22270, Loss: 0.43575385957956314, Accuracy: 50.36, Precision: 0.56, Recall: 0.53\n",
            "Epoch: 0, Batch: 22280, Loss: 0.514075642824173, Accuracy: 49.96, Precision: 0.49, Recall: 0.52\n",
            "Epoch: 0, Batch: 22290, Loss: 0.43836947083473204, Accuracy: 50.08, Precision: 0.52, Recall: 0.52\n",
            "Epoch: 0, Batch: 22300, Loss: 0.4143825024366379, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 22310, Loss: 0.35855151116847994, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 22320, Loss: 0.3218283370137215, Accuracy: 50.04, Precision: 0.51, Recall: 0.52\n",
            "Epoch: 0, Batch: 22330, Loss: 0.4626483231782913, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 22340, Loss: 0.5213775411248207, Accuracy: 51.98, Precision: 0.61, Recall: 0.59\n",
            "Epoch: 0, Batch: 22350, Loss: 0.4145678073167801, Accuracy: 50.8, Precision: 0.42, Recall: 0.45\n",
            "Epoch: 0, Batch: 22360, Loss: 0.3934102118015289, Accuracy: 50.0, Precision: 0.5, Recall: 0.48\n",
            "Epoch: 0, Batch: 22370, Loss: 0.470722296833992, Accuracy: 49.76, Precision: 0.54, Recall: 0.47\n",
            "Epoch: 0, Batch: 22380, Loss: 0.4108051359653473, Accuracy: 50.0, Precision: 0.43, Recall: 0.5\n",
            "Epoch: 0, Batch: 22390, Loss: 0.47015257477760314, Accuracy: 49.86, Precision: 0.57, Recall: 0.49\n",
            "Epoch: 0, Batch: 22400, Loss: 0.4224844425916672, Accuracy: 51.6, Precision: 0.6, Recall: 0.58\n",
            "Epoch: 0, Batch: 22410, Loss: 0.4635396897792816, Accuracy: 51.04, Precision: 0.54, Recall: 0.63\n",
            "Epoch: 0, Batch: 22420, Loss: 0.4213541954755783, Accuracy: 50.0, Precision: 0.5, Recall: 0.57\n",
            "Epoch: 0, Batch: 22430, Loss: 0.48026719093322756, Accuracy: 50.0, Precision: 0.5, Recall: 0.39\n",
            "Epoch: 0, Batch: 22440, Loss: 0.5271762520074844, Accuracy: 49.76, Precision: 0.52, Recall: 0.44\n",
            "Epoch: 0, Batch: 22450, Loss: 0.4198432132601738, Accuracy: 50.88, Precision: 0.54, Recall: 0.61\n",
            "Epoch: 0, Batch: 22460, Loss: 0.45403388142585754, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 22470, Loss: 0.41029041856527326, Accuracy: 50.0, Precision: 0.5, Recall: 0.47\n",
            "Epoch: 0, Batch: 22480, Loss: 0.3832173213362694, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 22490, Loss: 0.36005831956863404, Accuracy: 50.8, Precision: 0.55, Recall: 0.58\n",
            "Epoch: 0, Batch: 22500, Loss: 0.42111523151397706, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 22510, Loss: 0.5163744211196899, Accuracy: 50.24, Precision: 0.46, Recall: 0.47\n",
            "Epoch: 0, Batch: 22520, Loss: 0.5146979331970215, Accuracy: 49.92, Precision: 0.49, Recall: 0.54\n",
            "Epoch: 0, Batch: 22530, Loss: 0.46647484302520753, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 22540, Loss: 0.4531641751527786, Accuracy: 49.76, Precision: 0.52, Recall: 0.44\n",
            "Epoch: 0, Batch: 22550, Loss: 0.38865192532539367, Accuracy: 51.92, Precision: 0.44, Recall: 0.34\n",
            "Epoch: 0, Batch: 22560, Loss: 0.4223396614193916, Accuracy: 50.72, Precision: 0.54, Recall: 0.59\n",
            "Epoch: 0, Batch: 22570, Loss: 0.41991665959358215, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 22580, Loss: 0.45410528481006623, Accuracy: 50.4, Precision: 0.45, Recall: 0.46\n",
            "Epoch: 0, Batch: 22590, Loss: 0.5025798797607421, Accuracy: 50.0, Precision: 0.5, Recall: 0.4\n",
            "Epoch: 0, Batch: 22600, Loss: 0.4003115460276604, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 22610, Loss: 0.4678613871335983, Accuracy: 50.4, Precision: 0.54, Recall: 0.55\n",
            "Epoch: 0, Batch: 22620, Loss: 0.4113489165902138, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 22630, Loss: 0.472237229347229, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 22640, Loss: 0.3352485284209251, Accuracy: 50.3, Precision: 0.47, Recall: 0.45\n",
            "Epoch: 0, Batch: 22650, Loss: 0.41614986062049864, Accuracy: 50.1, Precision: 0.49, Recall: 0.45\n",
            "Epoch: 0, Batch: 22660, Loss: 0.4157418042421341, Accuracy: 50.96, Precision: 0.56, Recall: 0.58\n",
            "Epoch: 0, Batch: 22670, Loss: 0.43392919301986693, Accuracy: 50.28, Precision: 0.43, Recall: 0.48\n",
            "Epoch: 0, Batch: 22680, Loss: 0.45845836102962495, Accuracy: 50.4, Precision: 0.48, Recall: 0.4\n",
            "Epoch: 0, Batch: 22690, Loss: 0.4450201168656349, Accuracy: 50.32, Precision: 0.48, Recall: 0.42\n",
            "Epoch: 0, Batch: 22700, Loss: 0.41005077213048935, Accuracy: 49.88, Precision: 0.48, Recall: 0.53\n",
            "Epoch: 0, Batch: 22710, Loss: 0.5320787191390991, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 22720, Loss: 0.45814346969127656, Accuracy: 51.26, Precision: 0.59, Recall: 0.57\n",
            "Epoch: 0, Batch: 22730, Loss: 0.45052369832992556, Accuracy: 50.7, Precision: 0.57, Recall: 0.55\n",
            "Epoch: 0, Batch: 22740, Loss: 0.35304597169160845, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 22750, Loss: 0.5512081652879715, Accuracy: 50.28, Precision: 0.57, Recall: 0.52\n",
            "Epoch: 0, Batch: 22760, Loss: 0.4326650008559227, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 22770, Loss: 0.4968277156352997, Accuracy: 50.06, Precision: 0.51, Recall: 0.53\n",
            "Epoch: 0, Batch: 22780, Loss: 0.4777131214737892, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 22790, Loss: 0.40429034233093264, Accuracy: 50.7, Precision: 0.45, Recall: 0.43\n",
            "Epoch: 0, Batch: 22800, Loss: 0.43134516626596453, Accuracy: 50.12, Precision: 0.47, Recall: 0.48\n",
            "Epoch: 0, Batch: 22810, Loss: 0.37898790240287783, Accuracy: 50.7, Precision: 0.57, Recall: 0.55\n",
            "Epoch: 0, Batch: 22820, Loss: 0.5336945161223412, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 22830, Loss: 0.44127956330776213, Accuracy: 50.1, Precision: 0.55, Recall: 0.51\n",
            "Epoch: 0, Batch: 22840, Loss: 0.45725875794887544, Accuracy: 51.92, Precision: 0.42, Recall: 0.38\n",
            "Epoch: 0, Batch: 22850, Loss: 0.45841948986053466, Accuracy: 50.56, Precision: 0.54, Recall: 0.57\n",
            "Epoch: 0, Batch: 22860, Loss: 0.600280424952507, Accuracy: 50.0, Precision: 0.48, Recall: 0.5\n",
            "Epoch: 0, Batch: 22870, Loss: 0.42079560458660126, Accuracy: 50.8, Precision: 0.42, Recall: 0.45\n",
            "Epoch: 0, Batch: 22880, Loss: 0.4925190985202789, Accuracy: 49.74, Precision: 0.51, Recall: 0.37\n",
            "Epoch: 0, Batch: 22890, Loss: 0.38425158262252807, Accuracy: 51.62, Precision: 0.41, Recall: 0.41\n",
            "Epoch: 0, Batch: 22900, Loss: 0.46987502425909045, Accuracy: 50.0, Precision: 0.5, Recall: 0.51\n",
            "Epoch: 0, Batch: 22910, Loss: 0.4547350645065308, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 22920, Loss: 0.4621722877025604, Accuracy: 50.8, Precision: 0.46, Recall: 0.4\n",
            "Epoch: 0, Batch: 22930, Loss: 0.38112039864063263, Accuracy: 50.18, Precision: 0.47, Recall: 0.47\n",
            "Epoch: 0, Batch: 22940, Loss: 0.39598518908023833, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 22950, Loss: 0.423787023127079, Accuracy: 49.02, Precision: 0.43, Recall: 0.57\n",
            "Epoch: 0, Batch: 22960, Loss: 0.3640416577458382, Accuracy: 50.24, Precision: 0.49, Recall: 0.38\n",
            "Epoch: 0, Batch: 22970, Loss: 0.45464499294757843, Accuracy: 51.8, Precision: 0.44, Recall: 0.35\n",
            "Epoch: 0, Batch: 22980, Loss: 0.49621260166168213, Accuracy: 49.92, Precision: 0.49, Recall: 0.54\n",
            "Epoch: 0, Batch: 22990, Loss: 0.469975171983242, Accuracy: 50.08, Precision: 0.51, Recall: 0.54\n",
            "Epoch: 0, Batch: 23000, Loss: 0.5048062175512313, Accuracy: 50.2, Precision: 0.45, Recall: 0.48\n",
            "Epoch: 0, Batch: 23010, Loss: 0.5008942425251007, Accuracy: 50.0, Precision: 0.5, Recall: 0.44\n",
            "Epoch: 0, Batch: 23020, Loss: 0.45523504763841627, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 23030, Loss: 0.5044103264808655, Accuracy: 49.92, Precision: 0.52, Recall: 0.48\n",
            "Epoch: 0, Batch: 23040, Loss: 0.43505880534648894, Accuracy: 50.0, Precision: 0.5, Recall: 0.58\n",
            "Epoch: 0, Batch: 23050, Loss: 0.37272651940584184, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 23060, Loss: 0.44561128616333007, Accuracy: 49.78, Precision: 0.51, Recall: 0.39\n",
            "Epoch: 0, Batch: 23070, Loss: 0.4140401542186737, Accuracy: 49.94, Precision: 0.47, Recall: 0.51\n",
            "Epoch: 0, Batch: 23080, Loss: 0.4338573932647705, Accuracy: 51.68, Precision: 0.57, Recall: 0.62\n",
            "Epoch: 0, Batch: 23090, Loss: 0.43577553033828736, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 23100, Loss: 0.4112252458930016, Accuracy: 50.04, Precision: 0.48, Recall: 0.49\n",
            "Epoch: 0, Batch: 23110, Loss: 0.48410662859678266, Accuracy: 50.42, Precision: 0.43, Recall: 0.47\n",
            "Epoch: 0, Batch: 23120, Loss: 0.42277057468891144, Accuracy: 51.6, Precision: 0.4, Recall: 0.42\n",
            "Epoch: 0, Batch: 23130, Loss: 0.5392267554998398, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 23140, Loss: 0.5053877502679824, Accuracy: 49.92, Precision: 0.49, Recall: 0.54\n",
            "Epoch: 0, Batch: 23150, Loss: 0.4229241371154785, Accuracy: 50.0, Precision: 0.5, Recall: 0.49\n",
            "Epoch: 0, Batch: 23160, Loss: 0.4346927680075169, Accuracy: 51.82, Precision: 0.57, Recall: 0.63\n",
            "Epoch: 0, Batch: 23170, Loss: 0.4525963827967644, Accuracy: 50.48, Precision: 0.56, Recall: 0.54\n",
            "Epoch: 0, Batch: 23180, Loss: 0.46786875277757645, Accuracy: 49.5, Precision: 0.45, Recall: 0.55\n",
            "Epoch: 0, Batch: 23190, Loss: 0.42951221764087677, Accuracy: 50.6, Precision: 0.45, Recall: 0.44\n",
            "Epoch: 0, Batch: 23200, Loss: 0.43727951496839523, Accuracy: 49.92, Precision: 0.51, Recall: 0.46\n",
            "Epoch: 0, Batch: 23210, Loss: 0.467345829308033, Accuracy: 50.08, Precision: 0.54, Recall: 0.51\n",
            "Epoch: 0, Batch: 23220, Loss: 0.4517334461212158, Accuracy: 50.14, Precision: 0.57, Recall: 0.51\n",
            "Epoch: 0, Batch: 23230, Loss: 0.503167936205864, Accuracy: 50.3, Precision: 0.51, Recall: 0.65\n",
            "Epoch: 0, Batch: 23240, Loss: 0.485597026348114, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 23250, Loss: 0.4479550987482071, Accuracy: 49.16, Precision: 0.56, Recall: 0.43\n",
            "Epoch: 0, Batch: 23260, Loss: 0.5032737106084824, Accuracy: 50.56, Precision: 0.52, Recall: 0.64\n",
            "Epoch: 0, Batch: 23270, Loss: 0.48384194672107694, Accuracy: 50.84, Precision: 0.56, Recall: 0.57\n",
            "Epoch: 0, Batch: 23280, Loss: 0.3863816767930984, Accuracy: 50.24, Precision: 0.56, Recall: 0.52\n",
            "Epoch: 0, Batch: 23290, Loss: 0.45973907709121703, Accuracy: 49.98, Precision: 0.49, Recall: 0.51\n",
            "Epoch: 0, Batch: 23300, Loss: 0.444004213809967, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 23310, Loss: 0.420091213285923, Accuracy: 50.24, Precision: 0.54, Recall: 0.53\n",
            "Epoch: 0, Batch: 23320, Loss: 0.36602821946144104, Accuracy: 50.84, Precision: 0.43, Recall: 0.44\n",
            "Epoch: 0, Batch: 23330, Loss: 0.5190899223089218, Accuracy: 51.2, Precision: 0.44, Recall: 0.4\n",
            "Epoch: 0, Batch: 23340, Loss: 0.34271052330732343, Accuracy: 51.44, Precision: 0.42, Recall: 0.41\n",
            "Epoch: 0, Batch: 23350, Loss: 0.4963874354958534, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 23360, Loss: 0.4703664168715477, Accuracy: 49.94, Precision: 0.51, Recall: 0.47\n",
            "Epoch: 0, Batch: 23370, Loss: 0.46732428967952727, Accuracy: 50.0, Precision: 0.47, Recall: 0.5\n",
            "Epoch: 0, Batch: 23380, Loss: 0.41941528022289276, Accuracy: 51.76, Precision: 0.58, Recall: 0.61\n",
            "Epoch: 0, Batch: 23390, Loss: 0.5184172749519348, Accuracy: 50.0, Precision: 0.5, Recall: 0.5\n",
            "Epoch: 0, Batch: 23400, Loss: 0.480220665037632, Accuracy: 50.06, Precision: 0.49, Recall: 0.47\n",
            "Epoch: 0, Batch: 23410, Loss: 0.353055003285408, Accuracy: 51.08, Precision: 0.59, Recall: 0.56\n",
            "Epoch: 0, Batch: 23420, Loss: 0.5359181880950927, Accuracy: 49.78, Precision: 0.39, Recall: 0.51\n",
            "Epoch: 0, Batch: 23430, Loss: 0.4750701144337654, Accuracy: 49.78, Precision: 0.51, Recall: 0.39\n",
            "Epoch: 0, Batch: 23440, Loss: 0.6131845593452454, Accuracy: 50.8, Precision: 0.6, Recall: 0.54\n",
            "Epoch: 0, Batch: 23450, Loss: 0.4478056848049164, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 23460, Loss: 0.46877354979515073, Accuracy: 50.32, Precision: 0.54, Recall: 0.54\n",
            "Epoch: 0, Batch: 23470, Loss: 0.4626574695110321, Accuracy: 50.0, Precision: 0.5, Recall: 0.52\n",
            "Epoch: 0, Batch: 23480, Loss: 0.35535713732242585, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 23490, Loss: 0.47098219096660615, Accuracy: 50.02, Precision: 0.49, Recall: 0.49\n",
            "Epoch: 0, Batch: 23500, Loss: 0.44666669964790345, Accuracy: 49.96, Precision: 0.48, Recall: 0.51\n",
            "Epoch: 0, Batch: 23510, Loss: 0.44004901945590974, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 23520, Loss: 0.3777839794754982, Accuracy: 50.32, Precision: 0.52, Recall: 0.58\n",
            "Epoch: 0, Batch: 23530, Loss: 0.5438983857631683, Accuracy: 50.36, Precision: 0.47, Recall: 0.44\n",
            "Epoch: 0, Batch: 23540, Loss: 0.44978790879249575, Accuracy: 50.0, Precision: 0.5, Recall: 0.55\n",
            "Epoch: 0, Batch: 23550, Loss: 0.43933713287115095, Accuracy: 51.54, Precision: 0.43, Recall: 0.39\n",
            "Epoch: 0, Batch: 23560, Loss: 0.4606633991003036, Accuracy: 50.0, Precision: 0.58, Recall: 0.5\n",
            "Epoch: 0, Batch: 23570, Loss: 0.42847115844488143, Accuracy: 51.44, Precision: 0.42, Recall: 0.41\n",
            "Epoch: 0, Batch: 23580, Loss: 0.41376558840274813, Accuracy: 53.4, Precision: 0.6, Recall: 0.67\n",
            "Epoch: 0, Batch: 23590, Loss: 0.37554988712072374, Accuracy: 50.1, Precision: 0.45, Recall: 0.49\n",
            "Epoch: 0, Batch: 23600, Loss: 0.3223873481154442, Accuracy: 50.06, Precision: 0.47, Recall: 0.49\n",
            "Epoch: 0, Batch: 23610, Loss: 0.37529669106006625, Accuracy: 49.9, Precision: 0.51, Recall: 0.45\n",
            "Epoch: 0, Batch: 23620, Loss: 0.5436308234930038, Accuracy: 50.36, Precision: 0.52, Recall: 0.59\n",
            "Epoch: 0, Batch: 23630, Loss: 0.4704128593206406, Accuracy: 50.24, Precision: 0.48, Recall: 0.44\n",
            "Epoch: 0, Batch: 23640, Loss: 0.3690156154334545, Accuracy: 50.24, Precision: 0.56, Recall: 0.52\n",
            "Epoch: 0, Batch: 23650, Loss: 0.4331283539533615, Accuracy: 50.72, Precision: 0.56, Recall: 0.56\n",
            "Epoch: 0, Batch: 23660, Loss: 0.48367756605148315, Accuracy: 50.8, Precision: 0.55, Recall: 0.58\n",
            "Epoch: 0, Batch: 23670, Loss: 0.5793596029281616, Accuracy: 50.0, Precision: 0.5, Recall: 0.53\n",
            "Epoch: 0, Batch: 23680, Loss: 0.46937682330608366, Accuracy: 49.92, Precision: 0.54, Recall: 0.49\n",
            "Epoch: 0, Batch: 23690, Loss: 0.5178621649742127, Accuracy: 49.94, Precision: 0.49, Recall: 0.53\n",
            "Epoch: 0, Batch: 23700, Loss: 0.5702384173870086, Accuracy: 50.42, Precision: 0.53, Recall: 0.57\n",
            "Epoch: 0, Batch: 23710, Loss: 0.46997949481010437, Accuracy: 51.04, Precision: 0.46, Recall: 0.37\n",
            "Epoch: 0, Batch: 23720, Loss: 0.40205455422401426, Accuracy: 50.5, Precision: 0.45, Recall: 0.45\n",
            "Epoch: 0, Batch: 23730, Loss: 0.5124036461114884, Accuracy: 49.72, Precision: 0.57, Recall: 0.48\n",
            "Epoch: 0, Batch: 23740, Loss: 0.5406526654958725, Accuracy: 49.82, Precision: 0.41, Recall: 0.51\n",
            "Epoch: 0, Batch: 23750, Loss: 0.45958613604307175, Accuracy: 50.0, Precision: 0.5, Recall: 0.45\n",
            "Epoch: 0, Batch: 23760, Loss: 0.4532629013061523, Accuracy: 51.04, Precision: 0.46, Recall: 0.37\n",
            "Epoch: 0, Batch: 23770, Loss: 0.39509122669696806, Accuracy: 51.32, Precision: 0.56, Recall: 0.61\n",
            "Epoch: 0, Batch: 23780, Loss: 0.45264868140220643, Accuracy: 50.48, Precision: 0.54, Recall: 0.56\n",
            "Epoch: 0, Batch: 23790, Loss: 0.39532698392868043, Accuracy: 50.0, Precision: 0.5, Recall: 0.54\n",
            "Epoch: 0, Batch: 23800, Loss: 0.43193455040454865, Accuracy: 50.04, Precision: 0.49, Recall: 0.48\n",
            "Epoch: 0, Batch: 23810, Loss: 0.5217270463705063, Accuracy: 50.12, Precision: 0.56, Recall: 0.51\n",
            "Epoch: 0, Batch: 23820, Loss: 0.383596570789814, Accuracy: 50.28, Precision: 0.52, Recall: 0.57\n",
            "Epoch: 0, Batch: 23830, Loss: 0.41427197605371474, Accuracy: 50.3, Precision: 0.45, Recall: 0.47\n",
            "Epoch: 0, Batch: 23840, Loss: 0.42439628690481185, Accuracy: 50.8, Precision: 0.45, Recall: 0.42\n",
            "Epoch: 0, Batch: 23850, Loss: 0.40213954746723174, Accuracy: 49.84, Precision: 0.54, Recall: 0.48\n",
            "Epoch: 0, Batch: 23860, Loss: 0.47618611603975297, Accuracy: 50.72, Precision: 0.54, Recall: 0.59\n",
            "Epoch: 0, Batch: 23870, Loss: 0.4695508450269699, Accuracy: 50.12, Precision: 0.53, Recall: 0.52\n",
            "Epoch: 0, Batch: 23880, Loss: 0.36769490987062453, Accuracy: 50.04, Precision: 0.52, Recall: 0.51\n",
            "Epoch: 0, Batch: 23890, Loss: 0.4116265445947647, Accuracy: 50.16, Precision: 0.54, Recall: 0.52\n",
            "LOSS train 0.9977453947067261 valid 0.40340842904216473\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model = CNN(vocab_size,embedding_dim)\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "# defining the loss function\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "epoch_number = 0\n",
        "best_vloss = float('inf')\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "best_vloss = float('inf')\n",
        "train_losses = [] \n",
        "val_losses = []\n",
        "test_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_epoch(epoch_number)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # Where we're going, we don't need gradients\n",
        "    model.eval() \n",
        "\n",
        "    running_vloss = 0.0\n",
        "    total_val_predictions = []\n",
        "    total_val_labels = []\n",
        "    for i, vdata in enumerate(val_loader):\n",
        "        vlabels, vinputs, offset = vdata\n",
        "        if len(vlabels) == 10:\n",
        "          vinputs = vinputs.reshape([10, 23]).to(device=device,dtype=torch.long)\n",
        "          vlabels = vlabels.float().to(device=device) \n",
        "          voutputs = model(vinputs)\n",
        "          vloss = criterion(voutputs, vlabels.unsqueeze(1))\n",
        "          running_vloss += vloss.item()\n",
        "\n",
        "          # Calculate metrics for validation set\n",
        "          rounded_vpreds = torch.round(torch.sigmoid(voutputs))\n",
        "          total_val_predictions.extend(rounded_vpreds.tolist())\n",
        "          total_val_labels.extend(vlabels.tolist())\n",
        "        else:\n",
        "          pass\n",
        "    avg_vloss = running_vloss / len(val_loader)\n",
        "    val_losses.append(avg_vloss)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    val_accuracy, val_precision, val_recall = compute_metrics(torch.tensor(total_val_predictions), torch.tensor(total_val_labels))\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "\n",
        "    epoch_number += 1\n",
        "\n",
        "# After all epochs, evaluate the model on the test set\n",
        "model.eval()  # Ensure the model is in evaluation mode\n",
        "running_test_loss = 0.0\n",
        "total_test_predictions = []\n",
        "total_test_labels = []\n",
        "\n",
        "for i, tdata in enumerate(test_loader):\n",
        "    tlabels, tinputs, offset = tdata\n",
        "    if len(tlabels) == 10:\n",
        "      tinputs = tinputs.reshape([10, 23]).to(device=device, dtype=torch.long)\n",
        "      tlabels = tlabels.float().to(device=device)\n",
        "      toutputs = model(tinputs)\n",
        "      tloss = criterion(toutputs, tlabels.unsqueeze(1))\n",
        "      running_test_loss += tloss.item()\n",
        "      # Calculate metrics for testn set\n",
        "      rounded_tpreds = torch.round(torch.sigmoid(toutputs))\n",
        "      total_test_predictions.extend(rounded_tpreds.tolist())\n",
        "      total_test_labels.extend(tlabels.tolist())\n",
        "\n",
        "avg_test_loss = running_test_loss / len(test_loader)\n",
        "test_losses.append(avg_test_loss)\n",
        "test_accuracy, test_precision, test_recall = compute_metrics(torch.tensor(total_test_predictions), torch.tensor(total_test_labels))\n",
        "test_accuracies.append(test_accuracy)\n",
        "test_precisions.append(test_precision)\n",
        "test_recalls.append(test_recall)\n",
        "print('Test Loss: {}'.format(avg_test_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "JuP30WH9Zy0X",
        "outputId": "7ae3bb8f-da8f-45ee-c53d-633dc6c53f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[66], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, EPOCHS)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Plot and label the training and validation loss values\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m plt\u001b[39m.\u001b[39;49mplot(epochs, train_losses, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTraining Loss\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m plt\u001b[39m.\u001b[39mplot(epochs, val_losses, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation Loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Add in a title and axes labels\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/mlclass/lib/python3.10/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/mlclass/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/mlclass/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[1;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/mlclass/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate a sequence of integers to represent the epoch numbers\n",
        "epochs = range(1, EPOCHS+1)\n",
        "\n",
        "# Plot the training and validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_losses, label='Training Loss')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Plot the training and validation accuracy values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Print test metrics\n",
        "print(\"Test Loss: {:.4f}\".format(avg_test_loss))\n",
        "print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Test Precision: {:.4f}\".format(test_precision))\n",
        "print(\"Test Recall: {:.4f}\".format(test_recall))\n",
        "\n",
        "# Create a confusion matrix for the test set\n",
        "test_confusion = confusion_matrix(total_test_labels, total_test_predictions)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(test_confusion, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix - Test Set')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWit7ZZVzCpF+agTcHetCd",
      "include_colab_link": true,
      "mount_file_id": "1uYL8qjFTmqSwUOiGG1V4Nuut6-puTFf5",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
