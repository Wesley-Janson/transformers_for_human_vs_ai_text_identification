{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wesley-Janson/transformers_for_human_vs_ai_text_identification/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sVt0Q2rzlJJs"
      },
      "outputs": [],
      "source": [
        "# Import relevant packages and data_loader.py\n",
        "#import data_loader\n",
        "\n",
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for reading and displaying images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for creating validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, Conv2d, MaxPool1d, MaxPool2d, Module, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "k8CDKMYwpjwm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "kD90Pi_HpstG",
        "outputId": "8296eb8f-bbd7-4eb5-e0e4-7a13fe04d73e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-64f0835c-f5d7-4916-ae4e-f50059d474ac\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-64f0835c-f5d7-4916-ae4e-f50059d474ac\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.csv to data (2).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        " \n",
        " \n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aRaZIij8puzX"
      },
      "outputs": [],
      "source": [
        "def load_data(csv):\n",
        "  # Reads the raw csv file and split into\n",
        "  # sentences (x) and target (y)\n",
        "  df = pd.read_csv(csv)\n",
        "  print(len(df))\n",
        "  \n",
        "  text = df['intro'].values\n",
        "  labels = df['type'].values\n",
        "  return labels,text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oIY1CJJ5p0zA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This function processes training data, establishing number IDs for each vocabulary word,\n",
        "# converting word sequence into ID sequence (input_as_ids), and providing dict\n",
        "# to map from word to its ID (word2id), and list to map from ID back to word (id2word)\n",
        "def process_training_data(corpus_text):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        # Create the model's vocabulary and map to unique indices\n",
        "        word2id = {}\n",
        "        id2word = []\n",
        "        list_of_inputs = []\n",
        "        for entry in corpus_text:\n",
        "            for i,word in enumerate(entry):\n",
        "                if 7<i<=30:\n",
        "                    if word not in word2id:\n",
        "                        id2word.append(word)\n",
        "                        word2id[word] = len(id2word) - 1\n",
        "\n",
        "            # Convert string of text into string of IDs in a tensor for input to model\n",
        "            input_as_ids = []\n",
        "            for i,word in enumerate(entry):\n",
        "                if 7<i<=30:\n",
        "                    input_as_ids.append(word2id[word])\n",
        "            if len(input_as_ids) == 23:\n",
        "              list_of_inputs.append(input_as_ids)\n",
        "            # final_ids = torch.LongTensor(input_as_ids)\n",
        "        list_of_inputs = torch.Tensor(list_of_inputs)\n",
        "\n",
        "        return list_of_inputs,word2id,id2word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFeCg_VftF_Q",
        "outputId": "07a9d8fa-f0cc-48be-80ba-2a341087f963"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "'data (1).csv'\t'data (2).csv'\t data.csv  'data.csv '\t drive\t sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5T4irZ27ls7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "872ca398-6e22-4fbe-a582-ffdb7cd82d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-21db73800716>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"basic_english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlist_of_tokens_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.8 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "# Run data loader\n",
        "labels,text = load_data('/content/data.csv')\n",
        "print(len(text))\n",
        "train_x, val_x, train_y, val_y = train_test_split(text, labels, test_size = 0.8)\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "list_of_tokens_train = [tokenizer(x) for x in train_x]\n",
        "list_of_tokens_val = [tokenizer(x) for x in val_x]\n",
        "\n",
        "train_x,word2id,id2word = process_training_data(list_of_tokens_train)\n",
        "\n",
        "val_x,word2id,id2word = process_training_data(list_of_tokens_val)\n",
        "print(train_x)\n",
        "print(type(train_x))\n",
        "train_y = torch.Tensor(train_y)\n",
        "val_y = torch.Tensor(val_y)\n",
        "#############################\n",
        "#### SPLIT INTO TRAIN/TEST HERE??????\n",
        "#############################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "WDvtZacBBdtg",
        "outputId": "a27dcc46-0dfd-4e72-c8e4-69d60d0e7f0b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-97535e968f7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ],
      "source": [
        "print(train_x.shape)\n",
        "print(train_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZds-vUYwdW3"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "labels,text = load_data('data.csv')\n",
        "train_x, val_x, train_y, val_y = train_test_split(text, labels, test_size = 0.8)\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_x), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omleOMTjwJ3S",
        "outputId": "341f5981-fb0a-4608-a036-0d527ec7c175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The Harmonie Club is a private social club in Bern, Switzerland, that was founded in 1884. It is one of the oldest and most prestigious clubs in Switzerland.\\n\\nThe Harmonie Club was founded on October 13, 1884, by a group of friends who were looking for a place to socialize and enjoy their music. The club originally met at the home of its first president, Dr. Julius Hutter. Today, the club is located on Bellevuegasse in Bern.\\n\\nSince its inception, the Harmonie Club has been committed to promoting music and the arts. It has hosted many famous musicians, including Joseph Joachim, Wilhelm Furtwängler, and Arturo Toscanini. The club also sponsors a number of performances and festivals throughout the year.\\n\\nThe Harmonie Club is open to all members of the Swiss community who are interested in music and the arts. Membership is free of charge.'\n",
            " \"Red Sea Project is a land and property development announced by the Saudi Crown Prince Mohammad bin Salman in July 2017. It is planned to be established on the Saudi Arabian Red Sea coast. The project is focused on tourism, hoping to attract tourists to visit and explore the Saudi western coast. The mega project is expected to increase the Saudi GDP by $5.86 billion per year upon completion, when it will cover  of islands, beaches, desert, mountains and volcanic areas. The first phase is expected to be completed by 2022 when 3,000 hotel rooms will be constructed along with an airport, marina and recreation centers. The project is led by the Red Sea Development Company (TRSDC). It is expected to attract one million people every year. Upon completion, the project will create 70,000 new jobs. Location \\nThe project will be located at Tabuk province's shores of the Red Sea, particularly between the cities of Umluj and Al-Wajh. Ninety unspoiled offshore islands between the two cities will also be part of the project.\"\n",
            " \"Taekwondo, Tae Kwon Do or Taekwon-Do \\n\\nTaekwondo is a Korean martial art and sport. It is a dynamic, full-contact, joint-based system that utilizes throws and joint locks to defeat an opponent. Taekwondo emphasizes the use of footwork, body mechanics, and balance to evade and counterattacks. Taekwondo was created in the early 20th century by Choi Hong Hi and is currently practiced in over 80 countries. \\n\\nTaekwondo is a physically and mentally challenging martial art that has been used for centuries to keep societies safe. It has been credited with helping to create the world's first martial arts association, the World Taekwondo Federation (WTF), in 1964. Taekwondo has also been used as a tool for social change, helping to improve mental health, reduce crime rates, and promote peace and reconciliation.\"\n",
            " ...\n",
            " 'BLOM BANK (French: Banque du Liban et D’Outre Mer; Arabic: بنك لبنان والمهجر) is a Lebanese bank established in 1951 and has been frequently selected as the Best Bank in Lebanon by the most recognized regional and international financial institutions such as Euromoney and The Banker. Its business operations are based on a universal banking model that includes: Commercial Banking, Corporate Banking, Private Banking, Investment Banking, Asset Management, Retail Banking, Islamic Banking, Brokerage Services, and Insurance Products and Services. History\\nBLOM BANK started operating in 1951 in Beirut. Its establishment coincided with a booming period in the banking sector in Lebanon. By 1953, BLOM BANK started expanding and opened a branch in Jeddah, KSA. As the Lebanese Civil War broke out, BLOM BANK’s operations abroad increased to cater for the need of the Lebanese diaspora. Today, The Group is present in 11 countries across the world. On the leadership level, Dr. Naaman Azhari became the General Manager of the Bank in 1962 and Chairman of the Board and General Manager in 1971. In 2007, Dr. Naaman Azhari was appointed Chairman of BLOM BANK Group, and Honorary Chairman of BLOM BANK Group in 2020, while his son, Mr. Saad Azhari, became Chairman of the Board and General Manager of BLOM BANK.'\n",
            " \"Family Reunion is a 1981 American made-for-television comedy film starring Robert Klein and Valerie Harper.\\n\\nThe film is based on the real-life experiences of comedian Robert Klein and his wife, Valerie Harper. The movie was produced by Klein and Harper, with a screenplay by Klein and John Hughes. It aired on NBC on July 11, 1981.\\n\\nThe film tells the story of Klein's family reunion, which turns into a disaster when Klein's estranged brother (played by Hughes) unexpectedly shows up.\"\n",
            " \"Mat Hames is an Emmy-Winning American independent filmmaker known for the PBS and Prime Video documentary series Power Trip: the Story of Energy, as well as his Independent Lens documentaries When I Rise and What Was Ours. He was knighted by King Albert II for his documentary film about Belgian Resistance escape lines in World War II Last Best Hope. He directed the Rooster Teeth RTDocs Series including Common Ground, Waiting for the Punchline, Why We're Here: 15 Years of Rooster Teeth, The Meme Machine, and Connected. His films have been part of the Emmy-Winning U.S. PBS series Independent Lens, SundanceTV, and Amazon Prime. He is a founder of Austin documentary production company Alpheus Media. Alpheus Media, Inc. has also created advertising campaigns for clients including Johns Hopkins, as well as films for the Atlantic Magazine, museums, non-profits, healthcare organizations and Global NGOs. A portion of their interviews with more than 250 cancer survivors appear on the Livestrong web site, and in a best selling book,  Live Strong . External links\\n Alpheus Media\\n Connected\\n What Was Ours\\n Indiewire Film Review: World's Greatest Head Massage\\n Fighting Goliath: Texas Coal Wars\\n When I Rise\\n When I Rise - PBS Site\\n Last Best Hope\\n \"]\n",
            "<class 'numpy.ndarray'>\n",
            "(60000,)\n"
          ]
        }
      ],
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x)\n",
        "print(train_x)\n",
        "print(type(train_x))\n",
        "print(train_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zQmxBERv2lg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    print(label_list)\n",
        "    print(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "loader = torch.utils.dataloader(train, \n",
        "                                batch_size=1, # choose your batch size\n",
        "                                shuffle=True)\n",
        "dataloader = DataLoader(pd.read_csv('data.csv'), batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CavGDuyJxt5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv3_bNOlltWp"
      },
      "outputs": [],
      "source": [
        "# Define Architecture\n",
        "\n",
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv1d(59704, 4000, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm1d(23),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool1d(kernel_size=2, stride=2),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv1d(4000, 4, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm1d(23),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool1d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(4 * 7 * 7, 10)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQJ_G32eluyN",
        "outputId": "e259f22b-ff14-48b8-a807-108f4effad61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv1d(59704, 4000, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv1d(4000, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (5): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=196, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6z3lxJflwmH"
      },
      "outputs": [],
      "source": [
        "# Create train function\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    # getting the training set\n",
        "    print(train_x)\n",
        "    print(train_y)\n",
        "    print(train_x.shape)\n",
        "    print(train_y.shape)\n",
        "    x_train, y_train = Variable(torch.Tensor(train_x)), Variable(torch.Tensor(train_y))\n",
        "    # getting the validation set\n",
        "    x_val, y_val = Variable(val_x), Variable(val_y)\n",
        "    # converting the data into GPU format\n",
        "    if torch.cuda.is_available():\n",
        "        x_train = x_train.cuda()\n",
        "        y_train = y_train.cuda()\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "\n",
        "    # clearing the Gradients of the model parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # prediction for training and validation set\n",
        "    output_train = model(x_train)\n",
        "    output_val = model(x_val)\n",
        "\n",
        "    # computing the training and validation loss\n",
        "    loss_train = criterion(output_train, y_train)\n",
        "    loss_val = criterion(output_val, y_val)\n",
        "    train_losses.append(loss_train)\n",
        "    val_losses.append(loss_val)\n",
        "\n",
        "    # computing the updated weights of all the model parameters\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss = loss_train.item()\n",
        "    if epoch%2 == 0:\n",
        "        # printing the validation loss\n",
        "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do_4PK5Klx1_",
        "outputId": "b4ab0d7f-9582-4c93-8099-ed91309858ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 1.5000e+01, 1.6000e+01,\n",
            "         1.0000e+01],\n",
            "        [3.0000e+00, 1.0000e+01, 1.1000e+01,  ..., 3.1000e+01, 3.2000e+01,\n",
            "         2.1000e+01],\n",
            "        [1.9000e+01, 3.3000e+01, 1.4000e+01,  ..., 3.3000e+01, 1.4000e+01,\n",
            "         4.3000e+01],\n",
            "        ...,\n",
            "        [7.7557e+04, 5.1000e+01, 7.7558e+04,  ..., 1.9000e+01, 7.7370e+03,\n",
            "         8.6000e+01],\n",
            "        [1.2271e+04, 3.0000e+00, 3.6000e+01,  ..., 4.4520e+03, 1.4000e+01,\n",
            "         8.2000e+01],\n",
            "        [0.0000e+00, 1.1000e+01, 8.3900e+02,  ..., 1.9708e+04, 3.2000e+01,\n",
            "         9.0900e+02]])\n",
            "tensor([1., 1., 0.,  ..., 0., 0., 1.])\n",
            "torch.Size([59704, 23])\n",
            "torch.Size([60000])\n"
          ]
        }
      ],
      "source": [
        "# defining the number of epochs\n",
        "n_epochs = 25\n",
        "# empty list to store training losses\n",
        "train_losses = []\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "# training the model\n",
        "for epoch in range(n_epochs):\n",
        "  train(epoch)\n",
        "print(train_losses)\n",
        "print(val_loses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTk8jOI-reYo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uYL8qjFTmqSwUOiGG1V4Nuut6-puTFf5",
      "authorship_tag": "ABX9TyMmn13QWyBF9ic+uANjCLBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}